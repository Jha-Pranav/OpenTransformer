{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "579757e7-cb8b-40be-9f6f-e8395e4e90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformers\n",
    "\n",
    "import datasets\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c6b2d7c4-2c18-4b60-9c81-6103542cd77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task : Classification\n",
    "# Data : glue/mrpc\n",
    "# pretrained-model checkpoint = \"bert-base-uncased\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'mps' if torch.backend.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11627523-2fe6-427a-acf1-4ba20e78b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "dataset_cache = \"../../data/external/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7fabd7ba-e721-49d5-b714-9bb41a9293ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# LOad pretrained dataset, tokenizer , model \n",
    "raw_dataset = datasets.load_dataset(\"glue\",\"mrpc\",cache_dir=dataset_cache)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e5f7796-b0c4-4343-a725-77b18ce216ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['sentence1', 'sentence2', 'label', 'idx'],\n",
       " 'validation': ['sentence1', 'sentence2', 'label', 'idx'],\n",
       " 'test': ['sentence1', 'sentence2', 'label', 'idx']}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e24b533-20f2-4f9b-be8b-14c8da7f7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load DataSet into batches \n",
    "def tokenizer_func(example):\n",
    "    return tokenizer(example['sentence1'],example['sentence2'],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "052dac5f-9643-4ddd-a7cf-887344449fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = raw_dataset.map(tokenizer_func,batched=True,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a46cbcf7-7a48-4b61-b741-2248827597e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = tokenized_data.remove_columns(['sentence1', 'sentence2', 'idx'])\n",
    "tokenized_data = tokenized_data.rename_column('label',\"labels\")\n",
    "tokenized_data.set_format(\"torch\")\n",
    "tokenized_data[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "efcfd753-f61f-4a62-8468-008c96f10ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=raw_data['train'],batch_size=50,shuffle=True,collate_fn=data_collator,num_workers=25,pin_memory=True)\n",
    "val_dataloader = DataLoader(dataset=raw_data['validation'],batch_size=10,shuffle=True,collate_fn=data_collator,num_workers=25,pin_memory=True)\n",
    "test_dataloader = DataLoader(dataset=raw_data['test'],batch_size=50,shuffle=True,collate_fn=data_collator,num_workers=25,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2bf137a5-0b0b-4a4d-abdc-08533bfa479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singelbatch : {'input_ids': torch.Size([50, 96]), 'token_type_ids': torch.Size([50, 96]), 'attention_mask': torch.Size([50, 96]), 'labels': torch.Size([50])}\n",
      "MOdel training output on single batch ->  LOss :  tensor(0.6433, grad_fn=<NllLossBackward0>) torch.Size([50, 2])\n"
     ]
    }
   ],
   "source": [
    "# Santity\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"   # Supress warning\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "print(\"Singelbatch :\",{k:v.shape for k,v in batch.items()})\n",
    "output = model(**batch)\n",
    "print(\"MOdel training output on single batch -> \",\"LOss : \", output.loss\n",
    "      ,output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "57c75970-0c80-4ba7-ad43-a268a430a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(),lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9dba832e-ab26-49bb-b0fd-266b05602720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optim,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20f7c338-a917-4b54-9ab6-4a97a1983f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b9ddc38-f3ad-4898-afab-69bb89f0a1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75b030471c5492c9071a68f4a33e0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 s, sys: 10.2 s, total: 38.8 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        out = model(**batch)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "    \n",
    "        optim.step()\n",
    "        lr_scheduler.step()\n",
    "        optim.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ef6b1825-ed3e-48dc-86f5-0ef0e43a78f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8431372549019608, 'f1': 0.891156462585034}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "model.eval()\n",
    "for batch in val_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
