{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4928c83a-0997-4573-b7b9-851a76b8f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.blm.pl_dataloader import TinyStoriesDataloader\n",
    "from src.models.blm.pl_training import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfc453b-fd26-4d2a-a1df-bd4689062ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"/home/pranav-pc/projects/OpenTransformer/multiformer\"\n",
    "MODEL_CHECKPOINT_PATH = \"/home/pranav-pc/projects/model-registry/blm-medium/last.ckpt\"\n",
    "data_path_train = BASE_URL + \"/data/interim/TinyStories_train_65>tk>512.hf\"\n",
    "data_path_val = BASE_URL + \"/data/interim/TinyStories_val_65>tk>512.hf\"\n",
    "tokenizer_path = BASE_URL + \"/tokenizer_checkpoints\"\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 26\n",
    "ds = TinyStoriesDataloader(\n",
    "    data_path_train, data_path_val, tokenizer_path, batch_size, num_workers, subset_ratio=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdd87d3-39bf-40f2-acc2-14bc5a454d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer.load_from_checkpoint(MODEL_CHECKPOINT_PATH)\n",
    "model = torch.compile(model, dynamic=True)\n",
    "\n",
    "#### Inference\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18e9cc1-e273-4960-8878-fec3748d167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lili wanted to watch either a movie or a cartoon. Her mother didn’t let her watch a cartoon so instead she decided to go to the theater. When she got there, she saw a very special cartoon. It was about a princess who was so spoiled!\n",
      "\n",
      "Lili was very excited. She asked her mother if she could watch the cartoon, but her mother said no. Lili was very disappointed.\n",
      "\n",
      "Then Lili's mother said, \"If you want to watch the cartoon, you can watch the cartoon. But you have to be careful not to get too excited.\"\n",
      "\n",
      "So Lili went to the store and bought a cartoon. She watched it all the way home. She was so excited that she had a cartoon to watch. She was so happy that she could finally watch the cartoon. She was so glad she had listened to her mother and was so spoiled by the cartoon.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Lili wanted to watch either a movie or a cartoon. Her mother didn’t let her watch a cartoon so instead she\"\n",
    "\n",
    "\n",
    "def predict(text, max_new_tokens=450, temperature=0.8, top_k=3, conditional_break=[13, 13, 1]):\n",
    "    tokens = torch.LongTensor(ds.tokenizer.encode_as_ids(text))[:-1].to(\"cuda:0\").view(1, -1)\n",
    "    # print('tokens',ds.tokenizer.encode(text,out_type=str)[:-1])\n",
    "    print(\n",
    "        ds.tokenizer.decode_ids(\n",
    "            model.predict_step(\n",
    "                tokens,\n",
    "                None,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_k=top_k,\n",
    "                conditional_break=conditional_break,\n",
    "            )[0].tolist()\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f93b49-11d1-49c1-8a5e-fad9c699796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"I loved the movie. It was great!\",\n",
    "    \"The food was terrible.\",\n",
    "    \"The weather is okay.\",\n",
    "]\n",
    "sentiments = [\"positive\", \"negative\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a667249-cdd8-47cb-bdcc-ba9e746652f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4f786a-952f-418e-a326-9e7af11f0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text samples\n",
    "encoded_texts = ds.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Extract the input IDs and attention masks\n",
    "input_ids = encoded_texts[\"input_ids\"]\n",
    "attention_mask = encoded_texts[\"attention_mask\"]\n",
    "\n",
    "# Convert the sentiment labels to numerical form\n",
    "sentiment_labels = [sentiments.index(sentiment) for sentiment in sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076e00a4-0b24-416e-bc1d-18b34aa9652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1045, 3866, 1996, 3185, 1012, 2009, 2001, 2307,  999,  102],\n",
       "        [ 101, 1996, 2833, 2001, 6659, 1012,  102,    0,    0,    0,    0],\n",
       "        [ 101, 1996, 4633, 2003, 3100, 1012,  102,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9423abe-2eab-4a8f-93ec-0a3071c7c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ca12a2c-6602-40f6-8cb8-ed005dc7c7af",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 2]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentiment_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:1036\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1035\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1036\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fct(\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1038\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 2]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "classification_head = nn.Linear(model.config.hidden_size, 3)\n",
    "\n",
    "# Replace the pre-trained model's classification head with our custom head\n",
    "model.classifier = classification_head\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-tune the model\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(\n",
    "        input_ids, attention_mask=attention_mask, labels=torch.tensor(sentiment_labels)\n",
    "    )\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cd996-d2b5-42d0-a7fe-8e1e78bcd4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902ffd0-6fbf-4d36-9dd7-9d87fe1f893b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042a02c-bcc1-46f4-941a-6192b8af2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incontext learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a77fc-9a9b-48b0-9d47-ae6fdcdcc312",
   "metadata": {},
   "source": [
    "### GLUE (General Language Understanding Evaluation)\n",
    "\n",
    "\n",
    "**Single-Sentence Tasks**\n",
    "\n",
    "1. CoLA (Corpus of Linguistic Acceptability)\n",
    "- Goal: determine if a sentence is grammatically correct or not.\n",
    "- Dataset: it consists of English acceptability judgments drawn from books and journal articles. Each example is a sequence of words annotated with whether it is a correct grammatical English sentence or not.\n",
    "2. SST-2 (Stanford Sentiment Treebank)\n",
    "- Goal: determine if the sentence has a positive or negative sentiment.\n",
    "- Dataset: it consists of sentences from movie reviews and binary human annotations of their sentiment.\n",
    "\n",
    "\n",
    "**Similarity and Paraphrase Tasks**\n",
    "\n",
    "3. MRPC (Microsoft Research Paraphrase Corpus)\n",
    "- Goal: determine if two sentences are paraphrases from one another.\n",
    "- Dataset: it’s a corpus of sentence pairs automatically extracted from online news sources, with human annotations indicating whether the sentences in the pair are semantically equivalent (i.e. paraphrases).\n",
    "4. QQP (Quora Question Pairs)\n",
    "- Goal: determine if two questions are semantically equivalent or not.\n",
    "- Dataset: it’s a collection of question pairs from the community question-answering website Quora, with human annotations indicating whether the questions in the pair are actually the same question.\n",
    "5. STS-B (Semantic Textual Similarity Benchmark)\n",
    "- Goal: determine the similarity of two sentences with a score from one to five.\n",
    "- Dataset: it’s a collection of sentence pairs drawn from news headlines, video and image captions, and natural language inference data. Each pair is annotated by humans with a similarity score from one to five.\n",
    "\n",
    "\n",
    "**Inference Tasks**\n",
    "\n",
    "6. MNLI (Multi-Genre Natural Language Inference)\n",
    "- Goal: determine if a sentence entails, contradicts, or is unrelated to another sentence.\n",
    "- Dataset: it’s a crowdsourced collection of sentence pairs with textual entailment annotations. The premise sentences are gathered from ten different sources, including transcribed speech, fiction, and government reports. The dataset has two test sets: a matched (in-domain) and mismatched (cross-domain) test set. The scores on the matched and mismatched test sets are then averaged together to give the final score on the MNLI task.\n",
    "7. QNLI (Question-answering Natural Language Inference)\n",
    "- Goal: determine if the answer to a question is contained in a second sentence or not.\n",
    "- Dataset: it’s a question-answering dataset consisting of question-paragraph pairs, where one of the sentences in the paragraph (drawn from Wikipedia) contains the answer to the corresponding question (written by an annotator).\n",
    "8. RTE (Recognizing Textual Entailment)\n",
    "- Goal: determine if a sentence entails a given hypothesis or not.\n",
    "- Dataset: it is a combination of data from annual textual entailment challenges (i.e. from RTE1, RTE2, RTE3, and RTE5). Examples are constructed based on news and Wikipedia text.\n",
    "9. WNLI (Winograd Natural Language Inference)\n",
    "- Goal: determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not.\n",
    "- Dataset: this dataset is built from the Winograd Schema Challenge dataset, where it’s a reading comprehension task in which a system must read a sentence with a pronoun and select the referent of that pronoun from a list of choices. To convert the problem into sentence pair classification, the authors of the benchmark construct sentence pairs by replacing the ambiguous pronoun with each possible referent. The examples are manually constructed to foil simple statistical methods: each one is contingent on contextual information provided by a single word or phrase in the sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8600b04f-364b-4f9b-9516-0dd48aae9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9c2b382-0358-4d45-9e07-a94d671d2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00c30046-cdc9-4dfc-9829-c287d8f64c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GLUEConfig:\n",
    "    model_path: str\n",
    "    tokenizer_path: str\n",
    "    task_name: str = \"mrpc\"\n",
    "    max_seq_len: int = 512\n",
    "    train_batch_size: int = 64\n",
    "    eval_batch_size: int = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856f5951-2ab2-48a9-877b-befc31d85167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLUEDataModule(pl.LightningDataModule):\n",
    "    task_text_field_map = {\n",
    "        \"cola\": [\"sentence\"],\n",
    "        \"sst2\": [\"sentence\"],\n",
    "        \"mrpc\": [\"sentence1\", \"sentence2\"],\n",
    "        \"qqp\": [\"question1\", \"question2\"],\n",
    "        \"stsb\": [\"sentence1\", \"sentence2\"],\n",
    "        \"mnli\": [\"premise\", \"hypothesis\"],\n",
    "        \"qnli\": [\"question\", \"sentence\"],\n",
    "        \"rte\": [\"sentence1\", \"sentence2\"],\n",
    "        \"wnli\": [\"sentence1\", \"sentence2\"],\n",
    "        \"ax\": [\"premise\", \"hypothesis\"],\n",
    "    }\n",
    "\n",
    "    glue_task_num_labels = {\n",
    "        \"cola\": 2,\n",
    "        \"sst2\": 2,\n",
    "        \"mrpc\": 2,\n",
    "        \"qqp\": 2,\n",
    "        \"stsb\": 1,\n",
    "        \"mnli\": 3,\n",
    "        \"qnli\": 2,\n",
    "        \"rte\": 2,\n",
    "        \"wnli\": 2,\n",
    "        \"ax\": 3,\n",
    "    }\n",
    "\n",
    "    loader_columns = [\n",
    "        \"datasets_idx\",\n",
    "        \"input_ids\",\n",
    "        \"token_type_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"start_positions\",\n",
    "        \"end_positions\",\n",
    "        \"labels\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.column_name = self.task_text_field_map[args.task_name]\n",
    "        self.label_count = self.glue_task_num_labels[args.task_name]\n",
    "        self.tokenizer = self._load_tokenizer(self.args.tokenizer_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_tokenizer(tokenizer_path):\n",
    "        from src.tokenize.tokenizer import Tokenizer\n",
    "\n",
    "        return Tokenizer(tokenizer_path)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.dataset = load_dataset(\"glue\", self.args.task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21962af1-4a0d-44e6-86ff-7a2cc25337fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|███████████████████████| 502k/502k [00:02<00:00, 192kB/s]\n",
      "Downloading data: 100%|██████████████████████| 151k/151k [00:02<00:00, 67.2kB/s]\n",
      "Downloading data: 100%|██████████████████████| 114k/114k [00:02<00:00, 55.8kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144fc76b363346be9de35b3aac6ca017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc7d84640fa4b49a8771bbc446d8e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6093d78bb46f425296c00570202f16f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"stsb\", cache_dir=\"eval-data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fa39d2c-524f-4624-a37a-2eb2e40455f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66ebeedf-dc31-4916-a80c-419c84d21a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'A'),\n",
       " (' ', ' '),\n",
       " ('p', 'p'),\n",
       " ('l', 'l'),\n",
       " ('a', 'a'),\n",
       " ('n', 'n'),\n",
       " ('e', 'e'),\n",
       " (' ', ' '),\n",
       " ('i', 'i'),\n",
       " ('s', 's'),\n",
       " (' ', ' '),\n",
       " ('t', 't'),\n",
       " ('a', 'a'),\n",
       " ('k', 'k'),\n",
       " ('i', 'i'),\n",
       " ('n', 'n'),\n",
       " ('g', 'g'),\n",
       " (' ', ' '),\n",
       " ('o', 'o'),\n",
       " ('f', 'f'),\n",
       " ('f', 'f'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "list(zip(example[\"sentence1\"], example[\"sentence1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70107b31-a471-4aa5-93b3-85c90424109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abc16eb23a34721bca5636dd89ac8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe2ef0a2-17ed-429e-abf4-73f519ce1e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'The Nasdaq had a weekly gain of 17.27 , or 1.2 percent , closing at 1,520.15 on Friday .',\n",
       " 'sentence2': 'The tech-laced Nasdaq Composite .IXIC rallied 30.46 points , or 2.04 percent , to 1,520.15 .',\n",
       " 'label': 0,\n",
       " 'idx': 6,\n",
       " 'input_ids': [101,\n",
       "  1996,\n",
       "  17235,\n",
       "  2850,\n",
       "  4160,\n",
       "  2018,\n",
       "  1037,\n",
       "  4882,\n",
       "  5114,\n",
       "  1997,\n",
       "  2459,\n",
       "  1012,\n",
       "  2676,\n",
       "  1010,\n",
       "  2030,\n",
       "  1015,\n",
       "  1012,\n",
       "  1016,\n",
       "  3867,\n",
       "  1010,\n",
       "  5494,\n",
       "  2012,\n",
       "  1015,\n",
       "  1010,\n",
       "  19611,\n",
       "  1012,\n",
       "  2321,\n",
       "  2006,\n",
       "  5958,\n",
       "  1012,\n",
       "  102,\n",
       "  1996,\n",
       "  6627,\n",
       "  1011,\n",
       "  17958,\n",
       "  17235,\n",
       "  2850,\n",
       "  4160,\n",
       "  12490,\n",
       "  1012,\n",
       "  11814,\n",
       "  2594,\n",
       "  24356,\n",
       "  2382,\n",
       "  1012,\n",
       "  4805,\n",
       "  2685,\n",
       "  1010,\n",
       "  2030,\n",
       "  1016,\n",
       "  1012,\n",
       "  5840,\n",
       "  3867,\n",
       "  1010,\n",
       "  2000,\n",
       "  1015,\n",
       "  1010,\n",
       "  19611,\n",
       "  1012,\n",
       "  2321,\n",
       "  1012,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddafbdb-fd83-4f6e-a986-ae25ecd53d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
