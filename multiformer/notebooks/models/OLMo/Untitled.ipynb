{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13833c6-a105-49d7-9de0-debc9ce2d31a",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "Adapted from\n",
    "[OLMo](https://github.com/allenai/OLMo) ,\n",
    "[mistral](https://github.com/mistralai/mistral-src) ,\n",
    "[GPT-FAST](https://github.com/pytorch-labs/gpt-fast)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bf1507-75e1-48de-ad79-d4ff0d61b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION : 2.2.1\n",
      "GPU  :  CUDA\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "\n",
    "print(\"TORCH VERSION :\", version(\"torch\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print('GPU  : ', device.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5ff120-fca1-479a-86d9-d3a666262482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "577a5edd-e984-450e-b1d6-4739195b92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a1700-353a-4efd-8987-55c222a498dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89484199-ae35-485f-945b-7154bb0c4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2949d-e019-4056-abae-3074662440ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0038176-fe4a-4a6a-8e7f-acedc1cf981e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9435087f-6753-4eb3-bb50-a47169706b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e47212-bb60-4a66-a9ce-25425eb1b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    n_layer: int = 12\n",
    "    # input\n",
    "    d_model: int = \n",
    "    seq_len: int = 500\n",
    "    vocab_size:int = -1 # fill this after tokenization\n",
    "    # Norm\n",
    "    norm_eps: float = 1e-5\n",
    "    #RoPE\n",
    "    rope_base: float = 10000.0\n",
    "    scaling_factor:float = 1.0\n",
    "    # Attention\n",
    "    n_head: int = 32\n",
    "    n_kv_head: int = \"?\"\n",
    "    sliding_window: int = \"?\"\n",
    "    # FeedForward\n",
    "    intermediate_size: int = None\n",
    "    # Training\n",
    "    batch_size: int = None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef88004-392d-40c3-a1a6-7f33e5c614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryEmbedding(nn.Module,ModelArgs):\n",
    "    \"\"\"\n",
    "    [Rotary positional embeddings (RoPE)](https://arxiv.org/abs/2104.09864).\n",
    "    \"\"\"\n",
    "    def __init__(self,h_dim:int,seq_len:int,base:Union[int, float]=10000,device:str=None,scaling_factor: Union[int, float]=1.0):\n",
    "        super().__init__()\n",
    "        # Experimental\n",
    "        self.linear = nn.Linear()\n",
    "\n",
    "        #Long-termdecay: θi=10000**−2i/d.\n",
    "        theta = 1.0 / base ** (torch.arange(0,seq_len,2,dtype=torch.int16, device=device)/h_dim) #  (h_dim/2)\n",
    "        m = torch.arange(seq_len,dtype=torch.int16,device=device).type_as(theta).type_as(theta) #  (seq_len)\n",
    "        m /= scaling_factor\n",
    "        omega = torch.outer(m,theta)  # (seq_len,h_dim/2)\n",
    "        self.omega_complex = torch.polar(torch.ones_like(omega),omega)\n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        \n",
    "        x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2)) #(b,seq_len,d_model,head,head_dim/2,2)\n",
    "        omega_complex = self.omega_complex.unsqueeze(0).unsqueeze(2) # (seq_len,h_dim/2) -> (1,seq_len,1,h_dim/2)\n",
    "        x_totated = x_complex * omega_complex #(b,seq_len,d_model,head,head_dim/2,2)\n",
    "        x_out = torch.view_as_real(x_rotated) \n",
    "        return x_out.reshape(*x.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71703472-0509-4f9f-9008-953e8a59ef95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f17eaca-ac3e-42dd-ba21-5922d5312632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.repeat_interleave(2)\n",
    "y = torch.tensor([[1, 2], [3, 4]])\n",
    "# torch.repeat_interleave(y, 2)\n",
    "torch.repeat_interleave(y, 3, dim=1)\n",
    "torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0)\n",
    "torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0, output_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f039ac39-806b-4031-9f8f-dfc11a6be731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66b2f6-50eb-4519-b26b-959aa7384d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
