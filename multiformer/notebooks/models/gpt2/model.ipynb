{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96131a00-b819-467f-9bd5-328ebea1ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION : 2.2.2\n",
      "GPU  :  CUDA\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "\n",
    "print(\"TORCH VERSION :\", version(\"torch\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.backend.mps.is_available() else 'cpu'\n",
    "print('Device  : ', device.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408ffe96-5828-4c84-a02b-db1b22a9a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "compile = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "214e4cc3-a5bd-4529-bfb5-4c44af886aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import  nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338de3e7-f128-4724-a3ba-e297a3491814",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    device : str = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9dd1c8f-affe-4a4a-a5f2-510251d3933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.ln_1 = LayerNorm(config.n_embd,bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd,bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f8892f-9b78-456c-bd3a-e62360ab4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm with bias=False\"\"\"\n",
    "    def __init__(self,ndim,bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim)) # Multiplicative\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None # Additive\n",
    "\n",
    "    def forward(self,x):\n",
    "        device = x.device\n",
    "        \n",
    "        return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a589e306-c65b-4b26-90d6-462ea43b0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "\n",
    "        assert config.n_embd % config.n_head == 0, \"embedding dim should be divisible by head dim\"\n",
    "        self.c_attn = nn.Linear(config.n_embd,3*config.n_embd,bias=config.bias,device=config.device)\n",
    "\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias,device=config.device)\n",
    "\n",
    "        self.dropout = config.dropout\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B, T, C = x.size()\n",
    "        q,k,v = self.c_attn(x).split(self.n_embd,dim=2)\n",
    "\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        if self.flash:\n",
    "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0., is_causal=True)\n",
    "        else:\n",
    "            # In case of pytorch < 2.0\n",
    "            NotImplementedError\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        return self.resid_dropout(self.c_proj(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feeea700-d2dc-45d0-8a6c-e758a1f6b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias,device=config.device)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias,device=config.device)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee748830-6fad-4098-9f64-9f83a817d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size,config.n_embd,device=config.device),\n",
    "            wpe = nn.Embedding(config.block_size,config.n_embd,device=config.device),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd,bias=config.bias)\n",
    "        ))\n",
    "        \n",
    "        self.lm_head = nn.Linear(config.n_embd,config.vocab_size,bias=False,device=config.device)\n",
    "        # weight sharing https://paperswithcode.com/method/weight-tying\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0,std=0.02/math.sqrt(2*config.n_layer))\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6))\n",
    "        \n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        device = idx.device\n",
    "        b,t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "        \n",
    "        tok_emb = self.transformer.wte(idx) # b,t,n_embd\n",
    "        pos_emb = self.transformer.wpe(pos) # b,t,n_embd\n",
    "\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        if targets is not None:\n",
    "        # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        # model surgery to decrease the block size if necessary\n",
    "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
    "        # but want to use a smaller block size for some smaller, simpler model\n",
    "        assert block_size <= self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
    "        for block in self.transformer.h:\n",
    "            if hasattr(block.attn, 'bias'):\n",
    "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls,model_type,override_args=None):\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        override_args = override_args or {}\n",
    "\n",
    "        assert all(k == 'dropout' for k in override_args)\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        config_args['bias'] = True # always True for GPT model checkpoints\n",
    "        # we can override the dropout rate, if desired\n",
    "        if 'dropout' in override_args:\n",
    "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
    "            config_args['dropout'] = override_args['dropout']\n",
    "            \n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type,cache_dir='.')\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        # use_fused = fused_available and device_type == 'cuda'\n",
    "        use_fused = False\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee603885-0fa9-4b74-97e1-aa02286cf298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.69M\n"
     ]
    }
   ],
   "source": [
    "config = GPTConfig()\n",
    "model = GPT(config)\n",
    "\n",
    "# idx = torch.randint(low=1,high=1024,size=(2,1024),device='cpu')\n",
    "\n",
    "# idx_next = model.generate(idx,15,top_k=10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d81e4899-88d9-49c9-863a-699d81120281",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "\n",
    "optim_groups = [\n",
    "    {'params': decay_params, 'weight_decay': 1e-2},\n",
    "    {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56a4a3c3-69a4-42ae-bd52-b4e6545e1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n"
     ]
    }
   ],
   "source": [
    "num_decay_params = sum(p.numel() for p in decay_params)\n",
    "num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b45a86c7-b86c-4ced-bf90-2282bb3216af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_available = 'fused' in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e83a2e9e-7a42-4a7e-8923-559cc1b5e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fused': True}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "use_fused = fused_available and device == 'cuda'\n",
    "extra_args = dict(fused=True) if use_fused else dict()\n",
    "extra_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ec56687-09cf-404b-9c73-c011a7efa7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bfloat16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "065dba8b-8694-404b-9248-aa3647b93ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`fused=True` requires all the params to be floating point Tensors of supported devices: ['cuda', 'xpu', 'privateuseone'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptim_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/optim/adamw.py:68\u001b[0m, in \u001b[0;36mAdamW.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     62\u001b[0m fused_supported_devices \u001b[38;5;241m=\u001b[39m _get_fused_kernels_supported_devices()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m     64\u001b[0m     p\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01min\u001b[39;00m fused_supported_devices \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     torch\u001b[38;5;241m.\u001b[39mis_floating_point(p)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m ):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fused=True` requires all the params to be floating point Tensors of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported devices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfused_supported_devices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m foreach:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fused` and `foreach` cannot be `True` together.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `fused=True` requires all the params to be floating point Tensors of supported devices: ['cuda', 'xpu', 'privateuseone']."
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(optim_groups, lr=1e-4, betas=(0.9,0.95), **extra_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6cbdffa0-1b0a-4027-b958-58b8b226b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`fused=True` requires all the params to be floating point Tensors of supported devices: ['cuda', 'xpu', 'privateuseone'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 186\u001b[0m, in \u001b[0;36mGPT.configure_optimizers\u001b[0;34m(self, weight_decay, learning_rate, betas, device_type)\u001b[0m\n\u001b[1;32m    184\u001b[0m use_fused \u001b[38;5;241m=\u001b[39m fused_available \u001b[38;5;129;01mand\u001b[39;00m device_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    185\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(fused\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m use_fused \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 186\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptim_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing fused AdamW: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_fused\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/optim/adamw.py:68\u001b[0m, in \u001b[0;36mAdamW.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     62\u001b[0m fused_supported_devices \u001b[38;5;241m=\u001b[39m _get_fused_kernels_supported_devices()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m     64\u001b[0m     p\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01min\u001b[39;00m fused_supported_devices \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     torch\u001b[38;5;241m.\u001b[39mis_floating_point(p)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m ):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fused=True` requires all the params to be floating point Tensors of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported devices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfused_supported_devices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m foreach:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fused` and `foreach` cannot be `True` together.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `fused=True` requires all the params to be floating point Tensors of supported devices: ['cuda', 'xpu', 'privateuseone']."
     ]
    }
   ],
   "source": [
    "model.configure_optimizers(weight_decay=1e-2, learning_rate=1e-4, betas=(0.9, 0.95), device_type=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26684625-6187-47ee-87b5-597465d715d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95689606-91ab-4e7c-be87-d73aeed31531",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 2\n",
    "max_new_tokens = 500\n",
    "temprature = 0.8\n",
    "top_k = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1c284f2-ed63-4920-ad5e-141e1a994f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "ctx = nullcontext() if device=='cpu' else torch.amp.autocast(device_type=device,dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c891a5e2-b130-49d4-9997-25c05920f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.0\n",
      "number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "model = GPT.from_pretrained('gpt2',dict(dropout=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4051160f-0e41-4d7c-8f7d-97e25d0f23c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "if compile:\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a76e16c8-138c-45ed-9eb8-92978a517d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b7d756c-8996-4891-9bad-63cea6e68557",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding('gpt2')\n",
    "encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "decode = lambda l: enc.decode(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71ee0a03-27b8-4a11-9b9e-24e44c933caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"What is the meaning of name 'Pranav'\"\n",
    "idx = encode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "252b9c50-cfef-4b63-98bf-d207e7746edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2061,  318,  262, 3616,  286, 1438,  705,   47, 2596,  615,    6]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(idx, dtype=torch.long, device=device)[None, ...]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce73e1f6-b5f8-482e-9dec-1d8e8e6e0c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning of name 'Pranav' in Sanskrit?\n",
      "\n",
      "Pranav is a Sanskrit word for 'body', which refers to the body and the senses of the body. According to the first verse of the Vedanta, Pranav is a word of honor for a god or goddess.\n",
      "\n",
      "What is the meaning of the name of 'Pravell' in Sanskrit?\n",
      "\n",
      "Pravell is a term of honor or honor due to the creation of a temple, royal family and royal sisters.\n",
      "\n",
      "What is the meaning of the names or names of the temple houses, families, royal families and royal sisters in Sanskrit?\n",
      "\n",
      "A term of honor or honor due to the creation of a temple, royal family or royal sisters. The old Shravanapatnam speaks of the idea that each name of the family is the sacred name of its royal lineage, which means the lineage from which the name came. This kind of honor and honor is seen both as a name and a fact of history as well as a form of worship.\n",
      "\n",
      "What are the names or names of the temples in Sanskrit?\n",
      "\n",
      "A term of honor or honor because of the two worlds of the king, god and goddess.\n",
      "\n",
      "What is the name of the city or city-state in Sanskrit?\n",
      "\n",
      "The city is a broad term that are used to signify the village of a town, sometimes called Indian way or 'Indian town' or town.\n",
      "\n",
      "What is the name of the tribe in the Indian language of India?\n",
      "\n",
      "The tribe of the Indians of India encompasses most of the four regions of India.\n",
      "\n",
      "What is the name of the other three main aspects of Jainism in Sanskrit?\n",
      "\n",
      "Jainism is a belief in the existence of the Supreme Being of the universe; for that is the supreme being which is the supreme Being.\n",
      "\n",
      "What is the name of the word 'came' in Sanskrit?\n",
      "\n",
      "Came is a name derived from the word 'came' and the Indian word 'came'.\n",
      "\n",
      "What is the name of the word 'Khar' in Sanskrit?\n",
      "\n",
      "Khar, or 'khar', is a Sanskrit word meaning 'black man' or 'black man' or something similar to that.\n",
      "\n",
      "What is the name of the word 'Kap' in Sanskrit?\n",
      "\n",
      "Kap, or 'kap' is a Sanskrit word meaning 'black man' or 'black man' or something similar\n",
      "---------------\n",
      "What is the meaning of name 'Pranav' ('Pranaji'), or 'Pranaji'?\n",
      "\n",
      "Pranav's name is used in Sikhism because it is the only Sikh name that is known as 'Pranaji'. It is the only name that is known as 'Pranaji'.\n",
      "\n",
      "Sikh man knows the name Pranaji but is not a Sikh citizen. He is a non- Sikh. He is a non- Sikh citizen. He can speak about the name of Pranav and if he can speak about the name of Pranaji, he can speak about the name of Pranaji or its very name.\n",
      "\n",
      "In the state of Kerala, the name 'Pranaji' is only used in Kerala. In the state of Kerala, the name 'Pranaji' is only used in Kerala.\n",
      "\n",
      "The principal Sikh names in this country are:\n",
      "\n",
      "Pranaji (Mohan Singh) Phanu Pranav Pranav Narni Praja Singh\n",
      "\n",
      "Pathan Singh Pathan Pathan Pati Chit Thak Palu Patha Singh\n",
      "\n",
      "Chitavrva Pathan Pathan Pati Chitavrva Pati Charh Singh Wala Pathan\n",
      "\n",
      "Chitav of the Chitavras of the Sangh are Narni and Chitava Pranav.\n",
      "\n",
      "Pranaji is Sikh's way of naming, but it is Sanskrit and not Hindu.\n",
      "\n",
      "On any other sacred name, in Sanskrit meaning 'name' or 'person' and in Sanskrit meaning 'name' or 'individual' or 'all that is'.\n",
      "\n",
      "Some place as well, is Sorapur-ul-Korhat, or Tora-ul-Sheeser.\n",
      "\n",
      "When can temples be built?\n",
      "\n",
      "It is not known yet if temples are built in an orderly way.\n",
      "\n",
      "What is the difference between a temple and a secular temple?\n",
      "\n",
      "Unofficially, the idea is that the temple of the temple of the temple is the temple of the Hindu god, the temple of God, the temple of the Hindu identity and so on.\n",
      "\n",
      "In an example, it is believed to have been built in Shastri Bhutta.\n",
      "\n",
      "What is the reason behind a temple?\n",
      "\n",
      "There is a reason for the design of buildings.\n",
      "\n",
      "In the early days, Hindu temples were constructed with the purpose of learning. This was done by\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_sample):\n",
    "            y = model.generate(x, max_new_tokens, temperature=temprature, top_k=top_k)\n",
    "            print(decode(y[0].tolist()))\n",
    "            print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290e0e10-a88f-4d79-ae78-3d72c0ab9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/ Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc4242e-9d7d-4b60-b361-7700e7ad8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(50304,(8,1024),device=device)\n",
    "y = torch.randint(50304,(8,1024),device=device)\n",
    "get_batch = lambda split: (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66de7dad-2797-4ffd-a3a9-6e7d223a9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.59M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (resid_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model init\n",
    "gptconf = GPTConfig(\n",
    "    block_size = 1024, # how far back does the model look? i.e. context size\n",
    "    n_layer = 12, n_head = 12, n_embd = 768, # size of the model\n",
    "    dropout = 0, # for determinism\n",
    "    bias = False,\n",
    ")\n",
    "model = GPT(gptconf)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e289db-3870-4444-ac0a-a606e300718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 25, with 19,200 parameters\n",
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "optimizer = model.configure_optimizers(weight_decay=1e-2, learning_rate=1e-4, betas=(0.9, 0.95), device_type=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a73fe583-fa56-45df-909c-9fcb7ceba6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Compiling model...\")\n",
    "model = torch.compile(model) # pytorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c031007-55db-417b-8d45-4d5fad42e99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/15 loss: 10.9797\n",
      "1/15 loss: 10.9797\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 11.72 GiB of which 409.00 MiB is free. Including non-PyTorch memory, this process has 10.97 GiB memory in use. Of the allocated memory 8.75 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m lossf \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 11.72 GiB of which 409.00 MiB is free. Including non-PyTorch memory, this process has 10.97 GiB memory in use. Of the allocated memory 8.75 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "profile=True\n",
    "if profile:\n",
    "    # useful docs on pytorch profiler:\n",
    "    # - tutorial https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html\n",
    "    # - api https://pytorch.org/docs/stable/profiler.html#torch.profiler.profile\n",
    "    wait, warmup, active = 5, 5, 5\n",
    "    num_steps = wait + warmup + active\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./bench_log'),\n",
    "        record_shapes=False,\n",
    "        profile_memory=False,\n",
    "        with_stack=False, # incurs an additional overhead, disable if not needed\n",
    "        with_flops=True,\n",
    "        with_modules=False, # only for torchscript models atm\n",
    "    ) as prof:\n",
    "\n",
    "        X, Y = get_batch('train')\n",
    "        for k in range(num_steps):\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            X, Y = get_batch('train')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lossf = loss.item()\n",
    "            print(f\"{k}/{num_steps} loss: {lossf:.4f}\")\n",
    "\n",
    "            prof.step() # notify the profiler at end of each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f023212d-0340-4ea8-b91c-3a41feb55e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /tmp/ipykernel_10276/172839371.py line 49 \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 727, in _convert_frame\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 383, in _convert_frame_assert\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     compiled_product = _compile(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]                        ^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 665, in _compile\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     raise InternalTorchDynamoError(str(e)).with_traceback(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 646, in _compile\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 244, in time_wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 562, in compile_inner\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1033, in transform_code_object\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 151, in _fn\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 527, in transform\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2128, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     super().run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py\", line 328, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py\", line 328, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1282, in LOAD_METHOD\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.LOAD_ATTR(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1303, in LOAD_ATTR\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     result = BuiltinVariable(getattr).call_function(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     result = handler(tx, *args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1230, in call_getattr\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return obj.var_getattr(tx, name).clone(source=source)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 258, in var_getattr\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     value = self.const_getattr(tx, name)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/constant.py\", line 128, in const_getattr\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     member = getattr(self.value, name)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'to'\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]    File \"/tmp/ipykernel_10276/172839371.py\", line 60, in forward\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     x = block(x)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/tmp/ipykernel_10276/226634439.py\", line 12, in forward\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     x = x + self.attn(self.ln_1(x))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/tmp/ipykernel_10276/1693549525.py\", line 11, in forward\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 727, in _convert_frame\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 383, in _convert_frame_assert\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     compiled_product = _compile(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]                        ^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 665, in _compile\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     raise InternalTorchDynamoError(str(e)).with_traceback(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 646, in _compile\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 244, in time_wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 562, in compile_inner\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1033, in transform_code_object\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 151, in _fn\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 527, in transform\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2128, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     super().run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py\", line 328, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py\", line 328, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1282, in LOAD_METHOD\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     self.LOAD_ATTR(inst)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1303, in LOAD_ATTR\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     result = BuiltinVariable(getattr).call_function(\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     result = handler(tx, *args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1230, in call_getattr\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return obj.var_getattr(tx, name).clone(source=source)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 258, in var_getattr\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     value = self.const_getattr(tx, name)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/constant.py\", line 128, in const_getattr\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     member = getattr(self.value, name)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'to'\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]    File \"/tmp/ipykernel_10276/172839371.py\", line 60, in forward\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     x = block(x)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/tmp/ipykernel_10276/226634439.py\", line 12, in forward\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     x = x + self.attn(self.ln_1(x))\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]   File \"/tmp/ipykernel_10276/1693549525.py\", line 11, in forward\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING]     return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-03-28 20:32:26,770] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /tmp/ipykernel_10276/226634439.py line 11 \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 727, in _convert_frame\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 383, in _convert_frame_assert\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     compiled_product = _compile(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]                        ^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 665, in _compile\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     raise InternalTorchDynamoError(str(e)).with_traceback(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 646, in _compile\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 244, in time_wrapper\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 562, in compile_inner\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1033, in transform_code_object\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 151, in _fn\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 527, in transform\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2128, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     super().run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py\", line 328, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1282, in LOAD_METHOD\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.LOAD_ATTR(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1303, in LOAD_ATTR\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     result = BuiltinVariable(getattr).call_function(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     result = handler(tx, *args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1230, in call_getattr\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return obj.var_getattr(tx, name).clone(source=source)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 258, in var_getattr\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     value = self.const_getattr(tx, name)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/constant.py\", line 128, in const_getattr\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     member = getattr(self.value, name)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'to'\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]    File \"/tmp/ipykernel_10276/226634439.py\", line 12, in forward\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     x = x + self.attn(self.ln_1(x))\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/tmp/ipykernel_10276/1693549525.py\", line 11, in forward\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 727, in _convert_frame\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 383, in _convert_frame_assert\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     compiled_product = _compile(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]                        ^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 665, in _compile\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     raise InternalTorchDynamoError(str(e)).with_traceback(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 646, in _compile\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 244, in time_wrapper\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 562, in compile_inner\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1033, in transform_code_object\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 151, in _fn\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 527, in transform\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2128, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     super().run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1802, in CALL\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py\", line 328, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 470, in wrapper\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return inner_fn(self, inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1252, in CALL_FUNCTION_EX\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.call_function(fn, argsvars.items, kwargsvars.items)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 652, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.push(fn.call_function(self, args, kwargs))\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 294, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 248, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return super().call_function(tx, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py\", line 81, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return tx.inline_user_function_return(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 688, in inline_user_function_return\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2261, in inline_call\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return cls.inline_call_(parent, func, args, kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2376, in inline_call_\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1282, in LOAD_METHOD\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     self.LOAD_ATTR(inst)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1303, in LOAD_ATTR\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     result = BuiltinVariable(getattr).call_function(\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     result = handler(tx, *args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1230, in call_getattr\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return obj.var_getattr(tx, name).clone(source=source)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 258, in var_getattr\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     value = self.const_getattr(tx, name)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/constant.py\", line 128, in const_getattr\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     member = getattr(self.value, name)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'to'\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]    File \"/tmp/ipykernel_10276/226634439.py\", line 12, in forward\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     x = x + self.attn(self.ln_1(x))\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return forward_call(*args, **kwargs)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]   File \"/tmp/ipykernel_10276/1693549525.py\", line 11, in forward\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING]     return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-03-28 20:32:26,995] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /tmp/ipykernel_10276/1693549525.py line 8 \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 727, in _convert_frame\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 383, in _convert_frame_assert\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     compiled_product = _compile(\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]                        ^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 665, in _compile\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     raise InternalTorchDynamoError(str(e)).with_traceback(\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 646, in _compile\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 244, in time_wrapper\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 562, in compile_inner\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1033, in transform_code_object\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 151, in _fn\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 527, in transform\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2128, in run\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     super().run()\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1282, in LOAD_METHOD\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     self.LOAD_ATTR(inst)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1303, in LOAD_ATTR\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     result = BuiltinVariable(getattr).call_function(\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     result = handler(tx, *args, **kwargs)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1230, in call_getattr\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     return obj.var_getattr(tx, name).clone(source=source)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 258, in var_getattr\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     value = self.const_getattr(tx, name)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/constant.py\", line 128, in const_getattr\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     member = getattr(self.value, name)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'to'\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]    File \"/tmp/ipykernel_10276/1693549525.py\", line 11, in forward\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 727, in _convert_frame\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     result = inner_convert(frame, cache_entry, hooks, frame_state)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 383, in _convert_frame_assert\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     compiled_product = _compile(\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]                        ^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 665, in _compile\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     raise InternalTorchDynamoError(str(e)).with_traceback(\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 646, in _compile\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 244, in time_wrapper\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     r = func(*args, **kwargs)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 562, in compile_inner\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     out_code = transform_code_object(code, transform)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1033, in transform_code_object\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     transformations(instructions, code_options)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 151, in _fn\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     return fn(*args, **kwargs)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 527, in transform\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     tracer.run()\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2128, in run\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     super().run()\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 818, in run\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     and self.step()\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]         ^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 781, in step\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     getattr(self, inst.opname)(inst)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1282, in LOAD_METHOD\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     self.LOAD_ATTR(inst)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 1303, in LOAD_ATTR\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     result = BuiltinVariable(getattr).call_function(\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 651, in call_function\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     result = handler(tx, *args, **kwargs)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py\", line 1230, in call_getattr\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     return obj.var_getattr(tx, name).clone(source=source)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/base.py\", line 258, in var_getattr\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     value = self.const_getattr(tx, name)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]   File \"/home/pranav-pc/.env/lib/python3.11/site-packages/torch/_dynamo/variables/constant.py\", line 128, in const_getattr\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     member = getattr(self.value, name)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.InternalTorchDynamoError: 'NoneType' object has no attribute 'to'\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] from user code:\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]    File \"/tmp/ipykernel_10276/1693549525.py\", line 11, in forward\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING]     return F.layer_norm(x,self.weight.shape,self.weight.to(device),self.bias.to(device),1e-5)\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-03-28 20:32:27,001] torch._dynamo.convert_frame: [WARNING] \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m----> 9\u001b[0m         logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 60\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mdrop(tok_emb \u001b[38;5;241m+\u001b[39m pos_emb)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m---> 60\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# if we are given some desired targets also calculate the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m      9\u001b[0m     device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(x,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(device),\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device),\u001b[38;5;241m1e-5\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# simple benchmarking\n",
    "torch.cuda.synchronize()\n",
    "for stage, num_steps in enumerate([10, 20]): # burnin, then benchmark\n",
    "    t0 = time.time()\n",
    "    X, Y = get_batch('train')\n",
    "    for k in range(num_steps):\n",
    "        with ctx:\n",
    "            logits, loss = model(X, Y)\n",
    "        X, Y = get_batch('train')\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossf = loss.item()\n",
    "        print(f\"{k}/{num_steps} loss: {lossf:.4f}\")\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    dt = t1-t0\n",
    "    mfu = model.estimate_mfu(batch_size * 1 * num_steps, dt)\n",
    "    if stage == 1:\n",
    "        print(f\"time per iteration: {dt/num_steps*1000:.4f}ms, MFU: {mfu*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13c46c3b-7a85-4cb8-84c8-420347034a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da31753-0313-4542-9c9d-efb1ba5d2c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
