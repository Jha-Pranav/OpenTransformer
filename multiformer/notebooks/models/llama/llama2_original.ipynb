{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f75498-78a8-411e-9eab-b1e10ac3b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit : https://github.com/meta-llama/llama/blob/main/llama/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c62a88-0ba9-47b6-980e-ef1408f06a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION : 2.2.1\n",
      "GPU  :  CUDA\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "\n",
    "print(\"TORCH VERSION :\", version(\"torch\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print('GPU  : ', device.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80db382b-659b-44e3-ac77-361ea4b0d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import sentencepiece\n",
    "\n",
    "from typing import Union, Optional\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31377f34-58a7-4c1d-99c4-f05313a0eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 4096\n",
    "    n_layers: int = 32\n",
    "    n_heads: int = 32\n",
    "    n_kv_heads: Optional[int] = None\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 2048\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a93b92-b872-4b6e-a64f-f22d28396e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # The gamma parameter\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x: torch.Tensor):\n",
    "        # (B, Seq_Len, Dim) * (B, Seq_Len, 1) = (B, Seq_Len, Dim)\n",
    "        # rsqrt: 1 / sqrt(x)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # (Dim) * (B, Seq_Len, Dim) = (B, Seq_Len, Dim)\n",
    "        return self.weight * self._norm(x.float()).type_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351c68d9-7c40-4296-8ba3-e2a4be53f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float = 10000.0):\n",
    "    # As written in the paragraph 3.2.2 of the paper\n",
    "    # >> In order to generalize our results in 2D to any xi âˆˆ Rd where **d is even**, [...]\n",
    "    assert head_dim % 2 == 0, \"Dimension must be divisible by 2\"\n",
    "    # Build the theta parameter\n",
    "    # According to the formula theta_i = 10000^(-2(i-1)/dim) for i = [1, 2, ... dim/2]\n",
    "    # Shape: (Head_Dim / 2)\n",
    "    theta_numerator = torch.arange(0, head_dim, 2).float()\n",
    "    # Shape: (Head_Dim / 2)\n",
    "    theta = 1.0 / (theta ** (theta_numerator / head_dim)).to(device) # (Dim / 2)\n",
    "    # Construct the positions (the \"m\" parameter)\n",
    "    # Shape: (Seq_Len)\n",
    "    m = torch.arange(seq_len, device=device)\n",
    "    # Multiply each theta by each position using the outer product.\n",
    "    # Shape: (Seq_Len) outer_product* (Head_Dim / 2) -> (Seq_Len, Head_Dim / 2)\n",
    "    freqs = torch.outer(m, theta).float()\n",
    "    # We can compute complex numbers in the polar form c = R * exp**(m * theta), where R = 1 as follows:\n",
    "    # (Seq_Len, Head_Dim / 2) -> (Seq_Len, Head_Dim / 2)\n",
    "    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ac11ef-8835-4de9-9e58-087106daf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotary_embeddings(x: torch.Tensor, freqs_complex: torch.Tensor, device: str):\n",
    "    # Separate the last dimension pairs of two values, representing the real and imaginary parts of the complex number\n",
    "    # Two consecutive values will become a single complex number\n",
    "    # (B, Seq_Len, H, Head_Dim) -> (B, Seq_Len, H, Head_Dim/2)\n",
    "    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "    # Reshape the freqs_complex tensor to match the shape of the x_complex tensor. So we need to add the batch dimension and the head dimension\n",
    "    # (Seq_Len, Head_Dim/2) --> (1, Seq_Len, 1, Head_Dim/2)\n",
    "    freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
    "    # Multiply each complex number in the x_complex tensor by the corresponding complex number in the freqs_complex tensor\n",
    "    # Which results in the rotation of the complex number as shown in the Figure 1 of the paper\n",
    "    # (B, Seq_Len, H, Head_Dim/2) * (1, Seq_Len, 1, Head_Dim/2) = (B, Seq_Len, H, Head_Dim/2)\n",
    "    x_rotated = x_complex * freqs_complex\n",
    "    # Convert the complex number back to the real number\n",
    "    # (B, Seq_Len, H, Head_Dim/2) -> (B, Seq_Len, H, Head_Dim/2, 2)\n",
    "    x_out = torch.view_as_real(x_rotated)\n",
    "    # (B, Seq_Len, H, Head_Dim/2, 2) -> (B, Seq_Len, H, Head_Dim)\n",
    "    x_out = x_out.reshape(*x.shape)\n",
    "    return x_out.type_as(x).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d38d91-0c34-4dcb-a4f9-edff76ae7947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(12,10,31)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c2588-7f59-411f-91d4-1768d5e7f2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
