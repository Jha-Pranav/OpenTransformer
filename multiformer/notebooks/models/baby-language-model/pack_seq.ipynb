{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3f5bdc-6bc6-4d75-8c67-a637c0090057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "BASE_URL = \"/home/pranav-pc/projects/OpenTransformer/multiformer/\"\n",
    "data = load_from_disk(\n",
    "    BASE_URL + \"data/interim/TinyStories_65>tk>1024.hf\",\n",
    ")\n",
    "\n",
    "\n",
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.histogram(data['len']);\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d9c602-8873-4df0-be6a-875543f98e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokenize.tokenizer import Tokenizer\n",
    "\n",
    "TOKENIZER_CHECKPOINT = (\n",
    "    \"/home/pranav-pc/projects/OpenTransformer/multiformer/tokenizer_checkpoints/\"\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(TOKENIZER_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47e2936-3c04-4b7a-9d4f-1472c50f0827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddcc241-980e-4d89-910d-de63aa737386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# x = torch.randint(0,109,(100,)).sort().values.tolist()\n",
    "# print(x)\n",
    "\n",
    "# bucket = []\n",
    "# start = 0\n",
    "# end = len(x) - 1\n",
    "\n",
    "# while start < end:\n",
    "#     max_seq_len = 324\n",
    "#     if x[end] >= max_seq_len:\n",
    "#         bucket.append(end)\n",
    "#     else:\n",
    "#         if x[end] + x[start] > max_seq_len:\n",
    "#             bucket.append(end)\n",
    "#         else:\n",
    "#             small_bucket = [end,start]\n",
    "#             max_seq_len -= 2\n",
    "#             while sum(x[i] for i in small_bucket) + x[start + 1] <= max_seq_len:\n",
    "#                 start += 1\n",
    "#                 max_seq_len -= 2\n",
    "#                 small_bucket.append(start)\n",
    "#             bucket.append(small_bucket)\n",
    "\n",
    "#             start += 1\n",
    "#     print(max_seq_len)\n",
    "#     end -= 1\n",
    "# if start==end:\n",
    "#     bucket.append(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0625f779-7219-442e-a540-4a7bd1459912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_seq(\n",
    "    example,\n",
    "    min_seq_len=65,\n",
    "    max_seq_len=1024,\n",
    "    delimiter_id=29889,\n",
    "    eos_id=2,\n",
    "    para_separator=13,\n",
    "    sos_id=1,\n",
    "):\n",
    "    count = example[\"len\"]\n",
    "    idx = example[\"idx\"]\n",
    "    bucket = []\n",
    "    overflow_bucket = []\n",
    "    start = 0\n",
    "    end = len(count) - 1\n",
    "\n",
    "    while start < end:\n",
    "        if count[end] >= max_seq_len:\n",
    "            index = [indx for indx, i in enumerate(idx[end][:max_seq_len]) if i == delimiter_id]\n",
    "            if len(index):\n",
    "                index = index[-1] + 1\n",
    "                trim_token = idx[end][:index] + [eos_id]\n",
    "                bucket.append(trim_token)\n",
    "                # overflow\n",
    "                overflow_token = [sos_id] + idx[end][index:]\n",
    "                if len(overflow_token) > min_seq_len:\n",
    "                    index = True  # break the while loop there is no delimiter in the text (i.e [])\n",
    "                    while (len(overflow_token) > max_seq_len) and index:\n",
    "                        index = [\n",
    "                            indx\n",
    "                            for indx, i in enumerate(overflow_token[:max_seq_len])\n",
    "                            if i == delimiter_id\n",
    "                        ]\n",
    "                        if len(index):\n",
    "                            index = index[-1] + 1\n",
    "                            trim_token = overflow_token[:index]\n",
    "                            overflow_bucket.append(trim_token)\n",
    "                            overflow_token = [sos_id] + overflow_token[index:]\n",
    "                    overflow_bucket.append(overflow_token + [eos_id])\n",
    "            else:\n",
    "                print(\"Discarding sample at index : \", end)\n",
    "\n",
    "        else:\n",
    "            if count[end] + count[start] > max_seq_len:\n",
    "                bucket.append(idx[end])\n",
    "            else:\n",
    "                small_bucket = []\n",
    "                if idx[end][-1] == eos_id:\n",
    "                    idx[end].pop()  # remove eod_id\n",
    "                if idx[start][-1] == eos_id:\n",
    "                    idx[start].pop()\n",
    "                small_bucket.extend(idx[end])\n",
    "                small_bucket.extend(\n",
    "                    [para_separator, para_separator]\n",
    "                )  # adding /n/n after each entry\n",
    "                small_bucket.extend(idx[start])\n",
    "\n",
    "                # max_seq_len -= 2\n",
    "                while (start < end) and (\n",
    "                    len(small_bucket) + count[start + 1] <= (max_seq_len - 2)\n",
    "                ):\n",
    "                    start += 1\n",
    "                    # max_seq_len -= 2\n",
    "                    small_bucket.extend([para_separator, para_separator])\n",
    "                    if idx[start][-1] == eos_id:\n",
    "                        idx[start].pop()\n",
    "                    small_bucket.extend(idx[start])\n",
    "                small_bucket.append(eos_id)\n",
    "                bucket.append(small_bucket)\n",
    "                start += 1\n",
    "        end -= 1\n",
    "    if start == end:\n",
    "        bucket.append(idx[end])\n",
    "\n",
    "    bucket = bucket + [None] * (\n",
    "        len(idx) - len(bucket)\n",
    "    )  # hf dataset lib expect map func to return same dim as input i.e len(bucket) == len(idx)\n",
    "    overflow_bucket = overflow_bucket + [None] * (len(idx) - len(overflow_bucket))\n",
    "    return {\"packed\": bucket, \"overflow\": overflow_bucket}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde4e8ce-3363-4d7f-877f-3a84d2e4197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8388a3d1f6554fdda7559a2b0be93b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2128578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda example: {\"len\": len(example[\"idx\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aeaff2-25b7-44b4-afaf-4bcf28131e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fdc874914242e08b43f556e33df9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=25):   0%|          | 0/2119253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(pack_seq, batched=True, batch_size=int(1e5), num_proc=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2adc0c-420c-4b39-b5c8-1cfe2f227f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_data = data.remove_columns([\"idx\", \"len\", \"overflow\"]).rename_column(\"packed\", \"tokens\")\n",
    "overflow_data = data.remove_columns([\"idx\", \"len\", \"packed\"]).rename_column(\"overflow\", \"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ced8bec-1caf-4d72-9f47-c3ef28a47d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7c7bd4ae59491c85f7ce92656b5e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=25):   0%|          | 0/2112144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3c2d26ecff44d8ae02d47c8fc23ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=25):   0%|          | 0/1543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "packed_data = packed_data.filter(\n",
    "    lambda x: x[\"tokens\"], num_proc=25, batched=True, batch_size=int(1e5)\n",
    ")\n",
    "overflow_data = overflow_data.filter(lambda x: x[\"tokens\"], num_proc=25, batch_size=int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f8d1db-8429-4777-b7a2-a9e5722c3bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Hey, you two!\" the big boy shouted. \"That is my spade! Give it back!\"\\n\\nTom and Mia looked up. They saw the big boy. He was bigger and meaner than them. He wanted his spade back.\\n\\nWhat do you think will happen next?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_ids(overflow_data[1500][\"tokens\"]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2993c4-d155-489a-85aa-decf47f55483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there were two friends, Sam and Jack. Sam had a big eraser and Jack wanted it. He kept demanding it from Sam but Sam refused.\n",
      "\n",
      "\"No way! It's mine,\" said Sam.\n",
      "\n",
      "\"But I want it,\" whined Jack.\n",
      "\n",
      "Sam had a silly idea. He said, \"I'll give it to you if you give me five hugs.\"\n",
      "\n",
      "Jack thought about it and then agreed. So he hugged Sam five times and then Sam gave him the eraser. After that, they both played together smiling and laughing. They had lots of fun!\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(packed_data[6100][\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f805457e-3903-45bc-8549-4117e99b91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation = load_dataset(\n",
    "    BASE_URL + \"data/downloads/TinyStories\",\n",
    "    split=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358e9c8a-83b2-4b8a-be45-4a52367bce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little boy named Timmy. Timmy loved cars and he had a blue toy car that he played with all the time. One day, Timmy's mom took him to the store to buy some things. While they were there, Timmy saw a big red car that he really wanted.\n",
      "\n",
      "\"Mommy, I want that car,\" said Timmy.\n",
      "\n",
      "\"But Timmy, we don't have enough money to buy it,\" replied his mom.\n",
      "\n",
      "Timmy was sad, but then he had an idea. He said, \"Mommy, can we speed up and get more money?\"\n",
      "\n",
      "His mom laughed and said, \"No Timmy, we can't do that. But we can save up our money and maybe one day we can buy the red car.\"\n",
      "\n",
      "Timmy was happy with his mom's answer and he went back to playing with his blue toy car.\n"
     ]
    }
   ],
   "source": [
    "print(data_validation[6150][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a7dd95-29b5-4fcf-8401-b126edb7e0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21990\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf11f326-8969-49c4-ba86-1f394bffbad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2332c27ff64d13bbdf26db3a7026a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2128578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data.map(lambda example: {\"len\": len(example[\"idx\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88e1361-7b61-421b-8c1a-ff93731fee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.piece_to_id(\"<0x0A>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fe699-ccf4-48b9-b672-0e59a0858ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
