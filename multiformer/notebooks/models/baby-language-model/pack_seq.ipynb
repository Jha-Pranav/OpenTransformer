{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3f5bdc-6bc6-4d75-8c67-a637c0090057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "BASE_URL = \"/home/pranav-pc/projects/OpenTransformer/multiformer/\"\n",
    "data = load_from_disk(\n",
    "    BASE_URL + \"data/interim/TinyStories_65>tk>1024.hf\",\n",
    ")\n",
    "\n",
    "\n",
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.histogram(data['len']);\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d9c602-8873-4df0-be6a-875543f98e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokenize.tokenizer import Tokenizer\n",
    "\n",
    "TOKENIZER_CHECKPOINT = (\n",
    "    \"/home/pranav-pc/projects/OpenTransformer/multiformer/tokenizer_checkpoints/\"\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(TOKENIZER_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47e2936-3c04-4b7a-9d4f-1472c50f0827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddcc241-980e-4d89-910d-de63aa737386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# x = torch.randint(0,109,(100,)).sort().values.tolist()\n",
    "# print(x)\n",
    "\n",
    "# bucket = []\n",
    "# start = 0\n",
    "# end = len(x) - 1\n",
    "\n",
    "# while start < end:\n",
    "#     max_seq_len = 324\n",
    "#     if x[end] >= max_seq_len:\n",
    "#         bucket.append(end)\n",
    "#     else:\n",
    "#         if x[end] + x[start] > max_seq_len:\n",
    "#             bucket.append(end)\n",
    "#         else:\n",
    "#             small_bucket = [end,start]\n",
    "#             max_seq_len -= 2\n",
    "#             while sum(x[i] for i in small_bucket) + x[start + 1] <= max_seq_len:\n",
    "#                 start += 1\n",
    "#                 max_seq_len -= 2\n",
    "#                 small_bucket.append(start)\n",
    "#             bucket.append(small_bucket)\n",
    "\n",
    "#             start += 1\n",
    "#     print(max_seq_len)\n",
    "#     end -= 1\n",
    "# if start==end:\n",
    "#     bucket.append(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0625f779-7219-442e-a540-4a7bd1459912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_seq(\n",
    "    example,\n",
    "    min_seq_len=65,\n",
    "    max_seq_len=1024,\n",
    "    delimiter_id=29889,\n",
    "    eos_id=2,\n",
    "    para_separator=13,\n",
    "    sos_id=1,\n",
    "):\n",
    "    count = example[\"len\"]\n",
    "    idx = example[\"idx\"]\n",
    "    bucket = []\n",
    "    overflow_bucket = []\n",
    "    start = 0\n",
    "    end = len(count) - 1\n",
    "\n",
    "    while start < end:\n",
    "        max_seq_len = max_seq_len\n",
    "        if count[end] >= max_seq_len:\n",
    "            index = [\n",
    "                indx\n",
    "                for indx, i in enumerate(idx[end][:max_seq_len])\n",
    "                if i == delimiter_id\n",
    "            ]\n",
    "            if len(index):\n",
    "                index = index[-1] + 1\n",
    "                trim_token = idx[end][:index] + [eos_id]\n",
    "                bucket.append(trim_token)\n",
    "                # overflow\n",
    "                overflow_token = [sos_id] + idx[end][index:]\n",
    "                if len(overflow_token) > min_seq_len:\n",
    "                    while len(overflow_token) > max_seq_len:\n",
    "                        index = [\n",
    "                            indx\n",
    "                            for indx, i in enumerate(overflow_token[:max_seq_len])\n",
    "                            if i == delimiter_id\n",
    "                        ]\n",
    "                        if len(index):\n",
    "                            index = index[-1] + 1\n",
    "                            trim_token = overflow_token[:index] + [eos_id]\n",
    "                            overflow_bucket.append(trim_token)\n",
    "                            overflow_token = [sos_id] + overflow_token[index:]\n",
    "                        else:\n",
    "                            break\n",
    "                    overflow_bucket.append(overflow_token)\n",
    "\n",
    "            else:\n",
    "                print(\"Discarding sample at index : \", end)\n",
    "\n",
    "        else:\n",
    "            if count[end] + count[start] > max_seq_len:\n",
    "                bucket.append(idx[end])\n",
    "            else:\n",
    "                small_bucket = []\n",
    "                idx[end].pop()  # remove eod_id\n",
    "                idx[start].pop()\n",
    "                small_bucket.extend(idx[end])\n",
    "                small_bucket.extend(\n",
    "                    [para_separator, para_separator]\n",
    "                )  # adding /n/n after each entry\n",
    "                small_bucket.extend(idx[start])\n",
    "\n",
    "                # max_seq_len -= 2\n",
    "                while (start < end) and (\n",
    "                    len(small_bucket) + count[start + 1] <= (max_seq_len - 2)\n",
    "                ):\n",
    "                    start += 1\n",
    "                    # max_seq_len -= 2\n",
    "                    small_bucket.extend([para_separator, para_separator])\n",
    "                    idx[start].pop()\n",
    "                    small_bucket.extend(idx[start])\n",
    "                small_bucket.append(eos_id)\n",
    "                bucket.append(small_bucket)\n",
    "\n",
    "                start += 1\n",
    "        end -= 1\n",
    "    if start == end:\n",
    "        bucket.append(idx[end])\n",
    "\n",
    "    bucket = bucket + [None] * (\n",
    "        len(idx) - len(bucket)\n",
    "    )  # hf dataset lib expect map func to return same dim as input i.e len(bucket) == len(idx)\n",
    "    overflow_bucket = overflow_bucket + [None] * (len(idx) - len(overflow_bucket))\n",
    "    return {\"packed\": bucket, \"overflow\": overflow_bucket}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde4e8ce-3363-4d7f-877f-3a84d2e4197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8388a3d1f6554fdda7559a2b0be93b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2128578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda example: {\"len\": len(example[\"idx\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aeaff2-25b7-44b4-afaf-4bcf28131e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fdc874914242e08b43f556e33df9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=25):   0%|          | 0/2119253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(pack_seq, batched=True, batch_size=int(1e5), num_proc=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2adc0c-420c-4b39-b5c8-1cfe2f227f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_data = data.remove_columns([\"idx\", \"len\", \"overflow\"]).rename_column(\n",
    "    \"packed\", \"tokens\"\n",
    ")\n",
    "overflow_data = data.remove_columns([\"idx\", \"len\", \"packed\"]).rename_column(\n",
    "    \"overflow\", \"tokens\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ced8bec-1caf-4d72-9f47-c3ef28a47d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7c7bd4ae59491c85f7ce92656b5e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=25):   0%|          | 0/2112144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3c2d26ecff44d8ae02d47c8fc23ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=25):   0%|          | 0/1543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "packed_data = packed_data.filter(\n",
    "    lambda x: x[\"tokens\"], num_proc=25, batched=True, batch_size=int(1e5)\n",
    ")\n",
    "overflow_data = overflow_data.filter(\n",
    "    lambda x: x[\"tokens\"], num_proc=25, batch_size=int(1e5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f8d1db-8429-4777-b7a2-a9e5722c3bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Hey, you two!\" the big boy shouted. \"That is my spade! Give it back!\"\\n\\nTom and Mia looked up. They saw the big boy. He was bigger and meaner than them. He wanted his spade back.\\n\\nWhat do you think will happen next?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_ids(overflow_data[1500][\"tokens\"]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2993c4-d155-489a-85aa-decf47f55483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there were two friends, Sam and Jack. Sam had a big eraser and Jack wanted it. He kept demanding it from Sam but Sam refused.\n",
      "\n",
      "\"No way! It's mine,\" said Sam.\n",
      "\n",
      "\"But I want it,\" whined Jack.\n",
      "\n",
      "Sam had a silly idea. He said, \"I'll give it to you if you give me five hugs.\"\n",
      "\n",
      "Jack thought about it and then agreed. So he hugged Sam five times and then Sam gave him the eraser. After that, they both played together smiling and laughing. They had lots of fun!\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(packed_data[6100][\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f805457e-3903-45bc-8549-4117e99b91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation = load_dataset(\n",
    "    BASE_URL + \"data/downloads/TinyStories\",\n",
    "    split=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358e9c8a-83b2-4b8a-be45-4a52367bce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little boy named Timmy. Timmy loved cars and he had a blue toy car that he played with all the time. One day, Timmy's mom took him to the store to buy some things. While they were there, Timmy saw a big red car that he really wanted.\n",
      "\n",
      "\"Mommy, I want that car,\" said Timmy.\n",
      "\n",
      "\"But Timmy, we don't have enough money to buy it,\" replied his mom.\n",
      "\n",
      "Timmy was sad, but then he had an idea. He said, \"Mommy, can we speed up and get more money?\"\n",
      "\n",
      "His mom laughed and said, \"No Timmy, we can't do that. But we can save up our money and maybe one day we can buy the red car.\"\n",
      "\n",
      "Timmy was happy with his mom's answer and he went back to playing with his blue toy car.\n"
     ]
    }
   ],
   "source": [
    "print(data_validation[6150][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a7dd95-29b5-4fcf-8401-b126edb7e0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21990\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf11f326-8969-49c4-ba86-1f394bffbad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2332c27ff64d13bbdf26db3a7026a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2128578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data.map(lambda example: {\"len\": len(example[\"idx\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f185ff-581d-4cda-969a-814b3a8c946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f02a271-58d9-4ede-9d88-d6734d2fe8cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dataset.map() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    556\u001b[0m }\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dataset.map() got an unexpected keyword argument 'shuffle'"
     ]
    }
   ],
   "source": [
    "dataset.map(\n",
    "    dummy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88e1361-7b61-421b-8c1a-ff93731fee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.piece_to_id(\"<0x0A>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fe699-ccf4-48b9-b672-0e59a0858ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
