{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447c7b80-588c-4452-8d2c-1810847e3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.weights_adapter.blm2other import _FROM_HF, blm_to_hf, hf_to_blm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89bbeb5e-8698-4452-8e04-de70bfab71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT_PATH = (\n",
    "    \"/home/pranav-pc/projects/OpenTransformer/multiformer/blm-1024/checkpoints/last.ckpt\"\n",
    ")\n",
    "model_dict = torch.load(MODEL_CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf858b8c-5d38-4bef-b923-f61ef9badbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/pranav-pc/projects/OpenTransformer/multiformer/blm-1024/checkpoints/blm2hf/pytorch_model.bin\"\n",
    "HF_WEIGHTS = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfeee7e7-78e3-4c1c-bc14-a2fdfceb59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, hf in zip(model_dict[\"state_dict\"].items(), HF_WEIGHTS.items()):\n",
    "    # print(c[0],c[1].shape,hf[0],hf[1].shape)\n",
    "    if c[1].shape != hf[1].shape:\n",
    "        print(\">>>>\", c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3509f0af-01aa-4175-bae7-96a7ae300b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c672159-2c8a-43d1-904c-b1dc47f03fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if all the weights are matching as it is\n",
    "for i in range(4):\n",
    "    for k, v in {\n",
    "        k.replace(\"{}\", str(i)): v.replace(\"{}\", str(i)) for k, v in _FROM_HF.items() if v\n",
    "    }.items():\n",
    "        if not torch.equal(HF_WEIGHTS[k], model_dict[\"state_dict\"][v]):\n",
    "            print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4c08335-43ff-48bb-81e3-154d9fe8613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> layers.0.attention.wq.weight layers.0.attention.wq.weight\n",
      ">>>> layers.0.attention.wk.weight layers.0.attention.wk.weight\n",
      ">>>> layers.1.attention.wq.weight layers.1.attention.wq.weight\n",
      ">>>> layers.1.attention.wk.weight layers.1.attention.wk.weight\n",
      ">>>> layers.2.attention.wq.weight layers.2.attention.wq.weight\n",
      ">>>> layers.2.attention.wk.weight layers.2.attention.wk.weight\n",
      ">>>> layers.3.attention.wq.weight layers.3.attention.wq.weight\n",
      ">>>> layers.3.attention.wk.weight layers.3.attention.wk.weight\n"
     ]
    }
   ],
   "source": [
    "# TODO:  reverse translation failed. let's debug this later\n",
    "for c, hf in zip(\n",
    "    model_dict[\"state_dict\"].items(),\n",
    "    hf_to_blm(HF_WEIGHTS, num_heads=12, num_kv_heads=12, dim=768).items(),\n",
    "):\n",
    "    # print(c[0],c[1].shape,hf[0],hf[1].shape)\n",
    "    if not torch.equal(c[1], hf[1]):\n",
    "        print(\">>>>\", c[0], hf[0])\n",
    "        # print(c[1])\n",
    "        # print(\"--------------\")\n",
    "        # print(hf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafc5e3-aee0-445b-8300-96a6a43ed7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
