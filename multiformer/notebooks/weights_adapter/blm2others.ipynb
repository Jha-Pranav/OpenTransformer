{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be60d3d-d06b-44e6-a836-c534a0e3149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fce681-1435-4fc2-acef-d3c3f65c81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT_PATH = (\n",
    "    \"/home/pranav-pc/projects/OpenTransformer/multiformer/blm-1024/checkpoints/last.ckpt\"\n",
    ")\n",
    "model_dict = torch.load(MODEL_CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe8c61e-cc38-4c46-8728-7362bf94a06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'hparams_name', 'hyper_parameters'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60f48a8-a802-43fb-beca-ae0c3575b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_dict['hyper_parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc12325-6901-4313-9c2c-39d1539aa890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_embd.weight\n",
      "layers.0.norms.w\n",
      "layers.0.attention.wq.weight\n",
      "layers.0.attention.wk.weight\n",
      "layers.0.attention.wv.weight\n",
      "layers.0.attention.wo.weight\n",
      "layers.0.mlp.linear1.weight\n",
      "layers.0.mlp.linear2.weight\n",
      "layers.0.mlp.linear3.weight\n",
      "layers.1.norms.w\n",
      "layers.1.attention.wq.weight\n",
      "layers.1.attention.wk.weight\n",
      "layers.1.attention.wv.weight\n",
      "layers.1.attention.wo.weight\n",
      "layers.1.mlp.linear1.weight\n",
      "layers.1.mlp.linear2.weight\n",
      "layers.1.mlp.linear3.weight\n",
      "layers.2.norms.w\n",
      "layers.2.attention.wq.weight\n",
      "layers.2.attention.wk.weight\n",
      "layers.2.attention.wv.weight\n",
      "layers.2.attention.wo.weight\n",
      "layers.2.mlp.linear1.weight\n",
      "layers.2.mlp.linear2.weight\n",
      "layers.2.mlp.linear3.weight\n",
      "layers.3.norms.w\n",
      "layers.3.attention.wq.weight\n",
      "layers.3.attention.wk.weight\n",
      "layers.3.attention.wv.weight\n",
      "layers.3.attention.wo.weight\n",
      "layers.3.mlp.linear1.weight\n",
      "layers.3.mlp.linear2.weight\n",
      "layers.3.mlp.linear3.weight\n",
      "norm.w\n",
      "output.weight\n"
     ]
    }
   ],
   "source": [
    "for key in model_dict[\"state_dict\"]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afeb9c2-ff7b-4b1b-b340-3e2b8a5e98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_FROM_HF = {\n",
    "    \"model.embed_tokens.weight\": \"tok_embd.weight\",\n",
    "    \"model.layers.{}.self_attn.q_proj.weight\": \"layers.{}.attention.wq.weight\",\n",
    "    \"model.layers.{}.self_attn.k_proj.weight\": \"layers.{}.attention.wk.weight\",\n",
    "    \"model.layers.{}.self_attn.v_proj.weight\": \"layers.{}.attention.wv.weight\",\n",
    "    \"model.layers.{}.self_attn.o_proj.weight\": \"layers.{}.attention.wo.weight\",\n",
    "    \"model.layers.{}.self_attn.rotary_emb.inv_freq\": None,\n",
    "    \"model.layers.{}.mlp.gate_proj.weight\": \"layers.{}.mlp.linear1.weight\",\n",
    "    \"model.layers.{}.mlp.up_proj.weight\": \"layers.{}.mlp.linear3.weight\",\n",
    "    \"model.layers.{}.mlp.down_proj.weight\": \"layers.{}.mlp.linear2.weight\",\n",
    "    \"model.layers.{}.input_layernorm.weight\": \"layers.{}.norms.w2\",\n",
    "    \"model.layers.{}.post_attention_layernorm.weight\": \"layers.{}.norms.w\",\n",
    "    \"model.norm.weight\": \"norm.w\",\n",
    "    \"lm_head.weight\": \"output.weight\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b9ac7b-368d-451c-9d1e-1d27a177b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "_FROM_META = {\n",
    "    \"tok_embeddings.weight\": \"tok_embd.weight\",\n",
    "    \"norm.weight\": \"norm.w\",\n",
    "    \"output.weight\": \"output.weight\",\n",
    "    \"layers.{}.attention.wk.weight\": \"layers.{}.attention.wq.weight\",\n",
    "    \"layers.{}.attention.wq.weight\": \"layers.{}.attention.wk.weight\",\n",
    "    \"layers.{}.attention.wv.weight\": \"layers.{}.attention.wv.weight\",\n",
    "    \"layers.{}.attention.wo.weight\": \"layers.{}.attention.wo.weight\",\n",
    "    \"layers.{}.attention_norm.weight\": \"layers.{}.norms.w2\",\n",
    "    \"layers.{}.ffn_norm.weight\": \"layers.{}.norms.w\",\n",
    "    \"layers.{}.feed_forward.w1.weight\": \"layers.{}.mlp.linear1.weight\",\n",
    "    \"layers.{}.feed_forward.w2.weight\": \"layers.{}.mlp.linear2.weight\",\n",
    "    \"layers.{}.feed_forward.w3.weight\": \"layers.{}.mlp.linear3.weight\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1efab83c-34f6-437b-add0-0052462ffe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mapped_key(key: str, mapping_dict: Dict[str, str]) -> str:\n",
    "    try:\n",
    "        if \"layers\" in key:\n",
    "            # Replace layer number with \"{}\" to create key for lookup\n",
    "            abstract_key = re.sub(r\"(\\.\\d+)\", \".{}\", key)\n",
    "            layer_num = re.search(r\"\\d+\", key).group(0)\n",
    "\n",
    "            new_key = mapping_dict[abstract_key]\n",
    "\n",
    "            new_key = new_key.format(layer_num)\n",
    "        else:\n",
    "            new_key = mapping_dict[key]\n",
    "    except KeyError as e:\n",
    "        raise Exception(\n",
    "            f'Error converting the state dict. Found unexpected key: \"{key}\". '\n",
    "            \"Please make sure you're loading a checkpoint with the right format. \"\n",
    "        ) from e\n",
    "\n",
    "    return new_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28164057-6838-4467-b239-c48cccc9406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blm_to_hf(\n",
    "    state_dict: Dict[str, torch.Tensor],\n",
    "    num_heads: int = 12,\n",
    "    num_kv_heads: int = 12,\n",
    "    dim: int = 768,\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        state_dict (Dict[str, torch.Tensor]): State dict in blm's format.\n",
    "        num_heads (int): Number of heads in the model.\n",
    "        num_kv_heads (int): Number of heads in the key/value projection layers.\n",
    "        dim (int): Dimension of the model.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: State dict in Meta's format.\n",
    "    \"\"\"\n",
    "    converted_state_dict = {}\n",
    "    inverted_mapping_dict = {v: k for k, v in _FROM_HF.items()}\n",
    "    head_dim = dim // num_heads\n",
    "\n",
    "    def _permute(t, n_heads):\n",
    "        return (\n",
    "            t.view(n_heads, head_dim // 2, 2, dim)\n",
    "            .transpose(1, 2)\n",
    "            .reshape((head_dim * n_heads), dim)\n",
    "        )\n",
    "\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = _get_mapped_key(key, inverted_mapping_dict)\n",
    "        if \"q_proj\" in key:\n",
    "            value = _permute(value, num_heads)\n",
    "        elif \"k_proj\" in key:\n",
    "            value = _permute(value, num_kv_heads)\n",
    "        converted_state_dict[new_key] = value\n",
    "\n",
    "    return converted_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "415f5d76-d3e0-41ab-b905-9d596c649a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_to_blm(state_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        state_dict (Dict[str, torch.Tensor]): State dict in Meta's format.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: State dict in blm's format.\n",
    "    \"\"\"\n",
    "    converted_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        if key not in [\"rope.freqs\"]:  # Skip loading the position embeddings\n",
    "            new_key = _get_mapped_key(key, _FROM_META)\n",
    "            converted_state_dict[new_key] = value\n",
    "\n",
    "    return converted_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26eacb0-10e7-40c8-83c7-ff935fbfb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_model = torch.load('/home/pranav-pc/projects/OpenTransformer/checkpoints/llama-2-7b/consolidated.00.pth')\n",
    "# llama_model = meta_to_blm(llama_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d83b7dcc-a888-46f0-92bf-49df283d0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/home/pranav-pc/projects/OpenTransformer/multiformer/blm-1024/checkpoints/llama/blm-llama-7b.pth\"\n",
    "\n",
    "# llama_model['pytorch-lightning_version'] = '2.3.0.dev20240318'\n",
    "# llama_model['hparams_name'] = 'kwargs'\n",
    "# from src.models.blm.config import ModelArgs\n",
    "# llama_model['hyper_parameters'] = {'args': ModelArgs(vocab_size=32000, embedding_dim=4096, max_seq_len=4096, embedding_dropout=0.0, rms_norm_eps=1e-05, rope_scaling=1.0, rope_theta=10000.0, attention_bias=False, attention_dropout=0.0, num_attention_heads=32, num_key_value_heads=32, use_cache=True, use_sliding_window=True, residual_dropout=0.1, mlp_hidden_size=11008, mlp_dropout=0.0, num_layers=32, device='cpu', padding_idx=2),\n",
    "#  'is_causal': True,\n",
    "#  'attn_mask': None,\n",
    "#  'lr': 0.0005,\n",
    "#  'cosine_t_max': 1000}\n",
    "# torch.save(llama_model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3feaeacc-9039-465c-bd65-8ae91a8f185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blm_to_meta(state_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        state_dict (Dict[str, torch.Tensor]): State dict in blm's format.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: State dict in Meta's format.\n",
    "    \"\"\"\n",
    "    converted_state_dict = {}\n",
    "    inverted_mapping_dict = {v: k for k, v in _FROM_META.items()}\n",
    "\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = _get_mapped_key(key, inverted_mapping_dict)\n",
    "        converted_state_dict[new_key] = value\n",
    "\n",
    "    return converted_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4c93f5-82f9-47dc-9636-681801e7ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blm_to_meta(model_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35e47916-2b9e-4ee4-988a-c35acd6a5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_to_blm(\n",
    "    state_dict: Dict[str, torch.Tensor],\n",
    "    num_heads: int = 12,\n",
    "    num_kv_heads: int = 12,\n",
    "    dim: int = 768,\n",
    "    head_dim: int = None,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        state_dict (Dict[str, torch.Tensor]): State dict in Meta's format.\n",
    "        num_heads (int): Number of heads in the model.\n",
    "        num_kv_heads (int): Number of heads in the key/value projection layers.\n",
    "        dim (int): Dimension of the model.\n",
    "        head_dim (int): Dimension of the head. If not provided, it will be calculated\n",
    "            as dim // num_heads.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: State dict in blm's format.\n",
    "    \"\"\"\n",
    "    converted_state_dict = {}\n",
    "    if head_dim is None:\n",
    "        head_dim = dim // num_heads\n",
    "\n",
    "    def _permute(t, n_heads):\n",
    "        return (\n",
    "            t.view(n_heads, 2, head_dim // 2, dim)\n",
    "            .transpose(1, 2)\n",
    "            .reshape((head_dim * n_heads), dim)\n",
    "        )\n",
    "\n",
    "    for key, value in state_dict.items():\n",
    "        if \"rotary_emb.inv_freq\" not in key:  # Skip loading the position embeddings\n",
    "            new_key = _get_mapped_key(key, _FROM_HF)\n",
    "            if \"q_proj\" in key:\n",
    "                value = _permute(value, num_heads)\n",
    "            elif \"k_proj\" in key:\n",
    "                value = _permute(value, num_kv_heads)\n",
    "            converted_state_dict[new_key] = value\n",
    "    return converted_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef8824e-eeed-4e94-962b-0d71a6c220bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.2307e-02, -5.5769e-02, -1.3177e-01,  ...,  2.2935e-01,\n",
      "         -5.4016e-02,  1.1902e-01],\n",
      "        [ 3.2817e-02,  1.1855e-04,  3.0871e-02,  ..., -4.8728e-02,\n",
      "         -4.3831e-02, -1.0355e-01],\n",
      "        [-1.2030e-03, -2.2414e-01,  5.3518e-02,  ..., -1.0539e-01,\n",
      "         -1.3322e-01, -8.1382e-02],\n",
      "        ...,\n",
      "        [-6.4690e-02,  2.9343e-02, -1.5258e-04,  ..., -5.8976e-02,\n",
      "          1.8575e-01,  4.4744e-02],\n",
      "        [ 1.7963e-01,  1.1678e-01, -5.4585e-02,  ..., -5.7763e-02,\n",
      "         -2.2228e-01,  6.4764e-02],\n",
      "        [ 7.1337e-02, -2.0702e-01,  2.8848e-02,  ...,  9.6218e-02,\n",
      "         -2.9840e-02, -1.2775e-01]], device='cuda:0') 12\n",
      "tensor([[ 0.0006, -0.1292,  0.0835,  ..., -0.1895,  0.0720, -0.1217],\n",
      "        [ 0.0056, -0.0291, -0.3082,  ...,  0.0387, -0.0865, -0.1162],\n",
      "        [-0.0627, -0.1507, -0.0728,  ...,  0.2257,  0.1081,  0.2148],\n",
      "        ...,\n",
      "        [ 0.1453,  0.0486, -0.1470,  ..., -0.0579,  0.0439,  0.0829],\n",
      "        [ 0.0662, -0.1418,  0.0414,  ..., -0.0160,  0.1373,  0.1748],\n",
      "        [ 0.1188,  0.0646, -0.3359,  ...,  0.1219, -0.0254,  0.0006]],\n",
      "       device='cuda:0') 12\n",
      "tensor([[ 0.1390, -0.1411,  0.0004,  ...,  0.2166, -0.0291, -0.1342],\n",
      "        [ 0.0057, -0.0263, -0.1326,  ..., -0.0381, -0.0341,  0.1987],\n",
      "        [-0.0964, -0.0650,  0.1598,  ..., -0.2221,  0.0157,  0.0901],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0882, -0.0193,  ..., -0.3531, -0.0884,  0.0472],\n",
      "        [-0.1676,  0.0052, -0.1263,  ...,  0.2171, -0.0755,  0.2778],\n",
      "        [ 0.0967, -0.1660, -0.1133,  ..., -0.0924, -0.2848,  0.0450]],\n",
      "       device='cuda:0') 12\n",
      "tensor([[-0.1904,  0.0781, -0.0260,  ..., -0.0074, -0.1658,  0.1359],\n",
      "        [-0.1281,  0.0373,  0.0576,  ..., -0.0533,  0.0069, -0.1535],\n",
      "        [ 0.0775, -0.0207,  0.0156,  ...,  0.2091, -0.1287,  0.0878],\n",
      "        ...,\n",
      "        [-0.1049, -0.1896, -0.2463,  ...,  0.1776,  0.2710,  0.0579],\n",
      "        [ 0.0821,  0.1606,  0.1427,  ..., -0.2233,  0.1811,  0.1808],\n",
      "        [ 0.1790, -0.2561, -0.1975,  ..., -0.3736, -0.0985, -0.0709]],\n",
      "       device='cuda:0') 12\n",
      "tensor([[ 0.0110, -0.0384,  0.1478,  ..., -0.0050, -0.0287,  0.0347],\n",
      "        [ 0.1204, -0.1248,  0.0857,  ..., -0.1175,  0.0246,  0.0074],\n",
      "        [ 0.1169,  0.0324, -0.1075,  ...,  0.0991, -0.0522,  0.0723],\n",
      "        ...,\n",
      "        [-0.0557,  0.0235,  0.1326,  ..., -0.1731,  0.1146,  0.0797],\n",
      "        [ 0.1369, -0.1856, -0.0150,  ...,  0.1018,  0.1408,  0.0055],\n",
      "        [-0.1245,  0.2008,  0.0055,  ..., -0.0573, -0.0868,  0.1566]],\n",
      "       device='cuda:0') 12\n",
      "tensor([[-0.0648, -0.0207,  0.1214,  ...,  0.1373, -0.0800,  0.1300],\n",
      "        [-0.1054,  0.0838,  0.0417,  ...,  0.0338, -0.0864, -0.1369],\n",
      "        [-0.0509, -0.0559, -0.0021,  ...,  0.0506, -0.0477,  0.0035],\n",
      "        ...,\n",
      "        [-0.0399, -0.0829,  0.0117,  ...,  0.0612,  0.1573, -0.0190],\n",
      "        [ 0.1008, -0.0611, -0.0782,  ..., -0.2823,  0.0308, -0.1728],\n",
      "        [-0.1292,  0.0757,  0.1048,  ..., -0.0037,  0.0791,  0.0942]],\n",
      "       device='cuda:0') 12\n",
      "tensor([[ 0.0722, -0.0047,  0.0783,  ..., -0.0076,  0.0008, -0.2108],\n",
      "        [ 0.0049,  0.0102,  0.0020,  ..., -0.0323, -0.0189, -0.0157],\n",
      "        [ 0.1389, -0.0908, -0.0463,  ...,  0.0377,  0.0059, -0.0395],\n",
      "        ...,\n",
      "        [ 0.0428,  0.0411,  0.1981,  ..., -0.0224, -0.1870,  0.0865],\n",
      "        [-0.1242, -0.1252,  0.0630,  ..., -0.0356, -0.1044,  0.0098],\n",
      "        [ 0.1563, -0.1354,  0.1659,  ..., -0.1444, -0.1398,  0.1767]],\n",
      "       device='cuda:0') 12\n",
      "tensor([[-0.0460, -0.0379, -0.0401,  ...,  0.0476,  0.0321,  0.0358],\n",
      "        [-0.0355,  0.0476, -0.1207,  ...,  0.0656,  0.1795, -0.0086],\n",
      "        [ 0.0821, -0.0430,  0.1778,  ..., -0.0965,  0.0581,  0.1444],\n",
      "        ...,\n",
      "        [ 0.1316,  0.0373,  0.0659,  ...,  0.0169,  0.1417, -0.0027],\n",
      "        [ 0.1209, -0.1443, -0.0909,  ...,  0.0578, -0.2439,  0.3363],\n",
      "        [-0.1147,  0.1879, -0.1689,  ..., -0.0074, -0.0727, -0.0906]],\n",
      "       device='cuda:0') 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tok_embd.weight': tensor([[-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "         [-0.0024,  0.0108, -0.0182,  ...,  0.0005, -0.0436,  0.0270],\n",
       "         [-0.0827, -0.0160, -0.0518,  ..., -0.1533, -0.0490,  0.0909],\n",
       "         ...,\n",
       "         [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0188],\n",
       "         [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "         [-0.0406, -0.0110, -0.0283,  ...,  0.0344, -0.0347, -0.0188]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.norms.w': tensor([0.1570, 0.1649, 0.1578, 0.1534, 0.1473, 0.1549, 0.1634, 0.2792, 0.1523,\n",
       "         0.1406, 0.0617, 0.1445, 0.1376, 0.1397, 0.1580, 0.1514, 0.1633, 0.1397,\n",
       "         0.1655, 0.1390, 0.1695, 0.1402, 0.1481, 0.1264, 0.1438, 0.1410, 0.1371,\n",
       "         0.2102, 0.1409, 0.1850, 0.1454, 0.1394, 0.1555, 0.1386, 0.1472, 0.1209,\n",
       "         0.2077, 0.1555, 0.1558, 0.1519, 0.1542, 0.1612, 0.1654, 0.1531, 0.1833,\n",
       "         0.1591, 0.1632, 0.1340, 0.1568, 0.1453, 0.0869, 0.1625, 0.1303, 0.1675,\n",
       "         0.1486, 0.1203, 0.1484, 0.1429, 0.1474, 0.1598, 0.1574, 0.1548, 0.1389,\n",
       "         0.1470, 0.1496, 0.1376, 0.1656, 0.1448, 0.1263, 0.1421, 0.1275, 0.1257,\n",
       "         0.1466, 0.1341, 0.1421, 0.1226, 0.1471, 0.1450, 0.0793, 0.1495, 0.1404,\n",
       "         0.1279, 0.1669, 0.1488, 0.1550, 0.1385, 0.1718, 0.1540, 0.1650, 0.1439,\n",
       "         0.1467, 0.1105, 0.1540, 0.1357, 0.1617, 0.1557, 0.1261, 0.1325, 0.1078,\n",
       "         0.1486, 0.1532, 0.1398, 0.2487, 0.1554, 0.1488, 0.1397, 0.1538, 0.0484,\n",
       "         0.1377, 0.1571, 0.1472, 0.1410, 0.1705, 0.1501, 0.1577, 0.1549, 0.1359,\n",
       "         0.1076, 0.1672, 0.1866, 0.1305, 0.1395, 0.1287, 0.1359, 0.0564, 0.1711,\n",
       "         0.1274, 0.1471, 0.1565, 0.1609, 0.1272, 0.1208, 0.1627, 0.1543, 0.1543,\n",
       "         0.1404, 0.1434, 0.1524, 0.1571, 0.1507, 0.1545, 0.1271, 0.1402, 0.1473,\n",
       "         0.1653, 0.1514, 0.1540, 0.1487, 0.1719, 0.1759, 0.1577, 0.1410, 0.1534,\n",
       "         0.1572, 0.1621, 0.1641, 0.1593, 0.1002, 0.1747, 0.1567, 0.1392, 0.1361,\n",
       "         0.1629, 0.1435, 0.1285, 0.1335, 0.1489, 0.1479, 0.2296, 0.1458, 0.0696,\n",
       "         0.1561, 0.1534, 0.1362, 0.1473, 0.1603, 0.1686, 0.1543, 0.1371, 0.1606,\n",
       "         0.1401, 0.1481, 0.1615, 0.1820, 0.1431, 0.1578, 0.1405, 0.1681, 0.1630,\n",
       "         0.1602, 0.1510, 0.1398, 0.1362, 0.1521, 0.1744, 0.1192, 0.1561, 0.1571,\n",
       "         0.1477, 0.1110, 0.1708, 0.1496, 0.1417, 0.1290, 0.1520, 0.1215, 0.1598,\n",
       "         0.1363, 0.1604, 0.1590, 0.1851, 0.1370, 0.1415, 0.1437, 0.1643, 0.1539,\n",
       "         0.1509, 0.1505, 0.1342, 0.1694, 0.1502, 0.1416, 0.2388, 0.1954, 0.1674,\n",
       "         0.1589, 0.1668, 0.1622, 0.1261, 0.1722, 0.1417, 0.1493, 0.1426, 0.1272,\n",
       "         0.1533, 0.1248, 0.1662, 0.1438, 0.1258, 0.1701, 0.1275, 0.1622, 0.1592,\n",
       "         0.1506, 0.1424, 0.1559, 0.1480, 0.1621, 0.1392, 0.1848, 0.1500, 0.1523,\n",
       "         0.1636, 0.1529, 0.1559, 0.1567, 0.1633, 0.2070, 0.1358, 0.1535, 0.1473,\n",
       "         0.1474, 0.1695, 0.1340, 0.1363, 0.1385, 0.1555, 0.1511, 0.1575, 0.1606,\n",
       "         0.1408, 0.1783, 0.1365, 0.1546, 0.1288, 0.1499, 0.1674, 0.1601, 0.1728,\n",
       "         0.1585, 0.1577, 0.1616, 0.1588, 0.1355, 0.1355, 0.1430, 0.1540, 0.1531,\n",
       "         0.1435, 0.1571, 0.1392, 0.1627, 0.1337, 0.1433, 0.1525, 0.1527, 0.1547,\n",
       "         0.1377, 0.1562, 0.1489, 0.1393, 0.1457, 0.1722, 0.1433, 0.1452, 0.1232,\n",
       "         0.1330, 0.1347, 0.1970, 0.1234, 0.1627, 0.1374, 0.1481, 0.1457, 0.1526,\n",
       "         0.1884, 0.1517, 0.1464, 0.1502, 0.1573, 0.1439, 0.1464, 0.1585, 0.1238,\n",
       "         0.1342, 0.1205, 0.1540, 0.1736, 0.1543, 0.1534, 0.1469, 0.1526, 0.1497,\n",
       "         0.1569, 0.1926, 0.1540, 0.1543, 0.1197, 0.1574, 0.1462, 0.1710, 0.1488,\n",
       "         0.1584, 0.1464, 0.1607, 0.1645, 0.1145, 0.1189, 0.1341, 0.1634, 0.1414,\n",
       "         0.1601, 0.1514, 0.1461, 0.1536, 0.1576, 0.1643, 0.1625, 0.1415, 0.1413,\n",
       "         0.1485, 0.1480, 0.1500, 0.1367, 0.1421, 0.1530, 0.1508, 0.1486, 0.1731,\n",
       "         0.1479, 0.1614, 0.1602, 0.1455, 0.1336, 0.1397, 0.1378, 0.1467, 0.1457,\n",
       "         0.1785, 0.1488, 0.1378, 0.1012, 0.1469, 0.1696, 0.1391, 0.1569, 0.1250,\n",
       "         0.1789, 0.1459, 0.1520, 0.1740, 0.1555, 0.1154, 0.1672, 0.1570, 0.1410,\n",
       "         0.1365, 0.1608, 0.1672, 0.1513, 0.0765, 0.1488, 0.1434, 0.1362, 0.1419,\n",
       "         0.1678, 0.1508, 0.1424, 0.0747, 0.0920, 0.1108, 0.1644, 0.1350, 0.1300,\n",
       "         0.1607, 0.1457, 0.1283, 0.1496, 0.1407, 0.1302, 0.1579, 0.1414, 0.1472,\n",
       "         0.1428, 0.1642, 0.1418, 0.1673, 0.1471, 0.1401, 0.3928, 0.1474, 0.2239,\n",
       "         0.1902, 0.1501, 0.1394, 0.1625, 0.1490, 0.1606, 0.1675, 0.1597, 0.1487,\n",
       "         0.1557, 0.1407, 0.2428, 0.1344, 0.1576, 0.1546, 0.1619, 0.1461, 0.1520,\n",
       "         0.1660, 0.1474, 0.1489, 0.1655, 0.1565, 0.1504, 0.1417, 0.1158, 0.1367,\n",
       "         0.1511, 0.1487, 0.1328, 0.1058, 0.1540, 0.1613, 0.1656, 0.1465, 0.1464,\n",
       "         0.1557, 0.1457, 0.1517, 0.1443, 0.1556, 0.1708, 0.1568, 0.1733, 0.1477,\n",
       "         0.1510, 0.1482, 0.1570, 0.1087, 0.1307, 0.1564, 0.1555, 0.1554, 0.1665,\n",
       "         0.1676, 0.1366, 0.3098, 0.1716, 0.1706, 0.1571, 0.1468, 0.1603, 0.1474,\n",
       "         0.1396, 0.1578, 0.1736, 0.1556, 0.1532, 0.1459, 0.1351, 0.1688, 0.1363,\n",
       "         0.1530, 0.1512, 0.1639, 0.1739, 0.1937, 0.1547, 0.1435, 0.1508, 0.1533,\n",
       "         0.1532, 0.1572, 0.1341, 0.1814, 0.1590, 0.1644, 0.1438, 0.1651, 0.1455,\n",
       "         0.1374, 0.1445, 0.1507, 0.1404, 0.1600, 0.1558, 0.1423, 0.1520, 0.1496,\n",
       "         0.1359, 0.1418, 0.1556, 0.1629, 0.1558, 0.1618, 0.1584, 0.1807, 0.1461,\n",
       "         0.1380, 0.1485, 0.1554, 0.1669, 0.1698, 0.1251, 0.1616, 0.1145, 0.1400,\n",
       "         0.1587, 0.1436, 0.1699, 0.1426, 0.2263, 0.1469, 0.1475, 0.0733, 0.1135,\n",
       "         0.1359, 0.1568, 0.1670, 0.1606, 0.1628, 0.1390, 0.1424, 0.1751, 0.1465,\n",
       "         0.1061, 0.1490, 0.1638, 0.0793, 0.1521, 0.1750, 0.1350, 0.1452, 0.1482,\n",
       "         0.1483, 0.1523, 0.1809, 0.1652, 0.1465, 0.1995, 0.1634, 0.2114, 0.1693,\n",
       "         0.1552, 0.1801, 0.0964, 0.1583, 0.1518, 0.1484, 0.1242, 0.1427, 0.1481,\n",
       "         0.0620, 0.1564, 0.1421, 0.1444, 0.1529, 0.1666, 0.1461, 0.1568, 0.1503,\n",
       "         0.1433, 0.1376, 0.1469, 0.1329, 0.1669, 0.1486, 0.1392, 0.1611, 0.2089,\n",
       "         0.1028, 0.1897, 0.1473, 0.1612, 0.1616, 0.1360, 0.1598, 0.1655, 0.1503,\n",
       "         0.1205, 0.1059, 0.1602, 0.1445, 0.1877, 0.1439, 0.1713, 0.1489, 0.1661,\n",
       "         0.1589, 0.1510, 0.1593, 0.0607, 0.1419, 0.1417, 0.1434, 0.1532, 0.1510,\n",
       "         0.1607, 0.1625, 0.1501, 0.1448, 0.1523, 0.1456, 0.1498, 0.1233, 0.1500,\n",
       "         0.1583, 0.1515, 0.1486, 0.1429, 0.1441, 0.1663, 0.1456, 0.1620, 0.1661,\n",
       "         0.1362, 0.1650, 0.1499, 0.1348, 0.1333, 0.1376, 0.0788, 0.1407, 0.1385,\n",
       "         0.1444, 0.1236, 0.1540, 0.1137, 0.0547, 0.1421, 0.1563, 0.1412, 0.1472,\n",
       "         0.1644, 0.1539, 0.1479, 0.1528, 0.1502, 0.1451, 0.1396, 0.1358, 0.1573,\n",
       "         0.1586, 0.1315, 0.1356, 0.1571, 0.1032, 0.1635, 0.1573, 0.1482, 0.1326,\n",
       "         0.1596, 0.1535, 0.1384, 0.1540, 0.1491, 0.1487, 0.1470, 0.1194, 0.1525,\n",
       "         0.1217, 0.1594, 0.1430, 0.1448, 0.1214, 0.1478, 0.1318, 0.1430, 0.1734,\n",
       "         0.2255, 0.1423, 0.1378, 0.1559, 0.1398, 0.1530, 0.1475, 0.1606, 0.1628,\n",
       "         0.1483, 0.1425, 0.1359, 0.1442, 0.1756, 0.1531, 0.1499, 0.1206, 0.1486,\n",
       "         0.1475, 0.1466, 0.1451, 0.1501, 0.1461, 0.1728, 0.1693, 0.1594, 0.1325,\n",
       "         0.1778, 0.1427, 0.0767, 0.1397, 0.1405, 0.1385, 0.1487, 0.1526, 0.1621,\n",
       "         0.1531, 0.1453, 0.1547, 0.1516, 0.1372, 0.1530, 0.1428, 0.1409, 0.1557,\n",
       "         0.1459, 0.1309, 0.1629, 0.1487, 0.1535, 0.1532, 0.1332, 0.1350, 0.1755,\n",
       "         0.1505, 0.1453, 0.1465], device='cuda:0'),\n",
       " 'layers.0.attention.wq.weight': tensor([[-5.2307e-02, -5.5769e-02, -1.3177e-01,  ...,  2.2935e-01,\n",
       "          -5.4016e-02,  1.1902e-01],\n",
       "         [ 1.9021e-01, -8.4816e-03,  3.3365e-02,  ..., -1.6482e-02,\n",
       "          -1.3845e-01, -1.4257e-01],\n",
       "         [ 3.2817e-02,  1.1855e-04,  3.0871e-02,  ..., -4.8728e-02,\n",
       "          -4.3831e-02, -1.0355e-01],\n",
       "         ...,\n",
       "         [ 1.7963e-01,  1.1678e-01, -5.4585e-02,  ..., -5.7763e-02,\n",
       "          -2.2228e-01,  6.4764e-02],\n",
       "         [-3.1973e-02, -3.6752e-02, -7.3889e-02,  ..., -1.5277e-02,\n",
       "          -1.1861e-01, -9.4777e-02],\n",
       "         [ 7.1337e-02, -2.0702e-01,  2.8848e-02,  ...,  9.6218e-02,\n",
       "          -2.9840e-02, -1.2775e-01]], device='cuda:0'),\n",
       " 'layers.0.attention.wk.weight': tensor([[ 0.0006, -0.1292,  0.0835,  ..., -0.1895,  0.0720, -0.1217],\n",
       "         [-0.0743,  0.1500,  0.0527,  ..., -0.0335, -0.0135, -0.0466],\n",
       "         [ 0.0056, -0.0291, -0.3082,  ...,  0.0387, -0.0865, -0.1162],\n",
       "         ...,\n",
       "         [ 0.0662, -0.1418,  0.0414,  ..., -0.0160,  0.1373,  0.1748],\n",
       "         [ 0.0782, -0.0971,  0.0227,  ...,  0.1437, -0.0953,  0.2023],\n",
       "         [ 0.1188,  0.0646, -0.3359,  ...,  0.1219, -0.0254,  0.0006]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.attention.wv.weight': tensor([[-0.0579, -0.1393,  0.1843,  ..., -0.1480, -0.0053,  0.1488],\n",
       "         [-0.1899, -0.0990, -0.0106,  ..., -0.1089,  0.0936,  0.1428],\n",
       "         [ 0.0740,  0.0675,  0.0707,  ..., -0.1837, -0.1718,  0.0409],\n",
       "         ...,\n",
       "         [-0.1198,  0.1662,  0.1590,  ...,  0.1460, -0.1002, -0.0185],\n",
       "         [-0.0616, -0.0752,  0.1309,  ...,  0.0089,  0.0010,  0.0256],\n",
       "         [ 0.0797, -0.0114, -0.0983,  ..., -0.0765,  0.0154, -0.1365]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.attention.wo.weight': tensor([[ 0.1466,  0.0022,  0.0365,  ...,  0.1039,  0.1192, -0.0293],\n",
       "         [-0.2208, -0.1050,  0.0068,  ...,  0.0054,  0.0104,  0.0332],\n",
       "         [-0.0068,  0.1179,  0.0631,  ...,  0.0935,  0.0745, -0.0198],\n",
       "         ...,\n",
       "         [-0.0868,  0.0450,  0.0660,  ..., -0.0938,  0.0283, -0.1204],\n",
       "         [-0.2067,  0.1453,  0.0244,  ..., -0.0800,  0.0015, -0.0023],\n",
       "         [-0.1743,  0.0218,  0.0772,  ...,  0.0145, -0.0647,  0.0795]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.mlp.linear1.weight': tensor([[ 0.0463,  0.0428, -0.0611,  ...,  0.1543, -0.1007,  0.0822],\n",
       "         [ 0.0036, -0.0542, -0.1335,  ...,  0.2278,  0.2084, -0.0972],\n",
       "         [ 0.2158, -0.1678, -0.1142,  ..., -0.0280,  0.0036, -0.1184],\n",
       "         ...,\n",
       "         [ 0.0762,  0.0098, -0.0840,  ..., -0.0320,  0.1233,  0.1713],\n",
       "         [-0.1489,  0.1182, -0.1447,  ..., -0.0983,  0.1620, -0.1003],\n",
       "         [ 0.0796,  0.1287,  0.0659,  ..., -0.0119, -0.1098,  0.0349]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.mlp.linear2.weight': tensor([[-0.0482, -0.1685, -0.0115,  ...,  0.1840, -0.0708, -0.0035],\n",
       "         [-0.1788,  0.0912, -0.0607,  ...,  0.0726,  0.2293,  0.2272],\n",
       "         [ 0.2103,  0.0572,  0.0478,  ...,  0.0556, -0.0617, -0.0632],\n",
       "         ...,\n",
       "         [ 0.0539,  0.0029, -0.0104,  ...,  0.3167,  0.0363,  0.0702],\n",
       "         [ 0.0062, -0.1024, -0.1725,  ..., -0.0316,  0.0492, -0.1754],\n",
       "         [-0.0151, -0.1473, -0.1108,  ...,  0.0243,  0.0513,  0.0362]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.mlp.linear3.weight': tensor([[-0.0573,  0.0738,  0.0055,  ...,  0.1500, -0.1777, -0.0330],\n",
       "         [ 0.1465,  0.0298,  0.1787,  ..., -0.1816, -0.1352, -0.2725],\n",
       "         [ 0.0308, -0.2491, -0.0600,  ..., -0.0421, -0.3520, -0.1553],\n",
       "         ...,\n",
       "         [-0.0705,  0.0605, -0.1933,  ..., -0.2671,  0.1019, -0.1490],\n",
       "         [ 0.0701,  0.0906, -0.0620,  ..., -0.0149, -0.0144, -0.1427],\n",
       "         [-0.1563,  0.0960, -0.0023,  ...,  0.1178,  0.0552,  0.1532]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.norms.w': tensor([0.2850, 0.3023, 0.2806, 0.2770, 0.2713, 0.2849, 0.2808, 0.2160, 0.2665,\n",
       "         0.2793, 0.1345, 0.2768, 0.2551, 0.2790, 0.2649, 0.2702, 0.2542, 0.2526,\n",
       "         0.2837, 0.2656, 0.2484, 0.2960, 0.2846, 0.2475, 0.2595, 0.2864, 0.2667,\n",
       "         0.2964, 0.2628, 0.2866, 0.3046, 0.2519, 0.2867, 0.2783, 0.2638, 0.2228,\n",
       "         0.2779, 0.2955, 0.2709, 0.2708, 0.2811, 0.2665, 0.2782, 0.2995, 0.2267,\n",
       "         0.3002, 0.2482, 0.2866, 0.2573, 0.2640, 0.2442, 0.2808, 0.2650, 0.2713,\n",
       "         0.2690, 0.2434, 0.2591, 0.2640, 0.2756, 0.2854, 0.2870, 0.2528, 0.2844,\n",
       "         0.2363, 0.2793, 0.2621, 0.2817, 0.2486, 0.2451, 0.2579, 0.2749, 0.2643,\n",
       "         0.2742, 0.2767, 0.2715, 0.2648, 0.2519, 0.2931, 0.1343, 0.2446, 0.2816,\n",
       "         0.2502, 0.2981, 0.2693, 0.2692, 0.2688, 0.2818, 0.2748, 0.2729, 0.2524,\n",
       "         0.2512, 0.2076, 0.2830, 0.2696, 0.2857, 0.2616, 0.2139, 0.2538, 0.2633,\n",
       "         0.2675, 0.2544, 0.2699, 0.3037, 0.2655, 0.2747, 0.2562, 0.2782, 0.1908,\n",
       "         0.2717, 0.2818, 0.2716, 0.2787, 0.2976, 0.2734, 0.2559, 0.2694, 0.2591,\n",
       "         0.2447, 0.2483, 0.2767, 0.2387, 0.2827, 0.2716, 0.2659, 0.0962, 0.2593,\n",
       "         0.2618, 0.3057, 0.2751, 0.2787, 0.2775, 0.2613, 0.2648, 0.2630, 0.2733,\n",
       "         0.2630, 0.2550, 0.2663, 0.2813, 0.2894, 0.2803, 0.2955, 0.3064, 0.2732,\n",
       "         0.2754, 0.2481, 0.2582, 0.2652, 0.2748, 0.2635, 0.2967, 0.2612, 0.2693,\n",
       "         0.2764, 0.2708, 0.2983, 0.2818, 0.1921, 0.2805, 0.2688, 0.2635, 0.2609,\n",
       "         0.2945, 0.2528, 0.2501, 0.2395, 0.2692, 0.2658, 0.2720, 0.2681, 0.1324,\n",
       "         0.2730, 0.2718, 0.2875, 0.2732, 0.2821, 0.2977, 0.2715, 0.2701, 0.2781,\n",
       "         0.2550, 0.2743, 0.2987, 0.2601, 0.2556, 0.2770, 0.2789, 0.2802, 0.2804,\n",
       "         0.2799, 0.2852, 0.2598, 0.2666, 0.2780, 0.2665, 0.2609, 0.2723, 0.2803,\n",
       "         0.2448, 0.1995, 0.2821, 0.2758, 0.2741, 0.2581, 0.2776, 0.2488, 0.2652,\n",
       "         0.2375, 0.2689, 0.2546, 0.2838, 0.2864, 0.2734, 0.2711, 0.2775, 0.2989,\n",
       "         0.2780, 0.2423, 0.2430, 0.2864, 0.2773, 0.2767, 0.2850, 0.2611, 0.2694,\n",
       "         0.2705, 0.2643, 0.2973, 0.2743, 0.2931, 0.2444, 0.2652, 0.2502, 0.2559,\n",
       "         0.2684, 0.2430, 0.2848, 0.2772, 0.2323, 0.2249, 0.2665, 0.2780, 0.2663,\n",
       "         0.2746, 0.2701, 0.2535, 0.2663, 0.2889, 0.2658, 0.2553, 0.2702, 0.2745,\n",
       "         0.2685, 0.2884, 0.2831, 0.2720, 0.2696, 0.2839, 0.2858, 0.2871, 0.2859,\n",
       "         0.2862, 0.2982, 0.2688, 0.2687, 0.2502, 0.2784, 0.2615, 0.2736, 0.2903,\n",
       "         0.2685, 0.2823, 0.2492, 0.2818, 0.2484, 0.2817, 0.2782, 0.2801, 0.2865,\n",
       "         0.2731, 0.2552, 0.2906, 0.2971, 0.2746, 0.2700, 0.2835, 0.2865, 0.2953,\n",
       "         0.2670, 0.2360, 0.2838, 0.2801, 0.2666, 0.2817, 0.2725, 0.2682, 0.2756,\n",
       "         0.2551, 0.2815, 0.2714, 0.2683, 0.2636, 0.2570, 0.2565, 0.2567, 0.2256,\n",
       "         0.2595, 0.2715, 0.2788, 0.2080, 0.2801, 0.2513, 0.2825, 0.2662, 0.2776,\n",
       "         0.2884, 0.2556, 0.2675, 0.2871, 0.2890, 0.2552, 0.2474, 0.2689, 0.2226,\n",
       "         0.2360, 0.2061, 0.2806, 0.2924, 0.2814, 0.2789, 0.2720, 0.2555, 0.2459,\n",
       "         0.2721, 0.2577, 0.2790, 0.2905, 0.3048, 0.2794, 0.2917, 0.2758, 0.2873,\n",
       "         0.2599, 0.2738, 0.2617, 0.2700, 0.1831, 0.1809, 0.2620, 0.2429, 0.2971,\n",
       "         0.2820, 0.2565, 0.2903, 0.2916, 0.2722, 0.2732, 0.2866, 0.2563, 0.2713,\n",
       "         0.2838, 0.2827, 0.2874, 0.2627, 0.2760, 0.2786, 0.2679, 0.2792, 0.2758,\n",
       "         0.2693, 0.2781, 0.2667, 0.2617, 0.2538, 0.2524, 0.2286, 0.2626, 0.2733,\n",
       "         0.2744, 0.2614, 0.2886, 0.2333, 0.2795, 0.2767, 0.2769, 0.2757, 0.2644,\n",
       "         0.1988, 0.2430, 0.2585, 0.2802, 0.2907, 0.2246, 0.2794, 0.2682, 0.2706,\n",
       "         0.2881, 0.2447, 0.2891, 0.2644, 0.2444, 0.2948, 0.2812, 0.2370, 0.2723,\n",
       "         0.2728, 0.2793, 0.2771, 0.1062, 0.2465, 0.2708, 0.2598, 0.2628, 0.2565,\n",
       "         0.2944, 0.2559, 0.2723, 0.2994, 0.2573, 0.2559, 0.2672, 0.2911, 0.2798,\n",
       "         0.2696, 0.2507, 0.2553, 0.3058, 0.2565, 0.2721, 0.2588, 0.2771, 0.2817,\n",
       "         0.2573, 0.2707, 0.2726, 0.2657, 0.2620, 0.2908, 0.2751, 0.2682, 0.2638,\n",
       "         0.2692, 0.2966, 0.2115, 0.2702, 0.2911, 0.2530, 0.2888, 0.2850, 0.2849,\n",
       "         0.2803, 0.2527, 0.2552, 0.2679, 0.2718, 0.2724, 0.2364, 0.2648, 0.2592,\n",
       "         0.2678, 0.2872, 0.2691, 0.1741, 0.2675, 0.2774, 0.2650, 0.2695, 0.2932,\n",
       "         0.2746, 0.2748, 0.2671, 0.2634, 0.2779, 0.2535, 0.2940, 0.2833, 0.2743,\n",
       "         0.2554, 0.2781, 0.2867, 0.1810, 0.2863, 0.2702, 0.2759, 0.2628, 0.2718,\n",
       "         0.2880, 0.2743, 0.2539, 0.2357, 0.2915, 0.2674, 0.2443, 0.2630, 0.2762,\n",
       "         0.2517, 0.2646, 0.2836, 0.2720, 0.2693, 0.2601, 0.2831, 0.2809, 0.2445,\n",
       "         0.2492, 0.2770, 0.2654, 0.2786, 0.2854, 0.2478, 0.2916, 0.3008, 0.2773,\n",
       "         0.2681, 0.2345, 0.2741, 0.2732, 0.2386, 0.2895, 0.2746, 0.2817, 0.2767,\n",
       "         0.2818, 0.2768, 0.2923, 0.3095, 0.2667, 0.2563, 0.2290, 0.2745, 0.2899,\n",
       "         0.2534, 0.2739, 0.2997, 0.2864, 0.2608, 0.2767, 0.2544, 0.2642, 0.2594,\n",
       "         0.2682, 0.2673, 0.2688, 0.2373, 0.2784, 0.2779, 0.2969, 0.2365, 0.2784,\n",
       "         0.2645, 0.2724, 0.2753, 0.2728, 0.2459, 0.2785, 0.2782, 0.1499, 0.2519,\n",
       "         0.2378, 0.2760, 0.2742, 0.2752, 0.2766, 0.2592, 0.2571, 0.2775, 0.2646,\n",
       "         0.2643, 0.2469, 0.2599, 0.1390, 0.2709, 0.2697, 0.2534, 0.2695, 0.2951,\n",
       "         0.2748, 0.2872, 0.2753, 0.2532, 0.2485, 0.2811, 0.2907, 0.2962, 0.2671,\n",
       "         0.2745, 0.2717, 0.1966, 0.2622, 0.2784, 0.2933, 0.2401, 0.2780, 0.2766,\n",
       "         0.0856, 0.2584, 0.2927, 0.2662, 0.2746, 0.2539, 0.2819, 0.2797, 0.2719,\n",
       "         0.2787, 0.2712, 0.2581, 0.2608, 0.2812, 0.2515, 0.2642, 0.3038, 0.2265,\n",
       "         0.2579, 0.2906, 0.2605, 0.2699, 0.2751, 0.2757, 0.2819, 0.2877, 0.2768,\n",
       "         0.2565, 0.2105, 0.2659, 0.2800, 0.2586, 0.2806, 0.2648, 0.2809, 0.2931,\n",
       "         0.2721, 0.2939, 0.2762, 0.1266, 0.2867, 0.2975, 0.2670, 0.2810, 0.2630,\n",
       "         0.2735, 0.2700, 0.2601, 0.2819, 0.2897, 0.2629, 0.2737, 0.2650, 0.2747,\n",
       "         0.2657, 0.2846, 0.2979, 0.2630, 0.2429, 0.2802, 0.2500, 0.2729, 0.2828,\n",
       "         0.2768, 0.2861, 0.2828, 0.2616, 0.2310, 0.2784, 0.2198, 0.2806, 0.2345,\n",
       "         0.2724, 0.2690, 0.2749, 0.2530, 0.1021, 0.2817, 0.2740, 0.2732, 0.2494,\n",
       "         0.2981, 0.2845, 0.2748, 0.2719, 0.2712, 0.2887, 0.2455, 0.2643, 0.2846,\n",
       "         0.2843, 0.2289, 0.2217, 0.2942, 0.2675, 0.2719, 0.2721, 0.2633, 0.2440,\n",
       "         0.2856, 0.2795, 0.2820, 0.2766, 0.2758, 0.2872, 0.2991, 0.2085, 0.2734,\n",
       "         0.2174, 0.2652, 0.2821, 0.2662, 0.1942, 0.2947, 0.2593, 0.2654, 0.2713,\n",
       "         0.1670, 0.2440, 0.2736, 0.2812, 0.2791, 0.2839, 0.2805, 0.2680, 0.2717,\n",
       "         0.2740, 0.2624, 0.2657, 0.2619, 0.2935, 0.2664, 0.2652, 0.2351, 0.2649,\n",
       "         0.2687, 0.2763, 0.2500, 0.2753, 0.2638, 0.2834, 0.2729, 0.2779, 0.2660,\n",
       "         0.2847, 0.2505, 0.2178, 0.2730, 0.2891, 0.2449, 0.2377, 0.2879, 0.2964,\n",
       "         0.2872, 0.2804, 0.2920, 0.2657, 0.2950, 0.2684, 0.2541, 0.2514, 0.2783,\n",
       "         0.2674, 0.2776, 0.2738, 0.2798, 0.2835, 0.2725, 0.2434, 0.2724, 0.2726,\n",
       "         0.2797, 0.2806, 0.2693], device='cuda:0'),\n",
       " 'layers.1.attention.wq.weight': tensor([[ 0.1390, -0.1411,  0.0004,  ...,  0.2166, -0.0291, -0.1342],\n",
       "         [-0.1533, -0.0355, -0.0351,  ..., -0.1690, -0.1182,  0.0401],\n",
       "         [ 0.0057, -0.0263, -0.1326,  ..., -0.0381, -0.0341,  0.1987],\n",
       "         ...,\n",
       "         [-0.1676,  0.0052, -0.1263,  ...,  0.2171, -0.0755,  0.2778],\n",
       "         [ 0.1311,  0.0446, -0.0818,  ..., -0.0289, -0.0745, -0.1116],\n",
       "         [ 0.0967, -0.1660, -0.1133,  ..., -0.0924, -0.2848,  0.0450]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.attention.wk.weight': tensor([[-0.1904,  0.0781, -0.0260,  ..., -0.0074, -0.1658,  0.1359],\n",
       "         [-0.0802,  0.1203, -0.2155,  ...,  0.2079, -0.0185, -0.1158],\n",
       "         [-0.1281,  0.0373,  0.0576,  ..., -0.0533,  0.0069, -0.1535],\n",
       "         ...,\n",
       "         [ 0.0821,  0.1606,  0.1427,  ..., -0.2233,  0.1811,  0.1808],\n",
       "         [ 0.0722, -0.1211,  0.1966,  ...,  0.0470,  0.1589,  0.0648],\n",
       "         [ 0.1790, -0.2561, -0.1975,  ..., -0.3736, -0.0985, -0.0709]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.attention.wv.weight': tensor([[-0.0717,  0.0770, -0.0991,  ...,  0.0491, -0.0862,  0.0481],\n",
       "         [-0.0431, -0.1444, -0.1412,  ...,  0.0051, -0.0497,  0.0012],\n",
       "         [-0.1839,  0.0764,  0.2220,  ..., -0.0076,  0.0298,  0.1254],\n",
       "         ...,\n",
       "         [ 0.0397, -0.0081, -0.1985,  ..., -0.1305,  0.1607, -0.0330],\n",
       "         [ 0.0062, -0.0797,  0.1006,  ...,  0.1296, -0.0172, -0.1084],\n",
       "         [ 0.1955,  0.1953, -0.0558,  ...,  0.2237, -0.1092,  0.0137]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.attention.wo.weight': tensor([[ 0.1373, -0.0884,  0.0753,  ..., -0.1109, -0.0735, -0.1243],\n",
       "         [-0.0710, -0.0559,  0.1128,  ..., -0.0860, -0.0689,  0.1237],\n",
       "         [-0.1219, -0.0910, -0.1905,  ...,  0.0503,  0.0199, -0.2239],\n",
       "         ...,\n",
       "         [-0.1278, -0.2060,  0.0073,  ...,  0.0131,  0.0392,  0.0389],\n",
       "         [ 0.0973,  0.0558, -0.1478,  ...,  0.0671,  0.0944, -0.2563],\n",
       "         [-0.2048, -0.0466, -0.0445,  ..., -0.0501, -0.0100, -0.1828]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.mlp.linear1.weight': tensor([[-0.1883,  0.2186, -0.0378,  ...,  0.1630, -0.0320,  0.1056],\n",
       "         [-0.1005,  0.0234, -0.0973,  ...,  0.0336,  0.0236,  0.0625],\n",
       "         [-0.1987,  0.2180, -0.3647,  ...,  0.2351,  0.0707, -0.1502],\n",
       "         ...,\n",
       "         [-0.2060, -0.1977,  0.1359,  ..., -0.0702,  0.0640,  0.0009],\n",
       "         [-0.1134, -0.2038, -0.1146,  ...,  0.0463, -0.1863, -0.0404],\n",
       "         [-0.1248, -0.0313, -0.0459,  ...,  0.2766, -0.0022,  0.0652]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.mlp.linear2.weight': tensor([[-0.2300, -0.1832,  0.1219,  ..., -0.1696,  0.1809, -0.0236],\n",
       "         [ 0.1215, -0.0513, -0.1755,  ...,  0.1809,  0.0510, -0.0402],\n",
       "         [ 0.0611,  0.0124,  0.0978,  ...,  0.0641,  0.0073, -0.0616],\n",
       "         ...,\n",
       "         [-0.0740,  0.0539, -0.1510,  ...,  0.1079,  0.0107,  0.0847],\n",
       "         [ 0.0589, -0.0205,  0.1125,  ..., -0.1424,  0.0640, -0.4017],\n",
       "         [ 0.0836, -0.1071, -0.1104,  ...,  0.1783, -0.1031,  0.0903]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.mlp.linear3.weight': tensor([[ 2.8169e-02,  1.3795e-01,  1.2291e-01,  ..., -1.5917e-02,\n",
       "           4.2374e-02,  7.5753e-02],\n",
       "         [-4.3080e-02,  2.7758e-03, -6.1867e-02,  ..., -1.5814e-01,\n",
       "           1.9948e-01,  8.1876e-02],\n",
       "         [-3.9830e-02,  1.6483e-01,  2.1466e-02,  ...,  1.9038e-02,\n",
       "           1.0850e-02,  6.9070e-02],\n",
       "         ...,\n",
       "         [-1.4547e-01,  3.7087e-01, -1.2494e-01,  ...,  2.5284e-01,\n",
       "          -1.9718e-01,  4.0925e-02],\n",
       "         [ 3.1494e-01, -3.9862e-01, -2.6485e-01,  ...,  6.8914e-02,\n",
       "           3.0751e-04, -2.9491e-02],\n",
       "         [ 1.8489e-02,  1.3556e-01, -6.8992e-02,  ...,  8.1240e-02,\n",
       "           1.2838e-01, -1.5892e-01]], device='cuda:0'),\n",
       " 'layers.2.norms.w': tensor([0.3518, 0.3676, 0.3597, 0.3433, 0.3411, 0.3489, 0.3537, 0.2279, 0.3508,\n",
       "         0.3320, 0.2193, 0.3603, 0.3486, 0.3446, 0.3627, 0.3496, 0.3488, 0.3270,\n",
       "         0.3341, 0.3417, 0.3232, 0.3589, 0.3529, 0.3384, 0.3328, 0.3493, 0.3684,\n",
       "         0.3746, 0.3196, 0.3640, 0.3692, 0.3440, 0.3425, 0.3166, 0.3603, 0.2676,\n",
       "         0.3713, 0.3493, 0.3461, 0.3337, 0.3444, 0.3456, 0.3401, 0.3431, 0.2688,\n",
       "         0.3528, 0.3672, 0.3399, 0.3610, 0.3236, 0.2983, 0.3549, 0.3372, 0.3399,\n",
       "         0.3640, 0.3164, 0.3444, 0.3567, 0.3464, 0.3585, 0.3389, 0.3428, 0.3551,\n",
       "         0.3445, 0.3372, 0.3317, 0.3412, 0.3303, 0.3297, 0.3298, 0.3319, 0.3386,\n",
       "         0.3593, 0.3308, 0.3532, 0.3349, 0.3306, 0.3405, 0.2189, 0.3232, 0.3668,\n",
       "         0.3093, 0.3727, 0.3453, 0.3490, 0.3541, 0.3240, 0.3468, 0.3416, 0.3362,\n",
       "         0.3510, 0.2871, 0.3451, 0.3441, 0.3521, 0.3631, 0.2884, 0.3489, 0.3512,\n",
       "         0.3709, 0.3525, 0.3454, 0.3696, 0.3539, 0.3609, 0.3139, 0.3385, 0.2819,\n",
       "         0.3650, 0.3548, 0.3400, 0.3648, 0.3650, 0.3307, 0.3296, 0.3360, 0.3465,\n",
       "         0.3408, 0.3160, 0.3530, 0.3312, 0.3367, 0.3539, 0.3421, 0.1906, 0.3471,\n",
       "         0.3197, 0.3453, 0.3565, 0.3335, 0.3420, 0.3443, 0.3425, 0.3479, 0.3357,\n",
       "         0.3239, 0.3291, 0.3335, 0.3645, 0.3668, 0.3484, 0.3590, 0.3436, 0.3422,\n",
       "         0.3460, 0.3260, 0.3458, 0.3245, 0.3424, 0.3425, 0.3553, 0.3344, 0.3376,\n",
       "         0.3488, 0.3460, 0.3740, 0.3759, 0.2967, 0.3509, 0.3545, 0.3585, 0.3376,\n",
       "         0.3687, 0.3258, 0.3374, 0.3225, 0.3321, 0.3617, 0.3547, 0.3629, 0.1720,\n",
       "         0.3730, 0.3592, 0.3414, 0.3589, 0.3550, 0.3603, 0.3506, 0.3418, 0.3469,\n",
       "         0.3402, 0.3662, 0.3697, 0.3514, 0.3463, 0.3580, 0.3502, 0.3755, 0.3256,\n",
       "         0.3326, 0.3456, 0.3242, 0.3332, 0.3423, 0.3460, 0.3359, 0.3476, 0.3408,\n",
       "         0.3354, 0.3154, 0.3600, 0.3491, 0.3346, 0.3504, 0.3600, 0.3396, 0.3518,\n",
       "         0.3280, 0.3490, 0.3454, 0.3576, 0.3634, 0.3382, 0.3407, 0.3678, 0.3660,\n",
       "         0.3501, 0.3462, 0.3423, 0.3578, 0.3547, 0.3443, 0.3516, 0.3626, 0.3565,\n",
       "         0.3395, 0.3629, 0.3479, 0.3599, 0.3593, 0.3397, 0.3538, 0.3289, 0.3355,\n",
       "         0.3545, 0.3285, 0.3813, 0.3565, 0.3297, 0.2964, 0.3473, 0.3452, 0.3501,\n",
       "         0.3514, 0.3277, 0.3479, 0.3679, 0.3552, 0.3371, 0.3469, 0.3533, 0.3378,\n",
       "         0.3495, 0.3576, 0.3471, 0.3437, 0.3498, 0.3630, 0.3659, 0.3579, 0.3702,\n",
       "         0.3530, 0.3576, 0.3433, 0.3346, 0.3157, 0.3536, 0.3378, 0.3541, 0.3617,\n",
       "         0.3462, 0.3614, 0.3191, 0.3441, 0.3125, 0.3455, 0.3472, 0.3376, 0.3469,\n",
       "         0.3689, 0.3423, 0.3851, 0.3775, 0.3604, 0.3381, 0.3483, 0.3239, 0.3556,\n",
       "         0.3474, 0.3031, 0.3432, 0.3499, 0.3386, 0.3243, 0.3441, 0.3397, 0.3567,\n",
       "         0.3306, 0.3398, 0.3616, 0.3247, 0.3470, 0.3557, 0.3189, 0.3466, 0.3271,\n",
       "         0.3286, 0.3530, 0.3538, 0.2904, 0.3554, 0.3412, 0.3364, 0.3447, 0.3446,\n",
       "         0.3682, 0.3490, 0.3501, 0.3555, 0.3269, 0.3403, 0.3430, 0.3605, 0.3050,\n",
       "         0.3033, 0.3031, 0.3588, 0.3395, 0.3525, 0.3627, 0.3403, 0.3492, 0.3217,\n",
       "         0.3564, 0.3420, 0.3412, 0.3593, 0.3576, 0.3660, 0.3362, 0.3534, 0.3521,\n",
       "         0.3279, 0.3547, 0.3522, 0.3512, 0.2485, 0.2501, 0.3300, 0.3161, 0.3726,\n",
       "         0.3515, 0.3438, 0.3606, 0.3548, 0.3587, 0.3496, 0.3519, 0.3247, 0.3250,\n",
       "         0.3564, 0.3485, 0.3630, 0.3142, 0.3496, 0.3689, 0.3275, 0.3525, 0.3568,\n",
       "         0.3592, 0.3464, 0.3553, 0.3610, 0.3597, 0.3473, 0.3174, 0.3291, 0.3502,\n",
       "         0.3547, 0.3555, 0.3566, 0.3304, 0.3570, 0.3556, 0.3420, 0.3424, 0.3266,\n",
       "         0.3016, 0.3388, 0.3446, 0.3523, 0.3433, 0.3255, 0.3537, 0.3466, 0.3196,\n",
       "         0.3360, 0.3284, 0.3558, 0.3350, 0.3149, 0.3629, 0.3248, 0.3068, 0.3398,\n",
       "         0.3361, 0.3520, 0.3572, 0.1866, 0.3164, 0.3495, 0.3512, 0.3434, 0.3499,\n",
       "         0.3725, 0.3280, 0.3416, 0.3696, 0.3311, 0.3374, 0.3537, 0.3417, 0.3458,\n",
       "         0.3436, 0.3262, 0.3233, 0.3598, 0.3362, 0.3517, 0.3542, 0.3476, 0.3477,\n",
       "         0.3480, 0.3542, 0.3467, 0.3408, 0.3476, 0.3455, 0.3565, 0.3493, 0.3499,\n",
       "         0.3393, 0.3605, 0.2359, 0.3357, 0.3540, 0.3508, 0.3501, 0.3463, 0.3563,\n",
       "         0.3469, 0.3573, 0.3325, 0.3274, 0.3395, 0.3530, 0.3379, 0.3436, 0.3258,\n",
       "         0.3532, 0.3452, 0.3500, 0.2725, 0.3440, 0.3525, 0.3345, 0.3498, 0.3596,\n",
       "         0.3553, 0.3462, 0.3521, 0.3409, 0.3554, 0.3311, 0.3660, 0.3100, 0.3516,\n",
       "         0.3110, 0.3474, 0.3522, 0.2679, 0.3671, 0.3588, 0.3225, 0.3439, 0.3670,\n",
       "         0.3547, 0.3367, 0.3345, 0.3477, 0.3666, 0.3480, 0.3261, 0.3630, 0.3377,\n",
       "         0.3107, 0.3538, 0.3569, 0.3484, 0.3535, 0.3424, 0.3524, 0.3687, 0.3340,\n",
       "         0.3507, 0.3666, 0.3452, 0.3579, 0.3634, 0.3435, 0.3724, 0.3706, 0.3608,\n",
       "         0.3342, 0.3237, 0.3604, 0.3379, 0.3272, 0.3487, 0.3578, 0.3473, 0.3516,\n",
       "         0.3415, 0.3582, 0.3535, 0.3673, 0.3404, 0.3330, 0.3076, 0.3616, 0.3461,\n",
       "         0.3241, 0.3475, 0.3733, 0.3783, 0.3475, 0.3555, 0.3551, 0.3462, 0.3532,\n",
       "         0.3337, 0.3544, 0.3463, 0.3254, 0.3547, 0.3491, 0.3538, 0.3422, 0.3513,\n",
       "         0.3626, 0.3290, 0.3595, 0.3512, 0.3454, 0.3721, 0.3545, 0.1540, 0.3278,\n",
       "         0.3264, 0.3709, 0.3588, 0.3607, 0.3469, 0.3620, 0.3182, 0.3612, 0.3307,\n",
       "         0.3279, 0.3290, 0.3332, 0.2292, 0.3372, 0.3643, 0.3407, 0.3368, 0.3580,\n",
       "         0.3584, 0.3379, 0.3711, 0.3255, 0.3515, 0.3574, 0.3570, 0.3654, 0.3512,\n",
       "         0.3412, 0.3613, 0.2837, 0.3506, 0.3490, 0.3505, 0.3374, 0.3470, 0.3778,\n",
       "         0.1257, 0.3033, 0.3547, 0.3452, 0.3566, 0.3521, 0.3458, 0.3648, 0.3622,\n",
       "         0.3595, 0.3484, 0.3347, 0.3398, 0.3423, 0.3295, 0.3569, 0.3585, 0.3118,\n",
       "         0.3422, 0.3519, 0.3321, 0.3466, 0.3599, 0.3452, 0.3543, 0.3483, 0.3482,\n",
       "         0.3323, 0.3258, 0.3499, 0.3563, 0.3427, 0.3542, 0.3347, 0.3509, 0.3682,\n",
       "         0.3584, 0.3662, 0.3274, 0.1227, 0.3599, 0.3442, 0.3476, 0.3532, 0.3564,\n",
       "         0.3621, 0.3433, 0.3566, 0.3465, 0.3477, 0.3431, 0.3678, 0.3367, 0.3635,\n",
       "         0.3547, 0.3584, 0.3655, 0.3617, 0.3250, 0.3612, 0.3257, 0.3487, 0.3468,\n",
       "         0.3483, 0.3606, 0.3606, 0.3392, 0.3349, 0.3526, 0.3039, 0.3570, 0.3072,\n",
       "         0.3674, 0.3399, 0.3464, 0.3315, 0.1760, 0.3576, 0.3463, 0.3377, 0.3428,\n",
       "         0.3561, 0.3587, 0.3566, 0.3514, 0.3462, 0.3714, 0.3192, 0.3337, 0.3475,\n",
       "         0.3657, 0.3054, 0.3183, 0.3612, 0.3431, 0.3410, 0.3559, 0.3486, 0.3064,\n",
       "         0.3347, 0.3588, 0.3665, 0.3663, 0.3484, 0.3624, 0.3502, 0.3064, 0.3492,\n",
       "         0.2967, 0.3368, 0.3398, 0.3368, 0.2664, 0.3420, 0.3501, 0.3554, 0.3591,\n",
       "         0.2331, 0.3333, 0.3575, 0.3505, 0.3691, 0.3540, 0.3318, 0.3421, 0.3377,\n",
       "         0.3481, 0.3315, 0.3423, 0.3475, 0.3513, 0.3401, 0.3398, 0.3247, 0.3436,\n",
       "         0.3522, 0.3655, 0.3417, 0.3707, 0.3768, 0.3491, 0.3500, 0.3340, 0.3369,\n",
       "         0.3570, 0.3403, 0.2978, 0.3563, 0.3354, 0.3203, 0.3410, 0.3624, 0.3637,\n",
       "         0.3541, 0.3552, 0.3799, 0.3420, 0.3468, 0.3326, 0.3368, 0.3316, 0.3646,\n",
       "         0.3384, 0.3497, 0.3461, 0.3589, 0.3590, 0.3444, 0.3354, 0.3590, 0.3545,\n",
       "         0.3446, 0.3675, 0.3417], device='cuda:0'),\n",
       " 'layers.2.attention.wq.weight': tensor([[ 0.0110, -0.0384,  0.1478,  ..., -0.0050, -0.0287,  0.0347],\n",
       "         [-0.0626,  0.0737,  0.1811,  ..., -0.1063, -0.0998, -0.0748],\n",
       "         [ 0.1204, -0.1248,  0.0857,  ..., -0.1175,  0.0246,  0.0074],\n",
       "         ...,\n",
       "         [ 0.1369, -0.1856, -0.0150,  ...,  0.1018,  0.1408,  0.0055],\n",
       "         [ 0.0574, -0.0530, -0.2000,  ...,  0.1973,  0.1104, -0.0037],\n",
       "         [-0.1245,  0.2008,  0.0055,  ..., -0.0573, -0.0868,  0.1566]],\n",
       "        device='cuda:0'),\n",
       " 'layers.2.attention.wk.weight': tensor([[-0.0648, -0.0207,  0.1214,  ...,  0.1373, -0.0800,  0.1300],\n",
       "         [ 0.0772,  0.0998,  0.0277,  ...,  0.0987,  0.0954, -0.0936],\n",
       "         [-0.1054,  0.0838,  0.0417,  ...,  0.0338, -0.0864, -0.1369],\n",
       "         ...,\n",
       "         [ 0.1008, -0.0611, -0.0782,  ..., -0.2823,  0.0308, -0.1728],\n",
       "         [ 0.1315, -0.2005, -0.3205,  ...,  0.0934, -0.0341,  0.0567],\n",
       "         [-0.1292,  0.0757,  0.1048,  ..., -0.0037,  0.0791,  0.0942]],\n",
       "        device='cuda:0'),\n",
       " 'layers.2.attention.wv.weight': tensor([[ 1.0897e-02, -9.0498e-02,  2.2373e-01,  ...,  3.6049e-01,\n",
       "          -9.9876e-02, -1.0756e-02],\n",
       "         [-4.1102e-02, -1.6898e-02,  2.1661e-01,  ..., -4.0525e-02,\n",
       "          -8.4477e-02, -9.2151e-05],\n",
       "         [-4.7211e-02,  2.6803e-02, -8.3850e-02,  ...,  1.7512e-01,\n",
       "          -9.1698e-02,  7.1176e-02],\n",
       "         ...,\n",
       "         [ 2.0098e-02, -3.7404e-01,  1.3127e-01,  ..., -4.0419e-01,\n",
       "          -2.9134e-02, -1.1611e-02],\n",
       "         [-2.3137e-02,  3.0902e-01, -1.7956e-01,  ...,  7.1167e-02,\n",
       "          -4.9178e-02, -1.0871e-02],\n",
       "         [-1.3688e-01, -8.8135e-04, -2.0948e-01,  ...,  2.1960e-01,\n",
       "          -1.4430e-02, -3.0970e-01]], device='cuda:0'),\n",
       " 'layers.2.attention.wo.weight': tensor([[-0.0657, -0.2317, -0.0383,  ...,  0.2351, -0.0264,  0.1177],\n",
       "         [ 0.0873, -0.1856, -0.0678,  ...,  0.1665, -0.1700, -0.1056],\n",
       "         [ 0.0099, -0.0973,  0.1773,  ...,  0.0411,  0.0166, -0.0575],\n",
       "         ...,\n",
       "         [-0.1179, -0.1997, -0.1489,  ...,  0.1020, -0.1261,  0.0717],\n",
       "         [ 0.0245,  0.0589, -0.0324,  ...,  0.1328, -0.0154, -0.2206],\n",
       "         [-0.1238,  0.0565, -0.0963,  ..., -0.1724,  0.1173,  0.4158]],\n",
       "        device='cuda:0'),\n",
       " 'layers.2.mlp.linear1.weight': tensor([[ 0.1750,  0.0520, -0.1616,  ..., -0.0774,  0.0702, -0.0073],\n",
       "         [ 0.1220, -0.1289,  0.1700,  ...,  0.0056, -0.0832,  0.0090],\n",
       "         [ 0.0194,  0.0837, -0.0302,  ..., -0.1318,  0.0255, -0.1849],\n",
       "         ...,\n",
       "         [ 0.1489, -0.0244, -0.0553,  ..., -0.2343,  0.1858,  0.1101],\n",
       "         [-0.1167, -0.0551, -0.0879,  ...,  0.1352, -0.0206,  0.0667],\n",
       "         [-0.0910,  0.2155,  0.1605,  ...,  0.1922, -0.0854,  0.0740]],\n",
       "        device='cuda:0'),\n",
       " 'layers.2.mlp.linear2.weight': tensor([[-0.0841,  0.1528, -0.1812,  ..., -0.0041, -0.1300, -0.1827],\n",
       "         [ 0.0352, -0.0320,  0.1980,  ..., -0.2392, -0.0829, -0.0450],\n",
       "         [ 0.0145,  0.0416,  0.0254,  ..., -0.1590, -0.1779,  0.0059],\n",
       "         ...,\n",
       "         [-0.0889,  0.0133,  0.0582,  ...,  0.0159,  0.0795, -0.0977],\n",
       "         [-0.0382,  0.1480,  0.0501,  ...,  0.0724,  0.0376, -0.0458],\n",
       "         [ 0.1823,  0.0883,  0.0020,  ..., -0.2385,  0.1661, -0.0669]],\n",
       "        device='cuda:0'),\n",
       " 'layers.2.mlp.linear3.weight': tensor([[ 2.7730e-01,  2.7336e-01, -2.0194e-01,  ...,  1.8070e-01,\n",
       "           1.4725e-01, -2.3327e-01],\n",
       "         [-2.9346e-01, -2.6627e-03,  5.7417e-02,  ...,  1.8221e-01,\n",
       "          -4.1698e-02,  2.7278e-02],\n",
       "         [ 1.0522e-01, -4.5232e-02,  1.7893e-02,  ..., -7.6254e-02,\n",
       "          -5.4964e-02,  4.3374e-02],\n",
       "         ...,\n",
       "         [ 1.1214e-01, -1.6850e-01, -8.2301e-03,  ..., -2.9580e-02,\n",
       "           3.3160e-02,  3.9649e-02],\n",
       "         [-3.3311e-01,  1.1592e-02,  2.0787e-01,  ...,  1.3691e-04,\n",
       "           6.3022e-02, -1.9400e-01],\n",
       "         [-1.1334e-01, -5.7125e-02,  6.2066e-02,  ..., -6.4543e-02,\n",
       "          -3.0105e-01, -5.7921e-02]], device='cuda:0'),\n",
       " 'layers.3.norms.w': tensor([0.3713, 0.3945, 0.3791, 0.3904, 0.3871, 0.3935, 0.3811, 0.2951, 0.3790,\n",
       "         0.3594, 0.2912, 0.3829, 0.3914, 0.3983, 0.3806, 0.3858, 0.3760, 0.3683,\n",
       "         0.3792, 0.3881, 0.3910, 0.3515, 0.3614, 0.4026, 0.3709, 0.3635, 0.3912,\n",
       "         0.4223, 0.3681, 0.3825, 0.3939, 0.3584, 0.3840, 0.3660, 0.3978, 0.3505,\n",
       "         0.3792, 0.3697, 0.3829, 0.3702, 0.3469, 0.3586, 0.3711, 0.3844, 0.3739,\n",
       "         0.3968, 0.3819, 0.3493, 0.3891, 0.3886, 0.3514, 0.3978, 0.3818, 0.3961,\n",
       "         0.3955, 0.3830, 0.3750, 0.3892, 0.3690, 0.3657, 0.3687, 0.3897, 0.3645,\n",
       "         0.3951, 0.3654, 0.3903, 0.3705, 0.3950, 0.3593, 0.3771, 0.3875, 0.3780,\n",
       "         0.3877, 0.3708, 0.3781, 0.3663, 0.3698, 0.3643, 0.2914, 0.3868, 0.3794,\n",
       "         0.3691, 0.3759, 0.3668, 0.3807, 0.3779, 0.3684, 0.3692, 0.3699, 0.3771,\n",
       "         0.3845, 0.3528, 0.3646, 0.3820, 0.3859, 0.3625, 0.3580, 0.3987, 0.3904,\n",
       "         0.3743, 0.3863, 0.3493, 0.3793, 0.3766, 0.3841, 0.3726, 0.3878, 0.4299,\n",
       "         0.3875, 0.3688, 0.3873, 0.4176, 0.3748, 0.3880, 0.3796, 0.3977, 0.3865,\n",
       "         0.3785, 0.3630, 0.3644, 0.3707, 0.3711, 0.3762, 0.3770, 0.2683, 0.3671,\n",
       "         0.3704, 0.3595, 0.3972, 0.3642, 0.3814, 0.3863, 0.3692, 0.3923, 0.3768,\n",
       "         0.3873, 0.3645, 0.3937, 0.3703, 0.3713, 0.3729, 0.3832, 0.3530, 0.3741,\n",
       "         0.3743, 0.3613, 0.3648, 0.3743, 0.3723, 0.3708, 0.3877, 0.3729, 0.3898,\n",
       "         0.3824, 0.3764, 0.3856, 0.3777, 0.3548, 0.3856, 0.3730, 0.3680, 0.3739,\n",
       "         0.3554, 0.3785, 0.3626, 0.3815, 0.3710, 0.3940, 0.3849, 0.3924, 0.2624,\n",
       "         0.3751, 0.3826, 0.3872, 0.3941, 0.3892, 0.3995, 0.3838, 0.3826, 0.3739,\n",
       "         0.3744, 0.3781, 0.3967, 0.3768, 0.3923, 0.3823, 0.3798, 0.3807, 0.3709,\n",
       "         0.3758, 0.3819, 0.3696, 0.3723, 0.3629, 0.3814, 0.3736, 0.3999, 0.4095,\n",
       "         0.3787, 0.3818, 0.3724, 0.3735, 0.3735, 0.3864, 0.3891, 0.3773, 0.3731,\n",
       "         0.3672, 0.3639, 0.3768, 0.3758, 0.3826, 0.3572, 0.3839, 0.3763, 0.3740,\n",
       "         0.3881, 0.3835, 0.3728, 0.3673, 0.3675, 0.3861, 0.3716, 0.3780, 0.3709,\n",
       "         0.3543, 0.3667, 0.3694, 0.3711, 0.3891, 0.3687, 0.3741, 0.3760, 0.3940,\n",
       "         0.3801, 0.3810, 0.4079, 0.3885, 0.3959, 0.4075, 0.3883, 0.3814, 0.3640,\n",
       "         0.3810, 0.3647, 0.3925, 0.3747, 0.3722, 0.3706, 0.4007, 0.3821, 0.3717,\n",
       "         0.3578, 0.3878, 0.3619, 0.3914, 0.3816, 0.3788, 0.3877, 0.3810, 0.3719,\n",
       "         0.3663, 0.3879, 0.3793, 0.3555, 0.3578, 0.3830, 0.4022, 0.3796, 0.3710,\n",
       "         0.3768, 0.3639, 0.3711, 0.3854, 0.3808, 0.3558, 0.3790, 0.3759, 0.3714,\n",
       "         0.3905, 0.3700, 0.3862, 0.3878, 0.3730, 0.3659, 0.3806, 0.3596, 0.3729,\n",
       "         0.3766, 0.3930, 0.3671, 0.3564, 0.3857, 0.3529, 0.3787, 0.3889, 0.3757,\n",
       "         0.3604, 0.3817, 0.3852, 0.3749, 0.3662, 0.3989, 0.3863, 0.3695, 0.3891,\n",
       "         0.3677, 0.3718, 0.3834, 0.3671, 0.3787, 0.3900, 0.3658, 0.3986, 0.3590,\n",
       "         0.3852, 0.3807, 0.3981, 0.3958, 0.3558, 0.3777, 0.3720, 0.3793, 0.3644,\n",
       "         0.3633, 0.3570, 0.3876, 0.3766, 0.3820, 0.3717, 0.3697, 0.3756, 0.3911,\n",
       "         0.3827, 0.3980, 0.3819, 0.3595, 0.4458, 0.3777, 0.3771, 0.3895, 0.3718,\n",
       "         0.3782, 0.3799, 0.3693, 0.3712, 0.3679, 0.3270, 0.3772, 0.3680, 0.3753,\n",
       "         0.3535, 0.3938, 0.3663, 0.3664, 0.3699, 0.3857, 0.3782, 0.3724, 0.3430,\n",
       "         0.4039, 0.3628, 0.3626, 0.3704, 0.3872, 0.3841, 0.3627, 0.3780, 0.3893,\n",
       "         0.3889, 0.3810, 0.3696, 0.3818, 0.3962, 0.3830, 0.3690, 0.3743, 0.3762,\n",
       "         0.3694, 0.3997, 0.3770, 0.3905, 0.3732, 0.3876, 0.3799, 0.3818, 0.3419,\n",
       "         0.3506, 0.4107, 0.3768, 0.3879, 0.3749, 0.3644, 0.3847, 0.3745, 0.3689,\n",
       "         0.3849, 0.3819, 0.3712, 0.3921, 0.3667, 0.3904, 0.3656, 0.3169, 0.3821,\n",
       "         0.3829, 0.3745, 0.3861, 0.2540, 0.3626, 0.3674, 0.3893, 0.3868, 0.4140,\n",
       "         0.3760, 0.3863, 0.3806, 0.3703, 0.3756, 0.3904, 0.3830, 0.4201, 0.3805,\n",
       "         0.3780, 0.3425, 0.3701, 0.3682, 0.3870, 0.3742, 0.3806, 0.3688, 0.3521,\n",
       "         0.3821, 0.3770, 0.3907, 0.3713, 0.3897, 0.3831, 0.3808, 0.3882, 0.4043,\n",
       "         0.3631, 0.3975, 0.2314, 0.3602, 0.3799, 0.3700, 0.3891, 0.3521, 0.3826,\n",
       "         0.3799, 0.3735, 0.3812, 0.3668, 0.3641, 0.3893, 0.3759, 0.3721, 0.3523,\n",
       "         0.3667, 0.3577, 0.3846, 0.3525, 0.3796, 0.3772, 0.3726, 0.3748, 0.3852,\n",
       "         0.3809, 0.3500, 0.3751, 0.3466, 0.3785, 0.3698, 0.3786, 0.3736, 0.3767,\n",
       "         0.3713, 0.3993, 0.3999, 0.3427, 0.3934, 0.3877, 0.3649, 0.3727, 0.3887,\n",
       "         0.3972, 0.3682, 0.3797, 0.4320, 0.3709, 0.3866, 0.3789, 0.3673, 0.3898,\n",
       "         0.3769, 0.3851, 0.3864, 0.3812, 0.3713, 0.3972, 0.3724, 0.3750, 0.3669,\n",
       "         0.3803, 0.3672, 0.3580, 0.3683, 0.3795, 0.3778, 0.3908, 0.3714, 0.3768,\n",
       "         0.3639, 0.3792, 0.3817, 0.3643, 0.3856, 0.3701, 0.3714, 0.3663, 0.3759,\n",
       "         0.3788, 0.3833, 0.3788, 0.3733, 0.3834, 0.3827, 0.3542, 0.3810, 0.3902,\n",
       "         0.3554, 0.3953, 0.3885, 0.4058, 0.3786, 0.3728, 0.3492, 0.3641, 0.3948,\n",
       "         0.3769, 0.3843, 0.3668, 0.3709, 0.3756, 0.3653, 0.3790, 0.3755, 0.3783,\n",
       "         0.3673, 0.3730, 0.3857, 0.3544, 0.3834, 0.3637, 0.3747, 0.2548, 0.3641,\n",
       "         0.3540, 0.3748, 0.3839, 0.3810, 0.3880, 0.3810, 0.3617, 0.3718, 0.3406,\n",
       "         0.3720, 0.3430, 0.3698, 0.3200, 0.3666, 0.3646, 0.3754, 0.3701, 0.3792,\n",
       "         0.3643, 0.3812, 0.3717, 0.3751, 0.3754, 0.3736, 0.3627, 0.3917, 0.3783,\n",
       "         0.3638, 0.3894, 0.3684, 0.3744, 0.3804, 0.3853, 0.3764, 0.3716, 0.3810,\n",
       "         0.1871, 0.3737, 0.3769, 0.3650, 0.3827, 0.3912, 0.3686, 0.3728, 0.3706,\n",
       "         0.3702, 0.4069, 0.3679, 0.3734, 0.3538, 0.3702, 0.3785, 0.3840, 0.3714,\n",
       "         0.3643, 0.3687, 0.3563, 0.3711, 0.3736, 0.3969, 0.3808, 0.3736, 0.3736,\n",
       "         0.3842, 0.3789, 0.3846, 0.3765, 0.3752, 0.3801, 0.3725, 0.3757, 0.4024,\n",
       "         0.3902, 0.3728, 0.3828, 0.1559, 0.4006, 0.3819, 0.3887, 0.3598, 0.3827,\n",
       "         0.3889, 0.3755, 0.3911, 0.3632, 0.3742, 0.3784, 0.3925, 0.3841, 0.3908,\n",
       "         0.3924, 0.3595, 0.3800, 0.3692, 0.3709, 0.3742, 0.3669, 0.3822, 0.3684,\n",
       "         0.3917, 0.3775, 0.3803, 0.3695, 0.3574, 0.3722, 0.3676, 0.3885, 0.3604,\n",
       "         0.3705, 0.3733, 0.3731, 0.3808, 0.2871, 0.3727, 0.3860, 0.3897, 0.3818,\n",
       "         0.3567, 0.3610, 0.3703, 0.3965, 0.3747, 0.3644, 0.3550, 0.3588, 0.3912,\n",
       "         0.3749, 0.3663, 0.3801, 0.3942, 0.3814, 0.3585, 0.3718, 0.3682, 0.3785,\n",
       "         0.3624, 0.3658, 0.4025, 0.3710, 0.3835, 0.3802, 0.3714, 0.3527, 0.3679,\n",
       "         0.3633, 0.3778, 0.3716, 0.3619, 0.3619, 0.3761, 0.3816, 0.3686, 0.3775,\n",
       "         0.2882, 0.3668, 0.3910, 0.3676, 0.3768, 0.3570, 0.3944, 0.3831, 0.3642,\n",
       "         0.3876, 0.3437, 0.3796, 0.3775, 0.3875, 0.3716, 0.3752, 0.3766, 0.3854,\n",
       "         0.3640, 0.3738, 0.3925, 0.3528, 0.3743, 0.3699, 0.3696, 0.3628, 0.3705,\n",
       "         0.3691, 0.3550, 0.4446, 0.3675, 0.3664, 0.3563, 0.3950, 0.4005, 0.3670,\n",
       "         0.3832, 0.3865, 0.3674, 0.3820, 0.3694, 0.3934, 0.3777, 0.4005, 0.3928,\n",
       "         0.3659, 0.3924, 0.3724, 0.3578, 0.3836, 0.3906, 0.3705, 0.3629, 0.3889,\n",
       "         0.3660, 0.3827, 0.3833], device='cuda:0'),\n",
       " 'layers.3.attention.wq.weight': tensor([[ 0.0722, -0.0047,  0.0783,  ..., -0.0076,  0.0008, -0.2108],\n",
       "         [-0.1393, -0.1049,  0.0255,  ..., -0.0400,  0.0974, -0.1067],\n",
       "         [ 0.0049,  0.0102,  0.0020,  ..., -0.0323, -0.0189, -0.0157],\n",
       "         ...,\n",
       "         [-0.1242, -0.1252,  0.0630,  ..., -0.0356, -0.1044,  0.0098],\n",
       "         [-0.0008,  0.0315,  0.1721,  ...,  0.0221,  0.0762,  0.1487],\n",
       "         [ 0.1563, -0.1354,  0.1659,  ..., -0.1444, -0.1398,  0.1767]],\n",
       "        device='cuda:0'),\n",
       " 'layers.3.attention.wk.weight': tensor([[-0.0460, -0.0379, -0.0401,  ...,  0.0476,  0.0321,  0.0358],\n",
       "         [-0.0743,  0.0812, -0.0165,  ..., -0.0058,  0.0371, -0.0619],\n",
       "         [-0.0355,  0.0476, -0.1207,  ...,  0.0656,  0.1795, -0.0086],\n",
       "         ...,\n",
       "         [ 0.1209, -0.1443, -0.0909,  ...,  0.0578, -0.2439,  0.3363],\n",
       "         [ 0.1200, -0.0123,  0.0733,  ...,  0.1211,  0.0237, -0.0383],\n",
       "         [-0.1147,  0.1879, -0.1689,  ..., -0.0074, -0.0727, -0.0906]],\n",
       "        device='cuda:0'),\n",
       " 'layers.3.attention.wv.weight': tensor([[-0.2427, -0.2113, -0.0253,  ..., -0.0862,  0.1536, -0.1181],\n",
       "         [ 0.2168, -0.0495,  0.0598,  ..., -0.0095,  0.0185,  0.0239],\n",
       "         [ 0.1868,  0.0171,  0.1034,  ..., -0.1902, -0.0679,  0.2683],\n",
       "         ...,\n",
       "         [-0.0154, -0.0044, -0.1579,  ...,  0.0800,  0.3382,  0.2036],\n",
       "         [ 0.3032,  0.0618,  0.0185,  ...,  0.1109,  0.1052, -0.2469],\n",
       "         [-0.1466,  0.0466, -0.0626,  ..., -0.2297,  0.4947, -0.0035]],\n",
       "        device='cuda:0'),\n",
       " 'layers.3.attention.wo.weight': tensor([[-0.2110, -0.0767,  0.0830,  ...,  0.2152,  0.1082, -0.0229],\n",
       "         [ 0.3265, -0.1967,  0.0702,  ...,  0.0594, -0.0560, -0.1756],\n",
       "         [ 0.0990,  0.0758, -0.1612,  ...,  0.3231,  0.0286, -0.1451],\n",
       "         ...,\n",
       "         [ 0.2602,  0.0765,  0.0527,  ..., -0.1468, -0.1554,  0.1721],\n",
       "         [-0.0602,  0.0849, -0.1016,  ...,  0.0579, -0.0085, -0.1748],\n",
       "         [ 0.0534,  0.1322, -0.1432,  ..., -0.0021, -0.0172, -0.1150]],\n",
       "        device='cuda:0'),\n",
       " 'layers.3.mlp.linear1.weight': tensor([[ 0.0934, -0.0842, -0.1267,  ..., -0.0886,  0.1414,  0.1329],\n",
       "         [-0.0092,  0.0080,  0.1881,  ..., -0.0357,  0.1608, -0.1541],\n",
       "         [-0.1057, -0.1517,  0.0334,  ...,  0.0348, -0.0199,  0.0779],\n",
       "         ...,\n",
       "         [-0.2029,  0.1299,  0.1227,  ..., -0.0051, -0.0906, -0.1540],\n",
       "         [ 0.0746, -0.1266,  0.0520,  ..., -0.1229, -0.3139,  0.0379],\n",
       "         [-0.0429, -0.1099,  0.1019,  ...,  0.0661, -0.0074,  0.0269]],\n",
       "        device='cuda:0'),\n",
       " 'layers.3.mlp.linear2.weight': tensor([[-0.0232,  0.0222, -0.0735,  ..., -0.1948, -0.0307, -0.0704],\n",
       "         [-0.0071,  0.0945, -0.0295,  ..., -0.0415,  0.0115, -0.0357],\n",
       "         [ 0.0509,  0.0199,  0.1576,  ...,  0.0089, -0.1033, -0.0434],\n",
       "         ...,\n",
       "         [ 0.0364,  0.0775, -0.0801,  ...,  0.0121,  0.0747,  0.0911],\n",
       "         [-0.0436, -0.1864,  0.0425,  ..., -0.1689,  0.1751,  0.1225],\n",
       "         [ 0.0765, -0.2803,  0.2194,  ...,  0.0033,  0.1204,  0.0034]],\n",
       "        device='cuda:0'),\n",
       " 'layers.3.mlp.linear3.weight': tensor([[-0.2554,  0.1462,  0.0575,  ...,  0.1379, -0.0166, -0.1563],\n",
       "         [-0.1056, -0.0730,  0.0490,  ...,  0.0955,  0.0691,  0.0593],\n",
       "         [-0.0600,  0.0618,  0.1890,  ..., -0.0995, -0.1821, -0.0936],\n",
       "         ...,\n",
       "         [ 0.2628,  0.0374, -0.0786,  ..., -0.0333,  0.1229,  0.2434],\n",
       "         [-0.0059,  0.0756,  0.0266,  ...,  0.0075, -0.1401, -0.0854],\n",
       "         [ 0.1918, -0.2848,  0.0277,  ..., -0.3538, -0.2456,  0.2765]],\n",
       "        device='cuda:0'),\n",
       " 'norm.w': tensor([1.3040, 1.4584, 1.2607, 1.5102, 1.3036, 1.3770, 1.4489, 1.1113, 1.3322,\n",
       "         1.2926, 1.3145, 1.2013, 1.3715, 1.3766, 1.3332, 1.2285, 1.4015, 1.5318,\n",
       "         1.3893, 1.4325, 1.3398, 1.2962, 1.2964, 1.8019, 1.2643, 1.3031, 1.3199,\n",
       "         3.2042, 1.1455, 1.3905, 1.1837, 1.3179, 1.2688, 1.2223, 1.3189, 1.4870,\n",
       "         1.6226, 1.3320, 1.3485, 1.3837, 1.3537, 1.2795, 1.3385, 1.3480, 1.6117,\n",
       "         1.2895, 1.3533, 1.3244, 1.4944, 1.6099, 1.0699, 1.4447, 1.3139, 2.2648,\n",
       "         1.3770, 1.6408, 1.4498, 1.3391, 1.4044, 1.3943, 1.2731, 1.3879, 1.3294,\n",
       "         1.3337, 1.3335, 1.3750, 1.4352, 1.3532, 1.2510, 1.2363, 1.2447, 1.3914,\n",
       "         1.2876, 1.3379, 1.2488, 1.3441, 1.3789, 1.3867, 1.2118, 1.3480, 1.2778,\n",
       "         1.4108, 1.3282, 1.3219, 1.3070, 1.3135, 1.4252, 1.3385, 1.3623, 1.4744,\n",
       "         1.3953, 1.4672, 1.4450, 1.2932, 1.4717, 1.2973, 1.4411, 1.3474, 1.5583,\n",
       "         1.3681, 1.2533, 1.3936, 1.4662, 1.4743, 1.2864, 1.2645, 1.4023, 0.8315,\n",
       "         1.3211, 1.1973, 1.2355, 1.2401, 1.3724, 1.3543, 1.2970, 1.4589, 1.4709,\n",
       "         1.4202, 1.4841, 1.3553, 1.3841, 1.4266, 1.2322, 1.3007, 2.0951, 1.3666,\n",
       "         1.5020, 1.3595, 1.5419, 1.3018, 1.2675, 1.2690, 1.4922, 1.3914, 1.3826,\n",
       "         1.3293, 1.3720, 1.3155, 1.3588, 1.2400, 1.2352, 1.2817, 1.3112, 1.2979,\n",
       "         1.4201, 1.4280, 1.2699, 1.3717, 1.5031, 1.4410, 1.2803, 1.4783, 1.3627,\n",
       "         1.3680, 1.3184, 1.2270, 1.4649, 1.3709, 1.4302, 1.3386, 1.4017, 1.2640,\n",
       "         1.3418, 1.3090, 1.3758, 1.3424, 1.2607, 1.3349, 1.3643, 1.2763, 0.6834,\n",
       "         1.4682, 1.3118, 1.4934, 1.3120, 1.3772, 1.3779, 1.5302, 1.3158, 1.4529,\n",
       "         1.2883, 1.2505, 1.3263, 1.4487, 1.2193, 1.3699, 1.3851, 1.3913, 1.3113,\n",
       "         1.3889, 1.2839, 1.2635, 1.4425, 1.2698, 1.3564, 1.2383, 1.3692, 2.7880,\n",
       "         1.3609, 1.5373, 1.4708, 1.3275, 1.3225, 1.2034, 1.2665, 1.5137, 1.4102,\n",
       "         1.3075, 1.3441, 1.4323, 1.4654, 1.5626, 1.2515, 1.2028, 1.4641, 1.2469,\n",
       "         1.3398, 1.1899, 1.3728, 1.4424, 1.2732, 1.5686, 1.4327, 1.4265, 1.3534,\n",
       "         1.2994, 1.1673, 1.1837, 1.4085, 1.1617, 1.3135, 1.3790, 1.4340, 1.3507,\n",
       "         1.3241, 1.2802, 1.2195, 1.3306, 1.3075, 2.4403, 1.5410, 1.3379, 1.4347,\n",
       "         1.4544, 1.2413, 1.4266, 1.3027, 1.5309, 1.5134, 1.7792, 1.2773, 1.3193,\n",
       "         1.4583, 1.3543, 1.3453, 1.3259, 1.3983, 1.5526, 1.2769, 1.2989, 1.2160,\n",
       "         1.3304, 1.3995, 1.3040, 1.4095, 1.3930, 1.3378, 1.3546, 1.2570, 1.2091,\n",
       "         1.2146, 2.0151, 1.3701, 1.6218, 1.4133, 1.3803, 1.3069, 1.3803, 1.3839,\n",
       "         1.3216, 1.3717, 1.2964, 1.4507, 1.3395, 1.6384, 1.2219, 1.3771, 1.1722,\n",
       "         1.3207, 1.5577, 1.3918, 1.3319, 1.3765, 1.3835, 1.4141, 1.4117, 1.4651,\n",
       "         1.3958, 1.3926, 1.4033, 1.3894, 1.2815, 1.3147, 1.3814, 1.1564, 1.3245,\n",
       "         1.2963, 1.3553, 2.3196, 1.2976, 1.3179, 1.2208, 1.3543, 1.3782, 1.3949,\n",
       "         1.5368, 1.3302, 1.4989, 1.1647, 1.3053, 1.3689, 1.3785, 1.3731, 1.2187,\n",
       "         1.5268, 1.3381, 1.2042, 1.2815, 1.4491, 1.3647, 1.4115, 1.2785, 1.3142,\n",
       "         1.3954, 1.5668, 1.3473, 1.3680, 2.0813, 1.3206, 1.3924, 1.5123, 1.2470,\n",
       "         1.2734, 1.4017, 1.3136, 1.4297, 2.6005, 1.1218, 1.2733, 1.4083, 1.2895,\n",
       "         1.5610, 1.3386, 1.3873, 1.3327, 1.3962, 1.3660, 1.3824, 1.2987, 1.3089,\n",
       "         1.2388, 1.2747, 1.2985, 1.3835, 1.4207, 1.3379, 1.3210, 1.3213, 1.4043,\n",
       "         1.3022, 1.4203, 1.2091, 1.4534, 1.1927, 1.3374, 1.3338, 1.2448, 1.3537,\n",
       "         1.4019, 1.3203, 1.3305, 1.6271, 1.1928, 1.4045, 1.4436, 1.4215, 1.3612,\n",
       "         1.3454, 1.4095, 1.2948, 1.2592, 1.2476, 1.3165, 1.4927, 1.4911, 1.2589,\n",
       "         1.2480, 1.3289, 1.3945, 1.3513, 0.9100, 1.3414, 1.2920, 1.4045, 1.2743,\n",
       "         1.5279, 1.2920, 1.2346, 1.0656, 1.0894, 1.3417, 1.9723, 1.3903, 1.3137,\n",
       "         1.4771, 1.4176, 1.3652, 1.5102, 1.4205, 1.3316, 1.2488, 1.3183, 1.2316,\n",
       "         1.2746, 1.3844, 1.2334, 1.2697, 1.4785, 1.2576, 1.6215, 1.3167, 2.7962,\n",
       "         1.3092, 1.3330, 1.3440, 1.5439, 1.3071, 1.4006, 1.3557, 1.2675, 1.2991,\n",
       "         1.3990, 1.2403, 0.4153, 1.2549, 1.4084, 1.2696, 1.3125, 1.2960, 1.3456,\n",
       "         1.3489, 1.3921, 1.3750, 1.2407, 1.3152, 1.2936, 1.3989, 1.3800, 1.5891,\n",
       "         1.3220, 1.1512, 1.3008, 1.4502, 1.3057, 1.4263, 1.2180, 1.3197, 1.4010,\n",
       "         1.3531, 1.2503, 1.4632, 1.2908, 1.3710, 1.4644, 1.3376, 1.5353, 1.3400,\n",
       "         1.2517, 1.2949, 1.3108, 1.2413, 1.3377, 1.2381, 1.3469, 1.3898, 1.6549,\n",
       "         1.5326, 1.3636, 1.6660, 1.9324, 1.3187, 1.2948, 1.4186, 1.4979, 1.2781,\n",
       "         1.3772, 1.2929, 1.4142, 1.1619, 1.4827, 1.3544, 1.3251, 1.3070, 1.3138,\n",
       "         1.3354, 1.2180, 1.5183, 1.4262, 1.4008, 1.9789, 1.2425, 1.4183, 1.3501,\n",
       "         1.4728, 1.4975, 1.4165, 1.4783, 1.6144, 1.4862, 1.2110, 1.4552, 1.3792,\n",
       "         1.3377, 1.3728, 1.3412, 1.2838, 1.3990, 1.3422, 1.4565, 1.4732, 1.4309,\n",
       "         1.3499, 1.3244, 1.5212, 3.0558, 1.5093, 1.2791, 1.3673, 1.4399, 1.3390,\n",
       "         1.4358, 1.4208, 1.3767, 2.0519, 1.3620, 1.1495, 1.4683, 1.2370, 1.3384,\n",
       "         1.3109, 1.3437, 1.4133, 1.2790, 2.1794, 1.3694, 1.4340, 0.7033, 1.3489,\n",
       "         1.2231, 1.1991, 1.3140, 1.2091, 1.3308, 1.6000, 1.2731, 1.4004, 1.5139,\n",
       "         1.5767, 1.3487, 1.7359, 1.2539, 1.3715, 1.3703, 1.3833, 1.4717, 1.2509,\n",
       "         1.2476, 1.3417, 1.5846, 1.1683, 1.3339, 1.4897, 1.3571, 1.3042, 1.4046,\n",
       "         1.3156, 1.4753, 1.3476, 1.4227, 1.2936, 1.5743, 1.2347, 1.3384, 1.2594,\n",
       "         0.6225, 1.2578, 1.5127, 1.2868, 1.3433, 1.3299, 1.2744, 1.3048, 1.1624,\n",
       "         1.2801, 1.2828, 1.3343, 1.2656, 1.4331, 1.2826, 1.3001, 1.3968, 2.2564,\n",
       "         1.4724, 1.5363, 1.3903, 1.3693, 1.3818, 1.2923, 1.4805, 1.3939, 1.3852,\n",
       "         1.2728, 1.3955, 1.3389, 1.3701, 1.2322, 1.3784, 1.6343, 1.3553, 1.2057,\n",
       "         1.4831, 1.2139, 1.4552, 2.1320, 1.3306, 1.3050, 1.3066, 1.3598, 1.3205,\n",
       "         1.3364, 1.3906, 1.3454, 1.3112, 1.4236, 1.3080, 1.3163, 1.4770, 1.3201,\n",
       "         1.4160, 1.2479, 1.3088, 1.5043, 1.3817, 1.3995, 1.4323, 1.3326, 1.3318,\n",
       "         1.3111, 1.4447, 1.3152, 1.5391, 1.3707, 1.3327, 1.2356, 1.3120, 1.5779,\n",
       "         1.3890, 1.3280, 1.4438, 1.2743, 1.5150, 1.3296, 1.5081, 1.4394, 1.3525,\n",
       "         1.3953, 1.2434, 1.3784, 1.3521, 1.5215, 1.3938, 1.2729, 1.3706, 1.3464,\n",
       "         1.6167, 1.4588, 1.4070, 1.3170, 1.1508, 1.3590, 1.5099, 1.5660, 1.4965,\n",
       "         1.3631, 1.4813, 1.2508, 1.3526, 1.3803, 1.2655, 1.5117, 1.3511, 1.3196,\n",
       "         1.2133, 1.3857, 1.3962, 1.3181, 1.4943, 1.3382, 1.3241, 1.4704, 1.3628,\n",
       "         1.3179, 1.6786, 1.4971, 1.3174, 1.6102, 1.2511, 1.3634, 1.3541, 1.4448,\n",
       "         1.2662, 1.3029, 1.4265, 1.3215, 1.5390, 1.3648, 1.2245, 1.4137, 1.3375,\n",
       "         1.4988, 1.4877, 1.6557, 1.3571, 1.2700, 1.4828, 1.5108, 1.3532, 1.2914,\n",
       "         1.3265, 1.2587, 1.9530, 1.3132, 1.2494, 1.3995, 1.4885, 1.3892, 1.3162,\n",
       "         1.3471, 1.2714, 1.4589, 1.2616, 1.3068, 1.4872, 1.3257, 1.8999, 1.1811,\n",
       "         1.3179, 1.2886, 1.4297, 1.4076, 1.3134, 1.1388, 1.3382, 1.4866, 1.3278,\n",
       "         1.3293, 1.1998, 1.3625], device='cuda:0'),\n",
       " 'output.weight': tensor([[-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "         [-0.0024,  0.0108, -0.0182,  ...,  0.0005, -0.0436,  0.0270],\n",
       "         [-0.0827, -0.0160, -0.0518,  ..., -0.1533, -0.0490,  0.0909],\n",
       "         ...,\n",
       "         [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0188],\n",
       "         [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "         [-0.0406, -0.0110, -0.0283,  ...,  0.0344, -0.0347, -0.0188]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.norms.w2': tensor([0.1570, 0.1649, 0.1578, 0.1534, 0.1473, 0.1549, 0.1634, 0.2792, 0.1523,\n",
       "         0.1406, 0.0617, 0.1445, 0.1376, 0.1397, 0.1580, 0.1514, 0.1633, 0.1397,\n",
       "         0.1655, 0.1390, 0.1695, 0.1402, 0.1481, 0.1264, 0.1438, 0.1410, 0.1371,\n",
       "         0.2102, 0.1409, 0.1850, 0.1454, 0.1394, 0.1555, 0.1386, 0.1472, 0.1209,\n",
       "         0.2077, 0.1555, 0.1558, 0.1519, 0.1542, 0.1612, 0.1654, 0.1531, 0.1833,\n",
       "         0.1591, 0.1632, 0.1340, 0.1568, 0.1453, 0.0869, 0.1625, 0.1303, 0.1675,\n",
       "         0.1486, 0.1203, 0.1484, 0.1429, 0.1474, 0.1598, 0.1574, 0.1548, 0.1389,\n",
       "         0.1470, 0.1496, 0.1376, 0.1656, 0.1448, 0.1263, 0.1421, 0.1275, 0.1257,\n",
       "         0.1466, 0.1341, 0.1421, 0.1226, 0.1471, 0.1450, 0.0793, 0.1495, 0.1404,\n",
       "         0.1279, 0.1669, 0.1488, 0.1550, 0.1385, 0.1718, 0.1540, 0.1650, 0.1439,\n",
       "         0.1467, 0.1105, 0.1540, 0.1357, 0.1617, 0.1557, 0.1261, 0.1325, 0.1078,\n",
       "         0.1486, 0.1532, 0.1398, 0.2487, 0.1554, 0.1488, 0.1397, 0.1538, 0.0484,\n",
       "         0.1377, 0.1571, 0.1472, 0.1410, 0.1705, 0.1501, 0.1577, 0.1549, 0.1359,\n",
       "         0.1076, 0.1672, 0.1866, 0.1305, 0.1395, 0.1287, 0.1359, 0.0564, 0.1711,\n",
       "         0.1274, 0.1471, 0.1565, 0.1609, 0.1272, 0.1208, 0.1627, 0.1543, 0.1543,\n",
       "         0.1404, 0.1434, 0.1524, 0.1571, 0.1507, 0.1545, 0.1271, 0.1402, 0.1473,\n",
       "         0.1653, 0.1514, 0.1540, 0.1487, 0.1719, 0.1759, 0.1577, 0.1410, 0.1534,\n",
       "         0.1572, 0.1621, 0.1641, 0.1593, 0.1002, 0.1747, 0.1567, 0.1392, 0.1361,\n",
       "         0.1629, 0.1435, 0.1285, 0.1335, 0.1489, 0.1479, 0.2296, 0.1458, 0.0696,\n",
       "         0.1561, 0.1534, 0.1362, 0.1473, 0.1603, 0.1686, 0.1543, 0.1371, 0.1606,\n",
       "         0.1401, 0.1481, 0.1615, 0.1820, 0.1431, 0.1578, 0.1405, 0.1681, 0.1630,\n",
       "         0.1602, 0.1510, 0.1398, 0.1362, 0.1521, 0.1744, 0.1192, 0.1561, 0.1571,\n",
       "         0.1477, 0.1110, 0.1708, 0.1496, 0.1417, 0.1290, 0.1520, 0.1215, 0.1598,\n",
       "         0.1363, 0.1604, 0.1590, 0.1851, 0.1370, 0.1415, 0.1437, 0.1643, 0.1539,\n",
       "         0.1509, 0.1505, 0.1342, 0.1694, 0.1502, 0.1416, 0.2388, 0.1954, 0.1674,\n",
       "         0.1589, 0.1668, 0.1622, 0.1261, 0.1722, 0.1417, 0.1493, 0.1426, 0.1272,\n",
       "         0.1533, 0.1248, 0.1662, 0.1438, 0.1258, 0.1701, 0.1275, 0.1622, 0.1592,\n",
       "         0.1506, 0.1424, 0.1559, 0.1480, 0.1621, 0.1392, 0.1848, 0.1500, 0.1523,\n",
       "         0.1636, 0.1529, 0.1559, 0.1567, 0.1633, 0.2070, 0.1358, 0.1535, 0.1473,\n",
       "         0.1474, 0.1695, 0.1340, 0.1363, 0.1385, 0.1555, 0.1511, 0.1575, 0.1606,\n",
       "         0.1408, 0.1783, 0.1365, 0.1546, 0.1288, 0.1499, 0.1674, 0.1601, 0.1728,\n",
       "         0.1585, 0.1577, 0.1616, 0.1588, 0.1355, 0.1355, 0.1430, 0.1540, 0.1531,\n",
       "         0.1435, 0.1571, 0.1392, 0.1627, 0.1337, 0.1433, 0.1525, 0.1527, 0.1547,\n",
       "         0.1377, 0.1562, 0.1489, 0.1393, 0.1457, 0.1722, 0.1433, 0.1452, 0.1232,\n",
       "         0.1330, 0.1347, 0.1970, 0.1234, 0.1627, 0.1374, 0.1481, 0.1457, 0.1526,\n",
       "         0.1884, 0.1517, 0.1464, 0.1502, 0.1573, 0.1439, 0.1464, 0.1585, 0.1238,\n",
       "         0.1342, 0.1205, 0.1540, 0.1736, 0.1543, 0.1534, 0.1469, 0.1526, 0.1497,\n",
       "         0.1569, 0.1926, 0.1540, 0.1543, 0.1197, 0.1574, 0.1462, 0.1710, 0.1488,\n",
       "         0.1584, 0.1464, 0.1607, 0.1645, 0.1145, 0.1189, 0.1341, 0.1634, 0.1414,\n",
       "         0.1601, 0.1514, 0.1461, 0.1536, 0.1576, 0.1643, 0.1625, 0.1415, 0.1413,\n",
       "         0.1485, 0.1480, 0.1500, 0.1367, 0.1421, 0.1530, 0.1508, 0.1486, 0.1731,\n",
       "         0.1479, 0.1614, 0.1602, 0.1455, 0.1336, 0.1397, 0.1378, 0.1467, 0.1457,\n",
       "         0.1785, 0.1488, 0.1378, 0.1012, 0.1469, 0.1696, 0.1391, 0.1569, 0.1250,\n",
       "         0.1789, 0.1459, 0.1520, 0.1740, 0.1555, 0.1154, 0.1672, 0.1570, 0.1410,\n",
       "         0.1365, 0.1608, 0.1672, 0.1513, 0.0765, 0.1488, 0.1434, 0.1362, 0.1419,\n",
       "         0.1678, 0.1508, 0.1424, 0.0747, 0.0920, 0.1108, 0.1644, 0.1350, 0.1300,\n",
       "         0.1607, 0.1457, 0.1283, 0.1496, 0.1407, 0.1302, 0.1579, 0.1414, 0.1472,\n",
       "         0.1428, 0.1642, 0.1418, 0.1673, 0.1471, 0.1401, 0.3928, 0.1474, 0.2239,\n",
       "         0.1902, 0.1501, 0.1394, 0.1625, 0.1490, 0.1606, 0.1675, 0.1597, 0.1487,\n",
       "         0.1557, 0.1407, 0.2428, 0.1344, 0.1576, 0.1546, 0.1619, 0.1461, 0.1520,\n",
       "         0.1660, 0.1474, 0.1489, 0.1655, 0.1565, 0.1504, 0.1417, 0.1158, 0.1367,\n",
       "         0.1511, 0.1487, 0.1328, 0.1058, 0.1540, 0.1613, 0.1656, 0.1465, 0.1464,\n",
       "         0.1557, 0.1457, 0.1517, 0.1443, 0.1556, 0.1708, 0.1568, 0.1733, 0.1477,\n",
       "         0.1510, 0.1482, 0.1570, 0.1087, 0.1307, 0.1564, 0.1555, 0.1554, 0.1665,\n",
       "         0.1676, 0.1366, 0.3098, 0.1716, 0.1706, 0.1571, 0.1468, 0.1603, 0.1474,\n",
       "         0.1396, 0.1578, 0.1736, 0.1556, 0.1532, 0.1459, 0.1351, 0.1688, 0.1363,\n",
       "         0.1530, 0.1512, 0.1639, 0.1739, 0.1937, 0.1547, 0.1435, 0.1508, 0.1533,\n",
       "         0.1532, 0.1572, 0.1341, 0.1814, 0.1590, 0.1644, 0.1438, 0.1651, 0.1455,\n",
       "         0.1374, 0.1445, 0.1507, 0.1404, 0.1600, 0.1558, 0.1423, 0.1520, 0.1496,\n",
       "         0.1359, 0.1418, 0.1556, 0.1629, 0.1558, 0.1618, 0.1584, 0.1807, 0.1461,\n",
       "         0.1380, 0.1485, 0.1554, 0.1669, 0.1698, 0.1251, 0.1616, 0.1145, 0.1400,\n",
       "         0.1587, 0.1436, 0.1699, 0.1426, 0.2263, 0.1469, 0.1475, 0.0733, 0.1135,\n",
       "         0.1359, 0.1568, 0.1670, 0.1606, 0.1628, 0.1390, 0.1424, 0.1751, 0.1465,\n",
       "         0.1061, 0.1490, 0.1638, 0.0793, 0.1521, 0.1750, 0.1350, 0.1452, 0.1482,\n",
       "         0.1483, 0.1523, 0.1809, 0.1652, 0.1465, 0.1995, 0.1634, 0.2114, 0.1693,\n",
       "         0.1552, 0.1801, 0.0964, 0.1583, 0.1518, 0.1484, 0.1242, 0.1427, 0.1481,\n",
       "         0.0620, 0.1564, 0.1421, 0.1444, 0.1529, 0.1666, 0.1461, 0.1568, 0.1503,\n",
       "         0.1433, 0.1376, 0.1469, 0.1329, 0.1669, 0.1486, 0.1392, 0.1611, 0.2089,\n",
       "         0.1028, 0.1897, 0.1473, 0.1612, 0.1616, 0.1360, 0.1598, 0.1655, 0.1503,\n",
       "         0.1205, 0.1059, 0.1602, 0.1445, 0.1877, 0.1439, 0.1713, 0.1489, 0.1661,\n",
       "         0.1589, 0.1510, 0.1593, 0.0607, 0.1419, 0.1417, 0.1434, 0.1532, 0.1510,\n",
       "         0.1607, 0.1625, 0.1501, 0.1448, 0.1523, 0.1456, 0.1498, 0.1233, 0.1500,\n",
       "         0.1583, 0.1515, 0.1486, 0.1429, 0.1441, 0.1663, 0.1456, 0.1620, 0.1661,\n",
       "         0.1362, 0.1650, 0.1499, 0.1348, 0.1333, 0.1376, 0.0788, 0.1407, 0.1385,\n",
       "         0.1444, 0.1236, 0.1540, 0.1137, 0.0547, 0.1421, 0.1563, 0.1412, 0.1472,\n",
       "         0.1644, 0.1539, 0.1479, 0.1528, 0.1502, 0.1451, 0.1396, 0.1358, 0.1573,\n",
       "         0.1586, 0.1315, 0.1356, 0.1571, 0.1032, 0.1635, 0.1573, 0.1482, 0.1326,\n",
       "         0.1596, 0.1535, 0.1384, 0.1540, 0.1491, 0.1487, 0.1470, 0.1194, 0.1525,\n",
       "         0.1217, 0.1594, 0.1430, 0.1448, 0.1214, 0.1478, 0.1318, 0.1430, 0.1734,\n",
       "         0.2255, 0.1423, 0.1378, 0.1559, 0.1398, 0.1530, 0.1475, 0.1606, 0.1628,\n",
       "         0.1483, 0.1425, 0.1359, 0.1442, 0.1756, 0.1531, 0.1499, 0.1206, 0.1486,\n",
       "         0.1475, 0.1466, 0.1451, 0.1501, 0.1461, 0.1728, 0.1693, 0.1594, 0.1325,\n",
       "         0.1778, 0.1427, 0.0767, 0.1397, 0.1405, 0.1385, 0.1487, 0.1526, 0.1621,\n",
       "         0.1531, 0.1453, 0.1547, 0.1516, 0.1372, 0.1530, 0.1428, 0.1409, 0.1557,\n",
       "         0.1459, 0.1309, 0.1629, 0.1487, 0.1535, 0.1532, 0.1332, 0.1350, 0.1755,\n",
       "         0.1505, 0.1453, 0.1465], device='cuda:0'),\n",
       " 'layers.1.norms.w2': tensor([0.2850, 0.3023, 0.2806, 0.2770, 0.2713, 0.2849, 0.2808, 0.2160, 0.2665,\n",
       "         0.2793, 0.1345, 0.2768, 0.2551, 0.2790, 0.2649, 0.2702, 0.2542, 0.2526,\n",
       "         0.2837, 0.2656, 0.2484, 0.2960, 0.2846, 0.2475, 0.2595, 0.2864, 0.2667,\n",
       "         0.2964, 0.2628, 0.2866, 0.3046, 0.2519, 0.2867, 0.2783, 0.2638, 0.2228,\n",
       "         0.2779, 0.2955, 0.2709, 0.2708, 0.2811, 0.2665, 0.2782, 0.2995, 0.2267,\n",
       "         0.3002, 0.2482, 0.2866, 0.2573, 0.2640, 0.2442, 0.2808, 0.2650, 0.2713,\n",
       "         0.2690, 0.2434, 0.2591, 0.2640, 0.2756, 0.2854, 0.2870, 0.2528, 0.2844,\n",
       "         0.2363, 0.2793, 0.2621, 0.2817, 0.2486, 0.2451, 0.2579, 0.2749, 0.2643,\n",
       "         0.2742, 0.2767, 0.2715, 0.2648, 0.2519, 0.2931, 0.1343, 0.2446, 0.2816,\n",
       "         0.2502, 0.2981, 0.2693, 0.2692, 0.2688, 0.2818, 0.2748, 0.2729, 0.2524,\n",
       "         0.2512, 0.2076, 0.2830, 0.2696, 0.2857, 0.2616, 0.2139, 0.2538, 0.2633,\n",
       "         0.2675, 0.2544, 0.2699, 0.3037, 0.2655, 0.2747, 0.2562, 0.2782, 0.1908,\n",
       "         0.2717, 0.2818, 0.2716, 0.2787, 0.2976, 0.2734, 0.2559, 0.2694, 0.2591,\n",
       "         0.2447, 0.2483, 0.2767, 0.2387, 0.2827, 0.2716, 0.2659, 0.0962, 0.2593,\n",
       "         0.2618, 0.3057, 0.2751, 0.2787, 0.2775, 0.2613, 0.2648, 0.2630, 0.2733,\n",
       "         0.2630, 0.2550, 0.2663, 0.2813, 0.2894, 0.2803, 0.2955, 0.3064, 0.2732,\n",
       "         0.2754, 0.2481, 0.2582, 0.2652, 0.2748, 0.2635, 0.2967, 0.2612, 0.2693,\n",
       "         0.2764, 0.2708, 0.2983, 0.2818, 0.1921, 0.2805, 0.2688, 0.2635, 0.2609,\n",
       "         0.2945, 0.2528, 0.2501, 0.2395, 0.2692, 0.2658, 0.2720, 0.2681, 0.1324,\n",
       "         0.2730, 0.2718, 0.2875, 0.2732, 0.2821, 0.2977, 0.2715, 0.2701, 0.2781,\n",
       "         0.2550, 0.2743, 0.2987, 0.2601, 0.2556, 0.2770, 0.2789, 0.2802, 0.2804,\n",
       "         0.2799, 0.2852, 0.2598, 0.2666, 0.2780, 0.2665, 0.2609, 0.2723, 0.2803,\n",
       "         0.2448, 0.1995, 0.2821, 0.2758, 0.2741, 0.2581, 0.2776, 0.2488, 0.2652,\n",
       "         0.2375, 0.2689, 0.2546, 0.2838, 0.2864, 0.2734, 0.2711, 0.2775, 0.2989,\n",
       "         0.2780, 0.2423, 0.2430, 0.2864, 0.2773, 0.2767, 0.2850, 0.2611, 0.2694,\n",
       "         0.2705, 0.2643, 0.2973, 0.2743, 0.2931, 0.2444, 0.2652, 0.2502, 0.2559,\n",
       "         0.2684, 0.2430, 0.2848, 0.2772, 0.2323, 0.2249, 0.2665, 0.2780, 0.2663,\n",
       "         0.2746, 0.2701, 0.2535, 0.2663, 0.2889, 0.2658, 0.2553, 0.2702, 0.2745,\n",
       "         0.2685, 0.2884, 0.2831, 0.2720, 0.2696, 0.2839, 0.2858, 0.2871, 0.2859,\n",
       "         0.2862, 0.2982, 0.2688, 0.2687, 0.2502, 0.2784, 0.2615, 0.2736, 0.2903,\n",
       "         0.2685, 0.2823, 0.2492, 0.2818, 0.2484, 0.2817, 0.2782, 0.2801, 0.2865,\n",
       "         0.2731, 0.2552, 0.2906, 0.2971, 0.2746, 0.2700, 0.2835, 0.2865, 0.2953,\n",
       "         0.2670, 0.2360, 0.2838, 0.2801, 0.2666, 0.2817, 0.2725, 0.2682, 0.2756,\n",
       "         0.2551, 0.2815, 0.2714, 0.2683, 0.2636, 0.2570, 0.2565, 0.2567, 0.2256,\n",
       "         0.2595, 0.2715, 0.2788, 0.2080, 0.2801, 0.2513, 0.2825, 0.2662, 0.2776,\n",
       "         0.2884, 0.2556, 0.2675, 0.2871, 0.2890, 0.2552, 0.2474, 0.2689, 0.2226,\n",
       "         0.2360, 0.2061, 0.2806, 0.2924, 0.2814, 0.2789, 0.2720, 0.2555, 0.2459,\n",
       "         0.2721, 0.2577, 0.2790, 0.2905, 0.3048, 0.2794, 0.2917, 0.2758, 0.2873,\n",
       "         0.2599, 0.2738, 0.2617, 0.2700, 0.1831, 0.1809, 0.2620, 0.2429, 0.2971,\n",
       "         0.2820, 0.2565, 0.2903, 0.2916, 0.2722, 0.2732, 0.2866, 0.2563, 0.2713,\n",
       "         0.2838, 0.2827, 0.2874, 0.2627, 0.2760, 0.2786, 0.2679, 0.2792, 0.2758,\n",
       "         0.2693, 0.2781, 0.2667, 0.2617, 0.2538, 0.2524, 0.2286, 0.2626, 0.2733,\n",
       "         0.2744, 0.2614, 0.2886, 0.2333, 0.2795, 0.2767, 0.2769, 0.2757, 0.2644,\n",
       "         0.1988, 0.2430, 0.2585, 0.2802, 0.2907, 0.2246, 0.2794, 0.2682, 0.2706,\n",
       "         0.2881, 0.2447, 0.2891, 0.2644, 0.2444, 0.2948, 0.2812, 0.2370, 0.2723,\n",
       "         0.2728, 0.2793, 0.2771, 0.1062, 0.2465, 0.2708, 0.2598, 0.2628, 0.2565,\n",
       "         0.2944, 0.2559, 0.2723, 0.2994, 0.2573, 0.2559, 0.2672, 0.2911, 0.2798,\n",
       "         0.2696, 0.2507, 0.2553, 0.3058, 0.2565, 0.2721, 0.2588, 0.2771, 0.2817,\n",
       "         0.2573, 0.2707, 0.2726, 0.2657, 0.2620, 0.2908, 0.2751, 0.2682, 0.2638,\n",
       "         0.2692, 0.2966, 0.2115, 0.2702, 0.2911, 0.2530, 0.2888, 0.2850, 0.2849,\n",
       "         0.2803, 0.2527, 0.2552, 0.2679, 0.2718, 0.2724, 0.2364, 0.2648, 0.2592,\n",
       "         0.2678, 0.2872, 0.2691, 0.1741, 0.2675, 0.2774, 0.2650, 0.2695, 0.2932,\n",
       "         0.2746, 0.2748, 0.2671, 0.2634, 0.2779, 0.2535, 0.2940, 0.2833, 0.2743,\n",
       "         0.2554, 0.2781, 0.2867, 0.1810, 0.2863, 0.2702, 0.2759, 0.2628, 0.2718,\n",
       "         0.2880, 0.2743, 0.2539, 0.2357, 0.2915, 0.2674, 0.2443, 0.2630, 0.2762,\n",
       "         0.2517, 0.2646, 0.2836, 0.2720, 0.2693, 0.2601, 0.2831, 0.2809, 0.2445,\n",
       "         0.2492, 0.2770, 0.2654, 0.2786, 0.2854, 0.2478, 0.2916, 0.3008, 0.2773,\n",
       "         0.2681, 0.2345, 0.2741, 0.2732, 0.2386, 0.2895, 0.2746, 0.2817, 0.2767,\n",
       "         0.2818, 0.2768, 0.2923, 0.3095, 0.2667, 0.2563, 0.2290, 0.2745, 0.2899,\n",
       "         0.2534, 0.2739, 0.2997, 0.2864, 0.2608, 0.2767, 0.2544, 0.2642, 0.2594,\n",
       "         0.2682, 0.2673, 0.2688, 0.2373, 0.2784, 0.2779, 0.2969, 0.2365, 0.2784,\n",
       "         0.2645, 0.2724, 0.2753, 0.2728, 0.2459, 0.2785, 0.2782, 0.1499, 0.2519,\n",
       "         0.2378, 0.2760, 0.2742, 0.2752, 0.2766, 0.2592, 0.2571, 0.2775, 0.2646,\n",
       "         0.2643, 0.2469, 0.2599, 0.1390, 0.2709, 0.2697, 0.2534, 0.2695, 0.2951,\n",
       "         0.2748, 0.2872, 0.2753, 0.2532, 0.2485, 0.2811, 0.2907, 0.2962, 0.2671,\n",
       "         0.2745, 0.2717, 0.1966, 0.2622, 0.2784, 0.2933, 0.2401, 0.2780, 0.2766,\n",
       "         0.0856, 0.2584, 0.2927, 0.2662, 0.2746, 0.2539, 0.2819, 0.2797, 0.2719,\n",
       "         0.2787, 0.2712, 0.2581, 0.2608, 0.2812, 0.2515, 0.2642, 0.3038, 0.2265,\n",
       "         0.2579, 0.2906, 0.2605, 0.2699, 0.2751, 0.2757, 0.2819, 0.2877, 0.2768,\n",
       "         0.2565, 0.2105, 0.2659, 0.2800, 0.2586, 0.2806, 0.2648, 0.2809, 0.2931,\n",
       "         0.2721, 0.2939, 0.2762, 0.1266, 0.2867, 0.2975, 0.2670, 0.2810, 0.2630,\n",
       "         0.2735, 0.2700, 0.2601, 0.2819, 0.2897, 0.2629, 0.2737, 0.2650, 0.2747,\n",
       "         0.2657, 0.2846, 0.2979, 0.2630, 0.2429, 0.2802, 0.2500, 0.2729, 0.2828,\n",
       "         0.2768, 0.2861, 0.2828, 0.2616, 0.2310, 0.2784, 0.2198, 0.2806, 0.2345,\n",
       "         0.2724, 0.2690, 0.2749, 0.2530, 0.1021, 0.2817, 0.2740, 0.2732, 0.2494,\n",
       "         0.2981, 0.2845, 0.2748, 0.2719, 0.2712, 0.2887, 0.2455, 0.2643, 0.2846,\n",
       "         0.2843, 0.2289, 0.2217, 0.2942, 0.2675, 0.2719, 0.2721, 0.2633, 0.2440,\n",
       "         0.2856, 0.2795, 0.2820, 0.2766, 0.2758, 0.2872, 0.2991, 0.2085, 0.2734,\n",
       "         0.2174, 0.2652, 0.2821, 0.2662, 0.1942, 0.2947, 0.2593, 0.2654, 0.2713,\n",
       "         0.1670, 0.2440, 0.2736, 0.2812, 0.2791, 0.2839, 0.2805, 0.2680, 0.2717,\n",
       "         0.2740, 0.2624, 0.2657, 0.2619, 0.2935, 0.2664, 0.2652, 0.2351, 0.2649,\n",
       "         0.2687, 0.2763, 0.2500, 0.2753, 0.2638, 0.2834, 0.2729, 0.2779, 0.2660,\n",
       "         0.2847, 0.2505, 0.2178, 0.2730, 0.2891, 0.2449, 0.2377, 0.2879, 0.2964,\n",
       "         0.2872, 0.2804, 0.2920, 0.2657, 0.2950, 0.2684, 0.2541, 0.2514, 0.2783,\n",
       "         0.2674, 0.2776, 0.2738, 0.2798, 0.2835, 0.2725, 0.2434, 0.2724, 0.2726,\n",
       "         0.2797, 0.2806, 0.2693], device='cuda:0'),\n",
       " 'layers.2.norms.w2': tensor([0.3518, 0.3676, 0.3597, 0.3433, 0.3411, 0.3489, 0.3537, 0.2279, 0.3508,\n",
       "         0.3320, 0.2193, 0.3603, 0.3486, 0.3446, 0.3627, 0.3496, 0.3488, 0.3270,\n",
       "         0.3341, 0.3417, 0.3232, 0.3589, 0.3529, 0.3384, 0.3328, 0.3493, 0.3684,\n",
       "         0.3746, 0.3196, 0.3640, 0.3692, 0.3440, 0.3425, 0.3166, 0.3603, 0.2676,\n",
       "         0.3713, 0.3493, 0.3461, 0.3337, 0.3444, 0.3456, 0.3401, 0.3431, 0.2688,\n",
       "         0.3528, 0.3672, 0.3399, 0.3610, 0.3236, 0.2983, 0.3549, 0.3372, 0.3399,\n",
       "         0.3640, 0.3164, 0.3444, 0.3567, 0.3464, 0.3585, 0.3389, 0.3428, 0.3551,\n",
       "         0.3445, 0.3372, 0.3317, 0.3412, 0.3303, 0.3297, 0.3298, 0.3319, 0.3386,\n",
       "         0.3593, 0.3308, 0.3532, 0.3349, 0.3306, 0.3405, 0.2189, 0.3232, 0.3668,\n",
       "         0.3093, 0.3727, 0.3453, 0.3490, 0.3541, 0.3240, 0.3468, 0.3416, 0.3362,\n",
       "         0.3510, 0.2871, 0.3451, 0.3441, 0.3521, 0.3631, 0.2884, 0.3489, 0.3512,\n",
       "         0.3709, 0.3525, 0.3454, 0.3696, 0.3539, 0.3609, 0.3139, 0.3385, 0.2819,\n",
       "         0.3650, 0.3548, 0.3400, 0.3648, 0.3650, 0.3307, 0.3296, 0.3360, 0.3465,\n",
       "         0.3408, 0.3160, 0.3530, 0.3312, 0.3367, 0.3539, 0.3421, 0.1906, 0.3471,\n",
       "         0.3197, 0.3453, 0.3565, 0.3335, 0.3420, 0.3443, 0.3425, 0.3479, 0.3357,\n",
       "         0.3239, 0.3291, 0.3335, 0.3645, 0.3668, 0.3484, 0.3590, 0.3436, 0.3422,\n",
       "         0.3460, 0.3260, 0.3458, 0.3245, 0.3424, 0.3425, 0.3553, 0.3344, 0.3376,\n",
       "         0.3488, 0.3460, 0.3740, 0.3759, 0.2967, 0.3509, 0.3545, 0.3585, 0.3376,\n",
       "         0.3687, 0.3258, 0.3374, 0.3225, 0.3321, 0.3617, 0.3547, 0.3629, 0.1720,\n",
       "         0.3730, 0.3592, 0.3414, 0.3589, 0.3550, 0.3603, 0.3506, 0.3418, 0.3469,\n",
       "         0.3402, 0.3662, 0.3697, 0.3514, 0.3463, 0.3580, 0.3502, 0.3755, 0.3256,\n",
       "         0.3326, 0.3456, 0.3242, 0.3332, 0.3423, 0.3460, 0.3359, 0.3476, 0.3408,\n",
       "         0.3354, 0.3154, 0.3600, 0.3491, 0.3346, 0.3504, 0.3600, 0.3396, 0.3518,\n",
       "         0.3280, 0.3490, 0.3454, 0.3576, 0.3634, 0.3382, 0.3407, 0.3678, 0.3660,\n",
       "         0.3501, 0.3462, 0.3423, 0.3578, 0.3547, 0.3443, 0.3516, 0.3626, 0.3565,\n",
       "         0.3395, 0.3629, 0.3479, 0.3599, 0.3593, 0.3397, 0.3538, 0.3289, 0.3355,\n",
       "         0.3545, 0.3285, 0.3813, 0.3565, 0.3297, 0.2964, 0.3473, 0.3452, 0.3501,\n",
       "         0.3514, 0.3277, 0.3479, 0.3679, 0.3552, 0.3371, 0.3469, 0.3533, 0.3378,\n",
       "         0.3495, 0.3576, 0.3471, 0.3437, 0.3498, 0.3630, 0.3659, 0.3579, 0.3702,\n",
       "         0.3530, 0.3576, 0.3433, 0.3346, 0.3157, 0.3536, 0.3378, 0.3541, 0.3617,\n",
       "         0.3462, 0.3614, 0.3191, 0.3441, 0.3125, 0.3455, 0.3472, 0.3376, 0.3469,\n",
       "         0.3689, 0.3423, 0.3851, 0.3775, 0.3604, 0.3381, 0.3483, 0.3239, 0.3556,\n",
       "         0.3474, 0.3031, 0.3432, 0.3499, 0.3386, 0.3243, 0.3441, 0.3397, 0.3567,\n",
       "         0.3306, 0.3398, 0.3616, 0.3247, 0.3470, 0.3557, 0.3189, 0.3466, 0.3271,\n",
       "         0.3286, 0.3530, 0.3538, 0.2904, 0.3554, 0.3412, 0.3364, 0.3447, 0.3446,\n",
       "         0.3682, 0.3490, 0.3501, 0.3555, 0.3269, 0.3403, 0.3430, 0.3605, 0.3050,\n",
       "         0.3033, 0.3031, 0.3588, 0.3395, 0.3525, 0.3627, 0.3403, 0.3492, 0.3217,\n",
       "         0.3564, 0.3420, 0.3412, 0.3593, 0.3576, 0.3660, 0.3362, 0.3534, 0.3521,\n",
       "         0.3279, 0.3547, 0.3522, 0.3512, 0.2485, 0.2501, 0.3300, 0.3161, 0.3726,\n",
       "         0.3515, 0.3438, 0.3606, 0.3548, 0.3587, 0.3496, 0.3519, 0.3247, 0.3250,\n",
       "         0.3564, 0.3485, 0.3630, 0.3142, 0.3496, 0.3689, 0.3275, 0.3525, 0.3568,\n",
       "         0.3592, 0.3464, 0.3553, 0.3610, 0.3597, 0.3473, 0.3174, 0.3291, 0.3502,\n",
       "         0.3547, 0.3555, 0.3566, 0.3304, 0.3570, 0.3556, 0.3420, 0.3424, 0.3266,\n",
       "         0.3016, 0.3388, 0.3446, 0.3523, 0.3433, 0.3255, 0.3537, 0.3466, 0.3196,\n",
       "         0.3360, 0.3284, 0.3558, 0.3350, 0.3149, 0.3629, 0.3248, 0.3068, 0.3398,\n",
       "         0.3361, 0.3520, 0.3572, 0.1866, 0.3164, 0.3495, 0.3512, 0.3434, 0.3499,\n",
       "         0.3725, 0.3280, 0.3416, 0.3696, 0.3311, 0.3374, 0.3537, 0.3417, 0.3458,\n",
       "         0.3436, 0.3262, 0.3233, 0.3598, 0.3362, 0.3517, 0.3542, 0.3476, 0.3477,\n",
       "         0.3480, 0.3542, 0.3467, 0.3408, 0.3476, 0.3455, 0.3565, 0.3493, 0.3499,\n",
       "         0.3393, 0.3605, 0.2359, 0.3357, 0.3540, 0.3508, 0.3501, 0.3463, 0.3563,\n",
       "         0.3469, 0.3573, 0.3325, 0.3274, 0.3395, 0.3530, 0.3379, 0.3436, 0.3258,\n",
       "         0.3532, 0.3452, 0.3500, 0.2725, 0.3440, 0.3525, 0.3345, 0.3498, 0.3596,\n",
       "         0.3553, 0.3462, 0.3521, 0.3409, 0.3554, 0.3311, 0.3660, 0.3100, 0.3516,\n",
       "         0.3110, 0.3474, 0.3522, 0.2679, 0.3671, 0.3588, 0.3225, 0.3439, 0.3670,\n",
       "         0.3547, 0.3367, 0.3345, 0.3477, 0.3666, 0.3480, 0.3261, 0.3630, 0.3377,\n",
       "         0.3107, 0.3538, 0.3569, 0.3484, 0.3535, 0.3424, 0.3524, 0.3687, 0.3340,\n",
       "         0.3507, 0.3666, 0.3452, 0.3579, 0.3634, 0.3435, 0.3724, 0.3706, 0.3608,\n",
       "         0.3342, 0.3237, 0.3604, 0.3379, 0.3272, 0.3487, 0.3578, 0.3473, 0.3516,\n",
       "         0.3415, 0.3582, 0.3535, 0.3673, 0.3404, 0.3330, 0.3076, 0.3616, 0.3461,\n",
       "         0.3241, 0.3475, 0.3733, 0.3783, 0.3475, 0.3555, 0.3551, 0.3462, 0.3532,\n",
       "         0.3337, 0.3544, 0.3463, 0.3254, 0.3547, 0.3491, 0.3538, 0.3422, 0.3513,\n",
       "         0.3626, 0.3290, 0.3595, 0.3512, 0.3454, 0.3721, 0.3545, 0.1540, 0.3278,\n",
       "         0.3264, 0.3709, 0.3588, 0.3607, 0.3469, 0.3620, 0.3182, 0.3612, 0.3307,\n",
       "         0.3279, 0.3290, 0.3332, 0.2292, 0.3372, 0.3643, 0.3407, 0.3368, 0.3580,\n",
       "         0.3584, 0.3379, 0.3711, 0.3255, 0.3515, 0.3574, 0.3570, 0.3654, 0.3512,\n",
       "         0.3412, 0.3613, 0.2837, 0.3506, 0.3490, 0.3505, 0.3374, 0.3470, 0.3778,\n",
       "         0.1257, 0.3033, 0.3547, 0.3452, 0.3566, 0.3521, 0.3458, 0.3648, 0.3622,\n",
       "         0.3595, 0.3484, 0.3347, 0.3398, 0.3423, 0.3295, 0.3569, 0.3585, 0.3118,\n",
       "         0.3422, 0.3519, 0.3321, 0.3466, 0.3599, 0.3452, 0.3543, 0.3483, 0.3482,\n",
       "         0.3323, 0.3258, 0.3499, 0.3563, 0.3427, 0.3542, 0.3347, 0.3509, 0.3682,\n",
       "         0.3584, 0.3662, 0.3274, 0.1227, 0.3599, 0.3442, 0.3476, 0.3532, 0.3564,\n",
       "         0.3621, 0.3433, 0.3566, 0.3465, 0.3477, 0.3431, 0.3678, 0.3367, 0.3635,\n",
       "         0.3547, 0.3584, 0.3655, 0.3617, 0.3250, 0.3612, 0.3257, 0.3487, 0.3468,\n",
       "         0.3483, 0.3606, 0.3606, 0.3392, 0.3349, 0.3526, 0.3039, 0.3570, 0.3072,\n",
       "         0.3674, 0.3399, 0.3464, 0.3315, 0.1760, 0.3576, 0.3463, 0.3377, 0.3428,\n",
       "         0.3561, 0.3587, 0.3566, 0.3514, 0.3462, 0.3714, 0.3192, 0.3337, 0.3475,\n",
       "         0.3657, 0.3054, 0.3183, 0.3612, 0.3431, 0.3410, 0.3559, 0.3486, 0.3064,\n",
       "         0.3347, 0.3588, 0.3665, 0.3663, 0.3484, 0.3624, 0.3502, 0.3064, 0.3492,\n",
       "         0.2967, 0.3368, 0.3398, 0.3368, 0.2664, 0.3420, 0.3501, 0.3554, 0.3591,\n",
       "         0.2331, 0.3333, 0.3575, 0.3505, 0.3691, 0.3540, 0.3318, 0.3421, 0.3377,\n",
       "         0.3481, 0.3315, 0.3423, 0.3475, 0.3513, 0.3401, 0.3398, 0.3247, 0.3436,\n",
       "         0.3522, 0.3655, 0.3417, 0.3707, 0.3768, 0.3491, 0.3500, 0.3340, 0.3369,\n",
       "         0.3570, 0.3403, 0.2978, 0.3563, 0.3354, 0.3203, 0.3410, 0.3624, 0.3637,\n",
       "         0.3541, 0.3552, 0.3799, 0.3420, 0.3468, 0.3326, 0.3368, 0.3316, 0.3646,\n",
       "         0.3384, 0.3497, 0.3461, 0.3589, 0.3590, 0.3444, 0.3354, 0.3590, 0.3545,\n",
       "         0.3446, 0.3675, 0.3417], device='cuda:0'),\n",
       " 'layers.3.norms.w2': tensor([0.3713, 0.3945, 0.3791, 0.3904, 0.3871, 0.3935, 0.3811, 0.2951, 0.3790,\n",
       "         0.3594, 0.2912, 0.3829, 0.3914, 0.3983, 0.3806, 0.3858, 0.3760, 0.3683,\n",
       "         0.3792, 0.3881, 0.3910, 0.3515, 0.3614, 0.4026, 0.3709, 0.3635, 0.3912,\n",
       "         0.4223, 0.3681, 0.3825, 0.3939, 0.3584, 0.3840, 0.3660, 0.3978, 0.3505,\n",
       "         0.3792, 0.3697, 0.3829, 0.3702, 0.3469, 0.3586, 0.3711, 0.3844, 0.3739,\n",
       "         0.3968, 0.3819, 0.3493, 0.3891, 0.3886, 0.3514, 0.3978, 0.3818, 0.3961,\n",
       "         0.3955, 0.3830, 0.3750, 0.3892, 0.3690, 0.3657, 0.3687, 0.3897, 0.3645,\n",
       "         0.3951, 0.3654, 0.3903, 0.3705, 0.3950, 0.3593, 0.3771, 0.3875, 0.3780,\n",
       "         0.3877, 0.3708, 0.3781, 0.3663, 0.3698, 0.3643, 0.2914, 0.3868, 0.3794,\n",
       "         0.3691, 0.3759, 0.3668, 0.3807, 0.3779, 0.3684, 0.3692, 0.3699, 0.3771,\n",
       "         0.3845, 0.3528, 0.3646, 0.3820, 0.3859, 0.3625, 0.3580, 0.3987, 0.3904,\n",
       "         0.3743, 0.3863, 0.3493, 0.3793, 0.3766, 0.3841, 0.3726, 0.3878, 0.4299,\n",
       "         0.3875, 0.3688, 0.3873, 0.4176, 0.3748, 0.3880, 0.3796, 0.3977, 0.3865,\n",
       "         0.3785, 0.3630, 0.3644, 0.3707, 0.3711, 0.3762, 0.3770, 0.2683, 0.3671,\n",
       "         0.3704, 0.3595, 0.3972, 0.3642, 0.3814, 0.3863, 0.3692, 0.3923, 0.3768,\n",
       "         0.3873, 0.3645, 0.3937, 0.3703, 0.3713, 0.3729, 0.3832, 0.3530, 0.3741,\n",
       "         0.3743, 0.3613, 0.3648, 0.3743, 0.3723, 0.3708, 0.3877, 0.3729, 0.3898,\n",
       "         0.3824, 0.3764, 0.3856, 0.3777, 0.3548, 0.3856, 0.3730, 0.3680, 0.3739,\n",
       "         0.3554, 0.3785, 0.3626, 0.3815, 0.3710, 0.3940, 0.3849, 0.3924, 0.2624,\n",
       "         0.3751, 0.3826, 0.3872, 0.3941, 0.3892, 0.3995, 0.3838, 0.3826, 0.3739,\n",
       "         0.3744, 0.3781, 0.3967, 0.3768, 0.3923, 0.3823, 0.3798, 0.3807, 0.3709,\n",
       "         0.3758, 0.3819, 0.3696, 0.3723, 0.3629, 0.3814, 0.3736, 0.3999, 0.4095,\n",
       "         0.3787, 0.3818, 0.3724, 0.3735, 0.3735, 0.3864, 0.3891, 0.3773, 0.3731,\n",
       "         0.3672, 0.3639, 0.3768, 0.3758, 0.3826, 0.3572, 0.3839, 0.3763, 0.3740,\n",
       "         0.3881, 0.3835, 0.3728, 0.3673, 0.3675, 0.3861, 0.3716, 0.3780, 0.3709,\n",
       "         0.3543, 0.3667, 0.3694, 0.3711, 0.3891, 0.3687, 0.3741, 0.3760, 0.3940,\n",
       "         0.3801, 0.3810, 0.4079, 0.3885, 0.3959, 0.4075, 0.3883, 0.3814, 0.3640,\n",
       "         0.3810, 0.3647, 0.3925, 0.3747, 0.3722, 0.3706, 0.4007, 0.3821, 0.3717,\n",
       "         0.3578, 0.3878, 0.3619, 0.3914, 0.3816, 0.3788, 0.3877, 0.3810, 0.3719,\n",
       "         0.3663, 0.3879, 0.3793, 0.3555, 0.3578, 0.3830, 0.4022, 0.3796, 0.3710,\n",
       "         0.3768, 0.3639, 0.3711, 0.3854, 0.3808, 0.3558, 0.3790, 0.3759, 0.3714,\n",
       "         0.3905, 0.3700, 0.3862, 0.3878, 0.3730, 0.3659, 0.3806, 0.3596, 0.3729,\n",
       "         0.3766, 0.3930, 0.3671, 0.3564, 0.3857, 0.3529, 0.3787, 0.3889, 0.3757,\n",
       "         0.3604, 0.3817, 0.3852, 0.3749, 0.3662, 0.3989, 0.3863, 0.3695, 0.3891,\n",
       "         0.3677, 0.3718, 0.3834, 0.3671, 0.3787, 0.3900, 0.3658, 0.3986, 0.3590,\n",
       "         0.3852, 0.3807, 0.3981, 0.3958, 0.3558, 0.3777, 0.3720, 0.3793, 0.3644,\n",
       "         0.3633, 0.3570, 0.3876, 0.3766, 0.3820, 0.3717, 0.3697, 0.3756, 0.3911,\n",
       "         0.3827, 0.3980, 0.3819, 0.3595, 0.4458, 0.3777, 0.3771, 0.3895, 0.3718,\n",
       "         0.3782, 0.3799, 0.3693, 0.3712, 0.3679, 0.3270, 0.3772, 0.3680, 0.3753,\n",
       "         0.3535, 0.3938, 0.3663, 0.3664, 0.3699, 0.3857, 0.3782, 0.3724, 0.3430,\n",
       "         0.4039, 0.3628, 0.3626, 0.3704, 0.3872, 0.3841, 0.3627, 0.3780, 0.3893,\n",
       "         0.3889, 0.3810, 0.3696, 0.3818, 0.3962, 0.3830, 0.3690, 0.3743, 0.3762,\n",
       "         0.3694, 0.3997, 0.3770, 0.3905, 0.3732, 0.3876, 0.3799, 0.3818, 0.3419,\n",
       "         0.3506, 0.4107, 0.3768, 0.3879, 0.3749, 0.3644, 0.3847, 0.3745, 0.3689,\n",
       "         0.3849, 0.3819, 0.3712, 0.3921, 0.3667, 0.3904, 0.3656, 0.3169, 0.3821,\n",
       "         0.3829, 0.3745, 0.3861, 0.2540, 0.3626, 0.3674, 0.3893, 0.3868, 0.4140,\n",
       "         0.3760, 0.3863, 0.3806, 0.3703, 0.3756, 0.3904, 0.3830, 0.4201, 0.3805,\n",
       "         0.3780, 0.3425, 0.3701, 0.3682, 0.3870, 0.3742, 0.3806, 0.3688, 0.3521,\n",
       "         0.3821, 0.3770, 0.3907, 0.3713, 0.3897, 0.3831, 0.3808, 0.3882, 0.4043,\n",
       "         0.3631, 0.3975, 0.2314, 0.3602, 0.3799, 0.3700, 0.3891, 0.3521, 0.3826,\n",
       "         0.3799, 0.3735, 0.3812, 0.3668, 0.3641, 0.3893, 0.3759, 0.3721, 0.3523,\n",
       "         0.3667, 0.3577, 0.3846, 0.3525, 0.3796, 0.3772, 0.3726, 0.3748, 0.3852,\n",
       "         0.3809, 0.3500, 0.3751, 0.3466, 0.3785, 0.3698, 0.3786, 0.3736, 0.3767,\n",
       "         0.3713, 0.3993, 0.3999, 0.3427, 0.3934, 0.3877, 0.3649, 0.3727, 0.3887,\n",
       "         0.3972, 0.3682, 0.3797, 0.4320, 0.3709, 0.3866, 0.3789, 0.3673, 0.3898,\n",
       "         0.3769, 0.3851, 0.3864, 0.3812, 0.3713, 0.3972, 0.3724, 0.3750, 0.3669,\n",
       "         0.3803, 0.3672, 0.3580, 0.3683, 0.3795, 0.3778, 0.3908, 0.3714, 0.3768,\n",
       "         0.3639, 0.3792, 0.3817, 0.3643, 0.3856, 0.3701, 0.3714, 0.3663, 0.3759,\n",
       "         0.3788, 0.3833, 0.3788, 0.3733, 0.3834, 0.3827, 0.3542, 0.3810, 0.3902,\n",
       "         0.3554, 0.3953, 0.3885, 0.4058, 0.3786, 0.3728, 0.3492, 0.3641, 0.3948,\n",
       "         0.3769, 0.3843, 0.3668, 0.3709, 0.3756, 0.3653, 0.3790, 0.3755, 0.3783,\n",
       "         0.3673, 0.3730, 0.3857, 0.3544, 0.3834, 0.3637, 0.3747, 0.2548, 0.3641,\n",
       "         0.3540, 0.3748, 0.3839, 0.3810, 0.3880, 0.3810, 0.3617, 0.3718, 0.3406,\n",
       "         0.3720, 0.3430, 0.3698, 0.3200, 0.3666, 0.3646, 0.3754, 0.3701, 0.3792,\n",
       "         0.3643, 0.3812, 0.3717, 0.3751, 0.3754, 0.3736, 0.3627, 0.3917, 0.3783,\n",
       "         0.3638, 0.3894, 0.3684, 0.3744, 0.3804, 0.3853, 0.3764, 0.3716, 0.3810,\n",
       "         0.1871, 0.3737, 0.3769, 0.3650, 0.3827, 0.3912, 0.3686, 0.3728, 0.3706,\n",
       "         0.3702, 0.4069, 0.3679, 0.3734, 0.3538, 0.3702, 0.3785, 0.3840, 0.3714,\n",
       "         0.3643, 0.3687, 0.3563, 0.3711, 0.3736, 0.3969, 0.3808, 0.3736, 0.3736,\n",
       "         0.3842, 0.3789, 0.3846, 0.3765, 0.3752, 0.3801, 0.3725, 0.3757, 0.4024,\n",
       "         0.3902, 0.3728, 0.3828, 0.1559, 0.4006, 0.3819, 0.3887, 0.3598, 0.3827,\n",
       "         0.3889, 0.3755, 0.3911, 0.3632, 0.3742, 0.3784, 0.3925, 0.3841, 0.3908,\n",
       "         0.3924, 0.3595, 0.3800, 0.3692, 0.3709, 0.3742, 0.3669, 0.3822, 0.3684,\n",
       "         0.3917, 0.3775, 0.3803, 0.3695, 0.3574, 0.3722, 0.3676, 0.3885, 0.3604,\n",
       "         0.3705, 0.3733, 0.3731, 0.3808, 0.2871, 0.3727, 0.3860, 0.3897, 0.3818,\n",
       "         0.3567, 0.3610, 0.3703, 0.3965, 0.3747, 0.3644, 0.3550, 0.3588, 0.3912,\n",
       "         0.3749, 0.3663, 0.3801, 0.3942, 0.3814, 0.3585, 0.3718, 0.3682, 0.3785,\n",
       "         0.3624, 0.3658, 0.4025, 0.3710, 0.3835, 0.3802, 0.3714, 0.3527, 0.3679,\n",
       "         0.3633, 0.3778, 0.3716, 0.3619, 0.3619, 0.3761, 0.3816, 0.3686, 0.3775,\n",
       "         0.2882, 0.3668, 0.3910, 0.3676, 0.3768, 0.3570, 0.3944, 0.3831, 0.3642,\n",
       "         0.3876, 0.3437, 0.3796, 0.3775, 0.3875, 0.3716, 0.3752, 0.3766, 0.3854,\n",
       "         0.3640, 0.3738, 0.3925, 0.3528, 0.3743, 0.3699, 0.3696, 0.3628, 0.3705,\n",
       "         0.3691, 0.3550, 0.4446, 0.3675, 0.3664, 0.3563, 0.3950, 0.4005, 0.3670,\n",
       "         0.3832, 0.3865, 0.3674, 0.3820, 0.3694, 0.3934, 0.3777, 0.4005, 0.3928,\n",
       "         0.3659, 0.3924, 0.3724, 0.3578, 0.3836, 0.3906, 0.3705, 0.3629, 0.3889,\n",
       "         0.3660, 0.3827, 0.3833], device='cuda:0')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe297b-3b3e-41ab-bea1-a0218a63c367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
