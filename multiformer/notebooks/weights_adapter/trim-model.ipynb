{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0615b720-bce6-4635-85f9-8b4e4ce89d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b01d1d-e3b3-4c09-a280-5b1177e1c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLM - MEDIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b88dee6-b9b7-469c-9405-bf18167fa27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLM Instruct - v2\n",
    "MODEL_CHECKPOINT = (\n",
    "    \"/home/pranav-pc/projects/OpenTransformer/multiformer/blm-fine-tuned-imdb/last.ckpt\"\n",
    ")\n",
    "MODEL_REGISTRY = \"/home/pranav-pc/projects/model-registry/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c436dae1-bf12-4b60-855c-e3237a7e9534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load(MODEL_CHECKPOINT)\n",
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ac86d54-2941-45bc-af3c-84af836c713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c74c24f-99b4-47cf-a02c-feb6e58f614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_dict[\"loops\"]\n",
    "del model_dict[\"callbacks\"]\n",
    "del model_dict[\"optimizer_states\"]\n",
    "del model_dict[\"lr_schedulers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36eb084f-9691-4b14-96b7-31807bbe8581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 5,\n",
       " 'global_step': 364000,\n",
       " 'pytorch-lightning_version': '2.3.0.dev20240318',\n",
       " 'state_dict': OrderedDict([('model.tok_embd.weight',\n",
       "               tensor([[-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "                       [-0.0024,  0.0108, -0.0182,  ...,  0.0005, -0.0436,  0.0270],\n",
       "                       [-0.0827, -0.0160, -0.0518,  ..., -0.1533, -0.0490,  0.0909],\n",
       "                       ...,\n",
       "                       [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0188],\n",
       "                       [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "                       [-0.0406, -0.0110, -0.0283,  ...,  0.0344, -0.0347, -0.0188]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.0.norms.w',\n",
       "               tensor([0.1570, 0.1649, 0.1578, 0.1534, 0.1473, 0.1549, 0.1634, 0.2792, 0.1523,\n",
       "                       0.1406, 0.0617, 0.1445, 0.1376, 0.1397, 0.1580, 0.1514, 0.1633, 0.1397,\n",
       "                       0.1655, 0.1390, 0.1695, 0.1402, 0.1481, 0.1264, 0.1438, 0.1410, 0.1371,\n",
       "                       0.2102, 0.1409, 0.1850, 0.1454, 0.1394, 0.1555, 0.1386, 0.1472, 0.1209,\n",
       "                       0.2077, 0.1555, 0.1558, 0.1519, 0.1542, 0.1612, 0.1654, 0.1531, 0.1833,\n",
       "                       0.1591, 0.1632, 0.1340, 0.1568, 0.1453, 0.0869, 0.1625, 0.1303, 0.1675,\n",
       "                       0.1486, 0.1203, 0.1484, 0.1429, 0.1474, 0.1598, 0.1574, 0.1548, 0.1389,\n",
       "                       0.1470, 0.1496, 0.1376, 0.1656, 0.1448, 0.1263, 0.1421, 0.1275, 0.1257,\n",
       "                       0.1466, 0.1341, 0.1421, 0.1226, 0.1471, 0.1450, 0.0793, 0.1495, 0.1404,\n",
       "                       0.1279, 0.1669, 0.1488, 0.1550, 0.1385, 0.1718, 0.1540, 0.1650, 0.1439,\n",
       "                       0.1467, 0.1105, 0.1540, 0.1357, 0.1617, 0.1557, 0.1261, 0.1325, 0.1078,\n",
       "                       0.1486, 0.1532, 0.1398, 0.2487, 0.1554, 0.1488, 0.1397, 0.1538, 0.0484,\n",
       "                       0.1377, 0.1571, 0.1472, 0.1410, 0.1705, 0.1501, 0.1577, 0.1549, 0.1359,\n",
       "                       0.1076, 0.1672, 0.1866, 0.1305, 0.1395, 0.1287, 0.1359, 0.0564, 0.1711,\n",
       "                       0.1274, 0.1471, 0.1565, 0.1609, 0.1272, 0.1208, 0.1627, 0.1543, 0.1543,\n",
       "                       0.1404, 0.1434, 0.1524, 0.1571, 0.1507, 0.1545, 0.1271, 0.1402, 0.1473,\n",
       "                       0.1653, 0.1514, 0.1540, 0.1487, 0.1719, 0.1759, 0.1577, 0.1410, 0.1534,\n",
       "                       0.1572, 0.1621, 0.1641, 0.1593, 0.1002, 0.1747, 0.1567, 0.1392, 0.1361,\n",
       "                       0.1629, 0.1435, 0.1285, 0.1335, 0.1489, 0.1479, 0.2296, 0.1458, 0.0696,\n",
       "                       0.1561, 0.1534, 0.1362, 0.1473, 0.1603, 0.1686, 0.1543, 0.1371, 0.1606,\n",
       "                       0.1401, 0.1481, 0.1615, 0.1820, 0.1431, 0.1578, 0.1405, 0.1681, 0.1630,\n",
       "                       0.1602, 0.1510, 0.1398, 0.1362, 0.1521, 0.1744, 0.1192, 0.1561, 0.1571,\n",
       "                       0.1477, 0.1110, 0.1708, 0.1496, 0.1417, 0.1290, 0.1520, 0.1215, 0.1598,\n",
       "                       0.1363, 0.1604, 0.1590, 0.1851, 0.1370, 0.1415, 0.1437, 0.1643, 0.1539,\n",
       "                       0.1509, 0.1505, 0.1342, 0.1694, 0.1502, 0.1416, 0.2388, 0.1954, 0.1674,\n",
       "                       0.1589, 0.1668, 0.1622, 0.1261, 0.1722, 0.1417, 0.1493, 0.1426, 0.1272,\n",
       "                       0.1533, 0.1248, 0.1662, 0.1438, 0.1258, 0.1701, 0.1275, 0.1622, 0.1592,\n",
       "                       0.1506, 0.1424, 0.1559, 0.1480, 0.1621, 0.1392, 0.1848, 0.1500, 0.1523,\n",
       "                       0.1636, 0.1529, 0.1559, 0.1567, 0.1633, 0.2070, 0.1358, 0.1535, 0.1473,\n",
       "                       0.1474, 0.1695, 0.1340, 0.1363, 0.1385, 0.1555, 0.1511, 0.1575, 0.1606,\n",
       "                       0.1408, 0.1783, 0.1365, 0.1546, 0.1288, 0.1499, 0.1674, 0.1601, 0.1728,\n",
       "                       0.1585, 0.1577, 0.1616, 0.1588, 0.1355, 0.1355, 0.1430, 0.1540, 0.1531,\n",
       "                       0.1435, 0.1571, 0.1392, 0.1627, 0.1337, 0.1433, 0.1525, 0.1527, 0.1547,\n",
       "                       0.1377, 0.1562, 0.1489, 0.1393, 0.1457, 0.1722, 0.1433, 0.1452, 0.1232,\n",
       "                       0.1330, 0.1347, 0.1970, 0.1234, 0.1627, 0.1374, 0.1481, 0.1457, 0.1526,\n",
       "                       0.1884, 0.1517, 0.1464, 0.1502, 0.1573, 0.1439, 0.1464, 0.1585, 0.1238,\n",
       "                       0.1342, 0.1205, 0.1540, 0.1736, 0.1543, 0.1534, 0.1469, 0.1526, 0.1497,\n",
       "                       0.1569, 0.1926, 0.1540, 0.1543, 0.1197, 0.1574, 0.1462, 0.1710, 0.1488,\n",
       "                       0.1584, 0.1464, 0.1607, 0.1645, 0.1145, 0.1189, 0.1341, 0.1634, 0.1414,\n",
       "                       0.1601, 0.1514, 0.1461, 0.1536, 0.1576, 0.1643, 0.1625, 0.1415, 0.1413,\n",
       "                       0.1485, 0.1480, 0.1500, 0.1367, 0.1421, 0.1530, 0.1508, 0.1486, 0.1731,\n",
       "                       0.1479, 0.1614, 0.1602, 0.1455, 0.1336, 0.1397, 0.1378, 0.1467, 0.1457,\n",
       "                       0.1785, 0.1488, 0.1378, 0.1012, 0.1469, 0.1696, 0.1391, 0.1569, 0.1250,\n",
       "                       0.1789, 0.1459, 0.1520, 0.1740, 0.1555, 0.1154, 0.1672, 0.1570, 0.1410,\n",
       "                       0.1365, 0.1608, 0.1672, 0.1513, 0.0765, 0.1488, 0.1434, 0.1362, 0.1419,\n",
       "                       0.1678, 0.1508, 0.1424, 0.0747, 0.0920, 0.1108, 0.1644, 0.1350, 0.1300,\n",
       "                       0.1607, 0.1457, 0.1283, 0.1496, 0.1407, 0.1302, 0.1579, 0.1414, 0.1472,\n",
       "                       0.1428, 0.1642, 0.1418, 0.1673, 0.1471, 0.1401, 0.3928, 0.1474, 0.2239,\n",
       "                       0.1902, 0.1501, 0.1394, 0.1625, 0.1490, 0.1606, 0.1675, 0.1597, 0.1487,\n",
       "                       0.1557, 0.1407, 0.2428, 0.1344, 0.1576, 0.1546, 0.1619, 0.1461, 0.1520,\n",
       "                       0.1660, 0.1474, 0.1489, 0.1655, 0.1565, 0.1504, 0.1417, 0.1158, 0.1367,\n",
       "                       0.1511, 0.1487, 0.1328, 0.1058, 0.1540, 0.1613, 0.1656, 0.1465, 0.1464,\n",
       "                       0.1557, 0.1457, 0.1517, 0.1443, 0.1556, 0.1708, 0.1568, 0.1733, 0.1477,\n",
       "                       0.1510, 0.1482, 0.1570, 0.1087, 0.1307, 0.1564, 0.1555, 0.1554, 0.1665,\n",
       "                       0.1676, 0.1366, 0.3098, 0.1716, 0.1706, 0.1571, 0.1468, 0.1603, 0.1474,\n",
       "                       0.1396, 0.1578, 0.1736, 0.1556, 0.1532, 0.1459, 0.1351, 0.1688, 0.1363,\n",
       "                       0.1530, 0.1512, 0.1639, 0.1739, 0.1937, 0.1547, 0.1435, 0.1508, 0.1533,\n",
       "                       0.1532, 0.1572, 0.1341, 0.1814, 0.1590, 0.1644, 0.1438, 0.1651, 0.1455,\n",
       "                       0.1374, 0.1445, 0.1507, 0.1404, 0.1600, 0.1558, 0.1423, 0.1520, 0.1496,\n",
       "                       0.1359, 0.1418, 0.1556, 0.1629, 0.1558, 0.1618, 0.1584, 0.1807, 0.1461,\n",
       "                       0.1380, 0.1485, 0.1554, 0.1669, 0.1698, 0.1251, 0.1616, 0.1145, 0.1400,\n",
       "                       0.1587, 0.1436, 0.1699, 0.1426, 0.2263, 0.1469, 0.1475, 0.0733, 0.1135,\n",
       "                       0.1359, 0.1568, 0.1670, 0.1606, 0.1628, 0.1390, 0.1424, 0.1751, 0.1465,\n",
       "                       0.1061, 0.1490, 0.1638, 0.0793, 0.1521, 0.1750, 0.1350, 0.1452, 0.1482,\n",
       "                       0.1483, 0.1523, 0.1809, 0.1652, 0.1465, 0.1995, 0.1634, 0.2114, 0.1693,\n",
       "                       0.1552, 0.1801, 0.0964, 0.1583, 0.1518, 0.1484, 0.1242, 0.1427, 0.1481,\n",
       "                       0.0620, 0.1564, 0.1421, 0.1444, 0.1529, 0.1666, 0.1461, 0.1568, 0.1503,\n",
       "                       0.1433, 0.1376, 0.1469, 0.1329, 0.1669, 0.1486, 0.1392, 0.1611, 0.2089,\n",
       "                       0.1028, 0.1897, 0.1473, 0.1612, 0.1616, 0.1360, 0.1598, 0.1655, 0.1503,\n",
       "                       0.1205, 0.1059, 0.1602, 0.1445, 0.1877, 0.1439, 0.1713, 0.1489, 0.1661,\n",
       "                       0.1589, 0.1510, 0.1593, 0.0607, 0.1419, 0.1417, 0.1434, 0.1532, 0.1510,\n",
       "                       0.1607, 0.1625, 0.1501, 0.1448, 0.1523, 0.1456, 0.1498, 0.1233, 0.1500,\n",
       "                       0.1583, 0.1515, 0.1486, 0.1429, 0.1441, 0.1663, 0.1456, 0.1620, 0.1661,\n",
       "                       0.1362, 0.1650, 0.1499, 0.1348, 0.1333, 0.1376, 0.0788, 0.1407, 0.1385,\n",
       "                       0.1444, 0.1236, 0.1540, 0.1137, 0.0547, 0.1421, 0.1563, 0.1412, 0.1472,\n",
       "                       0.1644, 0.1539, 0.1479, 0.1528, 0.1502, 0.1451, 0.1396, 0.1358, 0.1573,\n",
       "                       0.1586, 0.1315, 0.1356, 0.1571, 0.1032, 0.1635, 0.1573, 0.1482, 0.1326,\n",
       "                       0.1596, 0.1535, 0.1384, 0.1540, 0.1491, 0.1487, 0.1470, 0.1194, 0.1525,\n",
       "                       0.1217, 0.1594, 0.1430, 0.1448, 0.1214, 0.1478, 0.1318, 0.1430, 0.1734,\n",
       "                       0.2255, 0.1423, 0.1378, 0.1559, 0.1398, 0.1530, 0.1475, 0.1606, 0.1628,\n",
       "                       0.1483, 0.1425, 0.1359, 0.1442, 0.1756, 0.1531, 0.1499, 0.1206, 0.1486,\n",
       "                       0.1475, 0.1466, 0.1451, 0.1501, 0.1461, 0.1728, 0.1693, 0.1594, 0.1325,\n",
       "                       0.1778, 0.1427, 0.0767, 0.1397, 0.1405, 0.1385, 0.1487, 0.1526, 0.1621,\n",
       "                       0.1531, 0.1453, 0.1547, 0.1516, 0.1372, 0.1530, 0.1428, 0.1409, 0.1557,\n",
       "                       0.1459, 0.1309, 0.1629, 0.1487, 0.1535, 0.1532, 0.1332, 0.1350, 0.1755,\n",
       "                       0.1505, 0.1453, 0.1465], device='cuda:0')),\n",
       "              ('model.layers.0.attention.wq.weight',\n",
       "               tensor([[-5.2307e-02, -5.5769e-02, -1.3177e-01,  ...,  2.2935e-01,\n",
       "                        -5.4016e-02,  1.1902e-01],\n",
       "                       [ 3.2817e-02,  1.1855e-04,  3.0871e-02,  ..., -4.8728e-02,\n",
       "                        -4.3831e-02, -1.0355e-01],\n",
       "                       [-1.2030e-03, -2.2414e-01,  5.3518e-02,  ..., -1.0539e-01,\n",
       "                        -1.3322e-01, -8.1382e-02],\n",
       "                       ...,\n",
       "                       [-6.4690e-02,  2.9343e-02, -1.5258e-04,  ..., -5.8976e-02,\n",
       "                         1.8575e-01,  4.4744e-02],\n",
       "                       [ 1.7963e-01,  1.1678e-01, -5.4585e-02,  ..., -5.7763e-02,\n",
       "                        -2.2228e-01,  6.4764e-02],\n",
       "                       [ 7.1337e-02, -2.0702e-01,  2.8848e-02,  ...,  9.6218e-02,\n",
       "                        -2.9840e-02, -1.2775e-01]], device='cuda:0')),\n",
       "              ('model.layers.0.attention.wk.weight',\n",
       "               tensor([[ 0.0006, -0.1292,  0.0835,  ..., -0.1895,  0.0720, -0.1217],\n",
       "                       [ 0.0056, -0.0291, -0.3082,  ...,  0.0387, -0.0865, -0.1162],\n",
       "                       [-0.0627, -0.1507, -0.0728,  ...,  0.2257,  0.1081,  0.2148],\n",
       "                       ...,\n",
       "                       [ 0.1453,  0.0486, -0.1470,  ..., -0.0579,  0.0439,  0.0829],\n",
       "                       [ 0.0662, -0.1418,  0.0414,  ..., -0.0160,  0.1373,  0.1748],\n",
       "                       [ 0.1188,  0.0646, -0.3359,  ...,  0.1219, -0.0254,  0.0006]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.0.attention.wv.weight',\n",
       "               tensor([[-0.0579, -0.1393,  0.1843,  ..., -0.1480, -0.0053,  0.1488],\n",
       "                       [-0.1899, -0.0990, -0.0106,  ..., -0.1089,  0.0936,  0.1428],\n",
       "                       [ 0.0740,  0.0675,  0.0707,  ..., -0.1837, -0.1718,  0.0409],\n",
       "                       ...,\n",
       "                       [-0.1198,  0.1662,  0.1590,  ...,  0.1460, -0.1002, -0.0185],\n",
       "                       [-0.0616, -0.0752,  0.1309,  ...,  0.0089,  0.0010,  0.0256],\n",
       "                       [ 0.0797, -0.0114, -0.0983,  ..., -0.0765,  0.0154, -0.1365]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.0.attention.wo.weight',\n",
       "               tensor([[ 0.1466,  0.0022,  0.0365,  ...,  0.1039,  0.1192, -0.0293],\n",
       "                       [-0.2208, -0.1050,  0.0068,  ...,  0.0054,  0.0104,  0.0332],\n",
       "                       [-0.0068,  0.1179,  0.0631,  ...,  0.0935,  0.0745, -0.0198],\n",
       "                       ...,\n",
       "                       [-0.0868,  0.0450,  0.0660,  ..., -0.0938,  0.0283, -0.1204],\n",
       "                       [-0.2067,  0.1453,  0.0244,  ..., -0.0800,  0.0015, -0.0023],\n",
       "                       [-0.1743,  0.0218,  0.0772,  ...,  0.0145, -0.0647,  0.0795]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.0.mlp.linear1.weight',\n",
       "               tensor([[ 0.0463,  0.0428, -0.0611,  ...,  0.1543, -0.1007,  0.0822],\n",
       "                       [ 0.0036, -0.0542, -0.1335,  ...,  0.2278,  0.2084, -0.0972],\n",
       "                       [ 0.2158, -0.1678, -0.1142,  ..., -0.0280,  0.0036, -0.1184],\n",
       "                       ...,\n",
       "                       [ 0.0762,  0.0098, -0.0840,  ..., -0.0320,  0.1233,  0.1713],\n",
       "                       [-0.1489,  0.1182, -0.1447,  ..., -0.0983,  0.1620, -0.1003],\n",
       "                       [ 0.0796,  0.1287,  0.0659,  ..., -0.0119, -0.1098,  0.0349]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.0.mlp.linear2.weight',\n",
       "               tensor([[-0.0482, -0.1685, -0.0115,  ...,  0.1840, -0.0708, -0.0035],\n",
       "                       [-0.1788,  0.0912, -0.0607,  ...,  0.0726,  0.2293,  0.2272],\n",
       "                       [ 0.2103,  0.0572,  0.0478,  ...,  0.0556, -0.0617, -0.0632],\n",
       "                       ...,\n",
       "                       [ 0.0539,  0.0029, -0.0104,  ...,  0.3167,  0.0363,  0.0702],\n",
       "                       [ 0.0062, -0.1024, -0.1725,  ..., -0.0316,  0.0492, -0.1754],\n",
       "                       [-0.0151, -0.1473, -0.1108,  ...,  0.0243,  0.0513,  0.0362]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.0.mlp.linear3.weight',\n",
       "               tensor([[-0.0573,  0.0738,  0.0055,  ...,  0.1500, -0.1777, -0.0330],\n",
       "                       [ 0.1465,  0.0298,  0.1787,  ..., -0.1816, -0.1352, -0.2725],\n",
       "                       [ 0.0308, -0.2491, -0.0600,  ..., -0.0421, -0.3520, -0.1553],\n",
       "                       ...,\n",
       "                       [-0.0705,  0.0605, -0.1933,  ..., -0.2671,  0.1019, -0.1490],\n",
       "                       [ 0.0701,  0.0906, -0.0620,  ..., -0.0149, -0.0144, -0.1427],\n",
       "                       [-0.1563,  0.0960, -0.0023,  ...,  0.1178,  0.0552,  0.1532]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.norms.w',\n",
       "               tensor([0.2850, 0.3023, 0.2806, 0.2770, 0.2713, 0.2849, 0.2808, 0.2160, 0.2665,\n",
       "                       0.2793, 0.1345, 0.2768, 0.2551, 0.2790, 0.2649, 0.2702, 0.2542, 0.2526,\n",
       "                       0.2837, 0.2656, 0.2484, 0.2960, 0.2846, 0.2475, 0.2595, 0.2864, 0.2667,\n",
       "                       0.2964, 0.2628, 0.2866, 0.3046, 0.2519, 0.2867, 0.2783, 0.2638, 0.2228,\n",
       "                       0.2779, 0.2955, 0.2709, 0.2708, 0.2811, 0.2665, 0.2782, 0.2995, 0.2267,\n",
       "                       0.3002, 0.2482, 0.2866, 0.2573, 0.2640, 0.2442, 0.2808, 0.2650, 0.2713,\n",
       "                       0.2690, 0.2434, 0.2591, 0.2640, 0.2756, 0.2854, 0.2870, 0.2528, 0.2844,\n",
       "                       0.2363, 0.2793, 0.2621, 0.2817, 0.2486, 0.2451, 0.2579, 0.2749, 0.2643,\n",
       "                       0.2742, 0.2767, 0.2715, 0.2648, 0.2519, 0.2931, 0.1343, 0.2446, 0.2816,\n",
       "                       0.2502, 0.2981, 0.2693, 0.2692, 0.2688, 0.2818, 0.2748, 0.2729, 0.2524,\n",
       "                       0.2512, 0.2076, 0.2830, 0.2696, 0.2857, 0.2616, 0.2139, 0.2538, 0.2633,\n",
       "                       0.2675, 0.2544, 0.2699, 0.3037, 0.2655, 0.2747, 0.2562, 0.2782, 0.1908,\n",
       "                       0.2717, 0.2818, 0.2716, 0.2787, 0.2976, 0.2734, 0.2559, 0.2694, 0.2591,\n",
       "                       0.2447, 0.2483, 0.2767, 0.2387, 0.2827, 0.2716, 0.2659, 0.0962, 0.2593,\n",
       "                       0.2618, 0.3057, 0.2751, 0.2787, 0.2775, 0.2613, 0.2648, 0.2630, 0.2733,\n",
       "                       0.2630, 0.2550, 0.2663, 0.2813, 0.2894, 0.2803, 0.2955, 0.3064, 0.2732,\n",
       "                       0.2754, 0.2481, 0.2582, 0.2652, 0.2748, 0.2635, 0.2967, 0.2612, 0.2693,\n",
       "                       0.2764, 0.2708, 0.2983, 0.2818, 0.1921, 0.2805, 0.2688, 0.2635, 0.2609,\n",
       "                       0.2945, 0.2528, 0.2501, 0.2395, 0.2692, 0.2658, 0.2720, 0.2681, 0.1324,\n",
       "                       0.2730, 0.2718, 0.2875, 0.2732, 0.2821, 0.2977, 0.2715, 0.2701, 0.2781,\n",
       "                       0.2550, 0.2743, 0.2987, 0.2601, 0.2556, 0.2770, 0.2789, 0.2802, 0.2804,\n",
       "                       0.2799, 0.2852, 0.2598, 0.2666, 0.2780, 0.2665, 0.2609, 0.2723, 0.2803,\n",
       "                       0.2448, 0.1995, 0.2821, 0.2758, 0.2741, 0.2581, 0.2776, 0.2488, 0.2652,\n",
       "                       0.2375, 0.2689, 0.2546, 0.2838, 0.2864, 0.2734, 0.2711, 0.2775, 0.2989,\n",
       "                       0.2780, 0.2423, 0.2430, 0.2864, 0.2773, 0.2767, 0.2850, 0.2611, 0.2694,\n",
       "                       0.2705, 0.2643, 0.2973, 0.2743, 0.2931, 0.2444, 0.2652, 0.2502, 0.2559,\n",
       "                       0.2684, 0.2430, 0.2848, 0.2772, 0.2323, 0.2249, 0.2665, 0.2780, 0.2663,\n",
       "                       0.2746, 0.2701, 0.2535, 0.2663, 0.2889, 0.2658, 0.2553, 0.2702, 0.2745,\n",
       "                       0.2685, 0.2884, 0.2831, 0.2720, 0.2696, 0.2839, 0.2858, 0.2871, 0.2859,\n",
       "                       0.2862, 0.2982, 0.2688, 0.2687, 0.2502, 0.2784, 0.2615, 0.2736, 0.2903,\n",
       "                       0.2685, 0.2823, 0.2492, 0.2818, 0.2484, 0.2817, 0.2782, 0.2801, 0.2865,\n",
       "                       0.2731, 0.2552, 0.2906, 0.2971, 0.2746, 0.2700, 0.2835, 0.2865, 0.2953,\n",
       "                       0.2670, 0.2360, 0.2838, 0.2801, 0.2666, 0.2817, 0.2725, 0.2682, 0.2756,\n",
       "                       0.2551, 0.2815, 0.2714, 0.2683, 0.2636, 0.2570, 0.2565, 0.2567, 0.2256,\n",
       "                       0.2595, 0.2715, 0.2788, 0.2080, 0.2801, 0.2513, 0.2825, 0.2662, 0.2776,\n",
       "                       0.2884, 0.2556, 0.2675, 0.2871, 0.2890, 0.2552, 0.2474, 0.2689, 0.2226,\n",
       "                       0.2360, 0.2061, 0.2806, 0.2924, 0.2814, 0.2789, 0.2720, 0.2555, 0.2459,\n",
       "                       0.2721, 0.2577, 0.2790, 0.2905, 0.3048, 0.2794, 0.2917, 0.2758, 0.2873,\n",
       "                       0.2599, 0.2738, 0.2617, 0.2700, 0.1831, 0.1809, 0.2620, 0.2429, 0.2971,\n",
       "                       0.2820, 0.2565, 0.2903, 0.2916, 0.2722, 0.2732, 0.2866, 0.2563, 0.2713,\n",
       "                       0.2838, 0.2827, 0.2874, 0.2627, 0.2760, 0.2786, 0.2679, 0.2792, 0.2758,\n",
       "                       0.2693, 0.2781, 0.2667, 0.2617, 0.2538, 0.2524, 0.2286, 0.2626, 0.2733,\n",
       "                       0.2744, 0.2614, 0.2886, 0.2333, 0.2795, 0.2767, 0.2769, 0.2757, 0.2644,\n",
       "                       0.1988, 0.2430, 0.2585, 0.2802, 0.2907, 0.2246, 0.2794, 0.2682, 0.2706,\n",
       "                       0.2881, 0.2447, 0.2891, 0.2644, 0.2444, 0.2948, 0.2812, 0.2370, 0.2723,\n",
       "                       0.2728, 0.2793, 0.2771, 0.1062, 0.2465, 0.2708, 0.2598, 0.2628, 0.2565,\n",
       "                       0.2944, 0.2559, 0.2723, 0.2994, 0.2573, 0.2559, 0.2672, 0.2911, 0.2798,\n",
       "                       0.2696, 0.2507, 0.2553, 0.3058, 0.2565, 0.2721, 0.2588, 0.2771, 0.2817,\n",
       "                       0.2573, 0.2707, 0.2726, 0.2657, 0.2620, 0.2908, 0.2751, 0.2682, 0.2638,\n",
       "                       0.2692, 0.2966, 0.2115, 0.2702, 0.2911, 0.2530, 0.2888, 0.2850, 0.2849,\n",
       "                       0.2803, 0.2527, 0.2552, 0.2679, 0.2718, 0.2724, 0.2364, 0.2648, 0.2592,\n",
       "                       0.2678, 0.2872, 0.2691, 0.1741, 0.2675, 0.2774, 0.2650, 0.2695, 0.2932,\n",
       "                       0.2746, 0.2748, 0.2671, 0.2634, 0.2779, 0.2535, 0.2940, 0.2833, 0.2743,\n",
       "                       0.2554, 0.2781, 0.2867, 0.1810, 0.2863, 0.2702, 0.2759, 0.2628, 0.2718,\n",
       "                       0.2880, 0.2743, 0.2539, 0.2357, 0.2915, 0.2674, 0.2443, 0.2630, 0.2762,\n",
       "                       0.2517, 0.2646, 0.2836, 0.2720, 0.2693, 0.2601, 0.2831, 0.2809, 0.2445,\n",
       "                       0.2492, 0.2770, 0.2654, 0.2786, 0.2854, 0.2478, 0.2916, 0.3008, 0.2773,\n",
       "                       0.2681, 0.2345, 0.2741, 0.2732, 0.2386, 0.2895, 0.2746, 0.2817, 0.2767,\n",
       "                       0.2818, 0.2768, 0.2923, 0.3095, 0.2667, 0.2563, 0.2290, 0.2745, 0.2899,\n",
       "                       0.2534, 0.2739, 0.2997, 0.2864, 0.2608, 0.2767, 0.2544, 0.2642, 0.2594,\n",
       "                       0.2682, 0.2673, 0.2688, 0.2373, 0.2784, 0.2779, 0.2969, 0.2365, 0.2784,\n",
       "                       0.2645, 0.2724, 0.2753, 0.2728, 0.2459, 0.2785, 0.2782, 0.1499, 0.2519,\n",
       "                       0.2378, 0.2760, 0.2742, 0.2752, 0.2766, 0.2592, 0.2571, 0.2775, 0.2646,\n",
       "                       0.2643, 0.2469, 0.2599, 0.1390, 0.2709, 0.2697, 0.2534, 0.2695, 0.2951,\n",
       "                       0.2748, 0.2872, 0.2753, 0.2532, 0.2485, 0.2811, 0.2907, 0.2962, 0.2671,\n",
       "                       0.2745, 0.2717, 0.1966, 0.2622, 0.2784, 0.2933, 0.2401, 0.2780, 0.2766,\n",
       "                       0.0856, 0.2584, 0.2927, 0.2662, 0.2746, 0.2539, 0.2819, 0.2797, 0.2719,\n",
       "                       0.2787, 0.2712, 0.2581, 0.2608, 0.2812, 0.2515, 0.2642, 0.3038, 0.2265,\n",
       "                       0.2579, 0.2906, 0.2605, 0.2699, 0.2751, 0.2757, 0.2819, 0.2877, 0.2768,\n",
       "                       0.2565, 0.2105, 0.2659, 0.2800, 0.2586, 0.2806, 0.2648, 0.2809, 0.2931,\n",
       "                       0.2721, 0.2939, 0.2762, 0.1266, 0.2867, 0.2975, 0.2670, 0.2810, 0.2630,\n",
       "                       0.2735, 0.2700, 0.2601, 0.2819, 0.2897, 0.2629, 0.2737, 0.2650, 0.2747,\n",
       "                       0.2657, 0.2846, 0.2979, 0.2630, 0.2429, 0.2802, 0.2500, 0.2729, 0.2828,\n",
       "                       0.2768, 0.2861, 0.2828, 0.2616, 0.2310, 0.2784, 0.2198, 0.2806, 0.2345,\n",
       "                       0.2724, 0.2690, 0.2749, 0.2530, 0.1021, 0.2817, 0.2740, 0.2732, 0.2494,\n",
       "                       0.2981, 0.2845, 0.2748, 0.2719, 0.2712, 0.2887, 0.2455, 0.2643, 0.2846,\n",
       "                       0.2843, 0.2289, 0.2217, 0.2942, 0.2675, 0.2719, 0.2721, 0.2633, 0.2440,\n",
       "                       0.2856, 0.2795, 0.2820, 0.2766, 0.2758, 0.2872, 0.2991, 0.2085, 0.2734,\n",
       "                       0.2174, 0.2652, 0.2821, 0.2662, 0.1942, 0.2947, 0.2593, 0.2654, 0.2713,\n",
       "                       0.1670, 0.2440, 0.2736, 0.2812, 0.2791, 0.2839, 0.2805, 0.2680, 0.2717,\n",
       "                       0.2740, 0.2624, 0.2657, 0.2619, 0.2935, 0.2664, 0.2652, 0.2351, 0.2649,\n",
       "                       0.2687, 0.2763, 0.2500, 0.2753, 0.2638, 0.2834, 0.2729, 0.2779, 0.2660,\n",
       "                       0.2847, 0.2505, 0.2178, 0.2730, 0.2891, 0.2449, 0.2377, 0.2879, 0.2964,\n",
       "                       0.2872, 0.2804, 0.2920, 0.2657, 0.2950, 0.2684, 0.2541, 0.2514, 0.2783,\n",
       "                       0.2674, 0.2776, 0.2738, 0.2798, 0.2835, 0.2725, 0.2434, 0.2724, 0.2726,\n",
       "                       0.2797, 0.2806, 0.2693], device='cuda:0')),\n",
       "              ('model.layers.1.attention.wq.weight',\n",
       "               tensor([[ 0.1390, -0.1411,  0.0004,  ...,  0.2166, -0.0291, -0.1342],\n",
       "                       [ 0.0057, -0.0263, -0.1326,  ..., -0.0381, -0.0341,  0.1987],\n",
       "                       [-0.0964, -0.0650,  0.1598,  ..., -0.2221,  0.0157,  0.0901],\n",
       "                       ...,\n",
       "                       [ 0.0146,  0.0882, -0.0193,  ..., -0.3531, -0.0884,  0.0472],\n",
       "                       [-0.1676,  0.0052, -0.1263,  ...,  0.2171, -0.0755,  0.2778],\n",
       "                       [ 0.0967, -0.1660, -0.1133,  ..., -0.0924, -0.2848,  0.0450]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.attention.wk.weight',\n",
       "               tensor([[-0.1904,  0.0781, -0.0260,  ..., -0.0074, -0.1658,  0.1359],\n",
       "                       [-0.1281,  0.0373,  0.0576,  ..., -0.0533,  0.0069, -0.1535],\n",
       "                       [ 0.0775, -0.0207,  0.0156,  ...,  0.2091, -0.1287,  0.0878],\n",
       "                       ...,\n",
       "                       [-0.1049, -0.1896, -0.2463,  ...,  0.1776,  0.2710,  0.0579],\n",
       "                       [ 0.0821,  0.1606,  0.1427,  ..., -0.2233,  0.1811,  0.1808],\n",
       "                       [ 0.1790, -0.2561, -0.1975,  ..., -0.3736, -0.0985, -0.0709]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.attention.wv.weight',\n",
       "               tensor([[-0.0717,  0.0770, -0.0991,  ...,  0.0491, -0.0862,  0.0481],\n",
       "                       [-0.0431, -0.1444, -0.1412,  ...,  0.0051, -0.0497,  0.0012],\n",
       "                       [-0.1839,  0.0764,  0.2220,  ..., -0.0076,  0.0298,  0.1254],\n",
       "                       ...,\n",
       "                       [ 0.0397, -0.0081, -0.1985,  ..., -0.1305,  0.1607, -0.0330],\n",
       "                       [ 0.0062, -0.0797,  0.1006,  ...,  0.1296, -0.0172, -0.1084],\n",
       "                       [ 0.1955,  0.1953, -0.0558,  ...,  0.2237, -0.1092,  0.0137]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.attention.wo.weight',\n",
       "               tensor([[ 0.1373, -0.0884,  0.0753,  ..., -0.1109, -0.0735, -0.1243],\n",
       "                       [-0.0710, -0.0559,  0.1128,  ..., -0.0860, -0.0689,  0.1237],\n",
       "                       [-0.1219, -0.0910, -0.1905,  ...,  0.0503,  0.0199, -0.2239],\n",
       "                       ...,\n",
       "                       [-0.1278, -0.2060,  0.0073,  ...,  0.0131,  0.0392,  0.0389],\n",
       "                       [ 0.0973,  0.0558, -0.1478,  ...,  0.0671,  0.0944, -0.2563],\n",
       "                       [-0.2048, -0.0466, -0.0445,  ..., -0.0501, -0.0100, -0.1828]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.mlp.linear1.weight',\n",
       "               tensor([[-0.1883,  0.2186, -0.0378,  ...,  0.1630, -0.0320,  0.1056],\n",
       "                       [-0.1005,  0.0234, -0.0973,  ...,  0.0336,  0.0236,  0.0625],\n",
       "                       [-0.1987,  0.2180, -0.3647,  ...,  0.2351,  0.0707, -0.1502],\n",
       "                       ...,\n",
       "                       [-0.2060, -0.1977,  0.1359,  ..., -0.0702,  0.0640,  0.0009],\n",
       "                       [-0.1134, -0.2038, -0.1146,  ...,  0.0463, -0.1863, -0.0404],\n",
       "                       [-0.1248, -0.0313, -0.0459,  ...,  0.2766, -0.0022,  0.0652]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.mlp.linear2.weight',\n",
       "               tensor([[-0.2300, -0.1832,  0.1219,  ..., -0.1696,  0.1809, -0.0236],\n",
       "                       [ 0.1215, -0.0513, -0.1755,  ...,  0.1809,  0.0510, -0.0402],\n",
       "                       [ 0.0611,  0.0124,  0.0978,  ...,  0.0641,  0.0073, -0.0616],\n",
       "                       ...,\n",
       "                       [-0.0740,  0.0539, -0.1510,  ...,  0.1079,  0.0107,  0.0847],\n",
       "                       [ 0.0589, -0.0205,  0.1125,  ..., -0.1424,  0.0640, -0.4017],\n",
       "                       [ 0.0836, -0.1071, -0.1104,  ...,  0.1783, -0.1031,  0.0903]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.1.mlp.linear3.weight',\n",
       "               tensor([[ 2.8169e-02,  1.3795e-01,  1.2291e-01,  ..., -1.5917e-02,\n",
       "                         4.2374e-02,  7.5753e-02],\n",
       "                       [-4.3080e-02,  2.7758e-03, -6.1867e-02,  ..., -1.5814e-01,\n",
       "                         1.9948e-01,  8.1876e-02],\n",
       "                       [-3.9830e-02,  1.6483e-01,  2.1466e-02,  ...,  1.9038e-02,\n",
       "                         1.0850e-02,  6.9070e-02],\n",
       "                       ...,\n",
       "                       [-1.4547e-01,  3.7087e-01, -1.2494e-01,  ...,  2.5284e-01,\n",
       "                        -1.9718e-01,  4.0925e-02],\n",
       "                       [ 3.1494e-01, -3.9862e-01, -2.6485e-01,  ...,  6.8914e-02,\n",
       "                         3.0751e-04, -2.9491e-02],\n",
       "                       [ 1.8489e-02,  1.3556e-01, -6.8992e-02,  ...,  8.1240e-02,\n",
       "                         1.2838e-01, -1.5892e-01]], device='cuda:0')),\n",
       "              ('model.layers.2.norms.w',\n",
       "               tensor([0.4681, 0.4768, 0.4979, 0.4796, 0.4787, 0.4978, 0.4891, 0.3583, 0.4853,\n",
       "                       0.4568, 0.3493, 0.5096, 0.4920, 0.4754, 0.4911, 0.4550, 0.4836, 0.4716,\n",
       "                       0.5082, 0.4717, 0.4764, 0.4969, 0.5001, 0.4742, 0.4769, 0.4928, 0.5073,\n",
       "                       0.4935, 0.4778, 0.4800, 0.4714, 0.4695, 0.4800, 0.4438, 0.5010, 0.3854,\n",
       "                       0.4670, 0.4291, 0.4522, 0.4548, 0.4495, 0.4992, 0.4764, 0.4663, 0.3920,\n",
       "                       0.5112, 0.5093, 0.4642, 0.4762, 0.4675, 0.4229, 0.4698, 0.4930, 0.4419,\n",
       "                       0.4656, 0.4159, 0.4541, 0.4975, 0.5032, 0.4668, 0.4352, 0.4452, 0.5023,\n",
       "                       0.4892, 0.4047, 0.4240, 0.4542, 0.4481, 0.4755, 0.4681, 0.4448, 0.4434,\n",
       "                       0.4738, 0.4573, 0.4767, 0.4524, 0.4630, 0.4650, 0.3533, 0.4597, 0.4816,\n",
       "                       0.4427, 0.5155, 0.4974, 0.5019, 0.4823, 0.4473, 0.4682, 0.5056, 0.4627,\n",
       "                       0.4707, 0.3953, 0.4944, 0.4934, 0.4617, 0.4885, 0.3848, 0.4966, 0.4877,\n",
       "                       0.4735, 0.4955, 0.4758, 0.5002, 0.4687, 0.4749, 0.4588, 0.4665, 0.4237,\n",
       "                       0.4899, 0.4475, 0.4541, 0.4923, 0.4811, 0.4649, 0.4883, 0.4862, 0.4628,\n",
       "                       0.4487, 0.4541, 0.4885, 0.4769, 0.4683, 0.4924, 0.4735, 0.2650, 0.4634,\n",
       "                       0.4503, 0.4674, 0.4815, 0.4578, 0.4865, 0.4890, 0.4840, 0.4635, 0.4888,\n",
       "                       0.4626, 0.4895, 0.4692, 0.5135, 0.5045, 0.4589, 0.4720, 0.4634, 0.4836,\n",
       "                       0.4835, 0.4564, 0.4986, 0.4693, 0.4768, 0.4892, 0.4701, 0.4463, 0.4758,\n",
       "                       0.4740, 0.4987, 0.5104, 0.5177, 0.4055, 0.4849, 0.4762, 0.4793, 0.4446,\n",
       "                       0.4524, 0.4715, 0.4708, 0.4336, 0.4484, 0.5274, 0.4999, 0.5148, 0.2581,\n",
       "                       0.4950, 0.4624, 0.4941, 0.5011, 0.5062, 0.4788, 0.4330, 0.4854, 0.4642,\n",
       "                       0.4772, 0.4891, 0.4852, 0.4874, 0.4718, 0.5092, 0.4391, 0.5075, 0.4285,\n",
       "                       0.4697, 0.4646, 0.4805, 0.4380, 0.5010, 0.5033, 0.4651, 0.4912, 0.5082,\n",
       "                       0.4803, 0.4891, 0.4732, 0.4863, 0.4494, 0.4840, 0.4734, 0.4752, 0.4426,\n",
       "                       0.4571, 0.4810, 0.4614, 0.4462, 0.4471, 0.4982, 0.4967, 0.4747, 0.4871,\n",
       "                       0.4697, 0.5014, 0.4648, 0.4930, 0.4699, 0.4669, 0.4898, 0.4828, 0.4912,\n",
       "                       0.4701, 0.4733, 0.4386, 0.4773, 0.5329, 0.4627, 0.4814, 0.4854, 0.4776,\n",
       "                       0.4783, 0.4509, 0.5256, 0.4987, 0.4787, 0.4392, 0.5167, 0.4822, 0.4861,\n",
       "                       0.4743, 0.4566, 0.4795, 0.5116, 0.5277, 0.4444, 0.5109, 0.4795, 0.4730,\n",
       "                       0.4751, 0.4781, 0.4687, 0.4994, 0.4904, 0.4982, 0.5208, 0.4904, 0.5122,\n",
       "                       0.4853, 0.4925, 0.4840, 0.4517, 0.4509, 0.4736, 0.4773, 0.4926, 0.4821,\n",
       "                       0.4782, 0.4880, 0.4477, 0.4751, 0.3922, 0.4688, 0.4803, 0.4887, 0.5043,\n",
       "                       0.5097, 0.4719, 0.5068, 0.4860, 0.4810, 0.4795, 0.4722, 0.4691, 0.5145,\n",
       "                       0.5019, 0.4099, 0.4734, 0.4947, 0.4655, 0.4658, 0.4748, 0.4577, 0.4818,\n",
       "                       0.4688, 0.5017, 0.4857, 0.4857, 0.4833, 0.4996, 0.4490, 0.4681, 0.4713,\n",
       "                       0.4826, 0.4658, 0.4761, 0.3692, 0.4804, 0.4681, 0.4492, 0.4672, 0.4853,\n",
       "                       0.4755, 0.4976, 0.4992, 0.4980, 0.4792, 0.4739, 0.4812, 0.5074, 0.4416,\n",
       "                       0.4151, 0.3867, 0.5056, 0.4616, 0.4440, 0.4891, 0.4689, 0.4821, 0.4441,\n",
       "                       0.5011, 0.4721, 0.4658, 0.5280, 0.4680, 0.5025, 0.4898, 0.4978, 0.4864,\n",
       "                       0.4632, 0.4932, 0.4728, 0.4678, 0.3410, 0.3829, 0.4879, 0.4463, 0.5050,\n",
       "                       0.4719, 0.4782, 0.4776, 0.4629, 0.4964, 0.4778, 0.4706, 0.4462, 0.4304,\n",
       "                       0.4870, 0.4724, 0.4883, 0.4264, 0.4895, 0.4680, 0.4560, 0.5000, 0.5024,\n",
       "                       0.4619, 0.4947, 0.4747, 0.5113, 0.4895, 0.4944, 0.4675, 0.4684, 0.4279,\n",
       "                       0.4907, 0.4839, 0.4989, 0.4696, 0.4767, 0.4756, 0.4838, 0.4634, 0.4722,\n",
       "                       0.4416, 0.5026, 0.4845, 0.4927, 0.4864, 0.4748, 0.4798, 0.5046, 0.4731,\n",
       "                       0.4975, 0.4702, 0.4852, 0.4256, 0.4319, 0.4716, 0.4389, 0.4347, 0.4481,\n",
       "                       0.4781, 0.4786, 0.4679, 0.2724, 0.4488, 0.4593, 0.5113, 0.4719, 0.3334,\n",
       "                       0.5195, 0.4428, 0.5062, 0.5364, 0.5027, 0.4698, 0.4896, 0.4860, 0.4880,\n",
       "                       0.4594, 0.4215, 0.4181, 0.4329, 0.4649, 0.4806, 0.5075, 0.4682, 0.4840,\n",
       "                       0.5262, 0.5060, 0.4731, 0.4751, 0.5045, 0.4586, 0.4694, 0.4583, 0.5133,\n",
       "                       0.4635, 0.4979, 0.3110, 0.4382, 0.4730, 0.4849, 0.4835, 0.4464, 0.4797,\n",
       "                       0.4917, 0.4681, 0.4867, 0.4744, 0.4683, 0.4610, 0.4566, 0.4466, 0.4674,\n",
       "                       0.4718, 0.4678, 0.4934, 0.4204, 0.4336, 0.4847, 0.4842, 0.4870, 0.4845,\n",
       "                       0.4933, 0.4752, 0.4950, 0.5048, 0.4644, 0.4513, 0.4561, 0.4624, 0.4971,\n",
       "                       0.4303, 0.4881, 0.4826, 0.4197, 0.5278, 0.5049, 0.4622, 0.5180, 0.5266,\n",
       "                       0.4830, 0.4480, 0.4827, 0.3957, 0.5150, 0.5049, 0.4589, 0.5277, 0.4982,\n",
       "                       0.4595, 0.4809, 0.4804, 0.4673, 0.5036, 0.4910, 0.4836, 0.5113, 0.4899,\n",
       "                       0.4960, 0.4631, 0.4867, 0.4731, 0.4804, 0.4881, 0.4942, 0.4597, 0.4928,\n",
       "                       0.4816, 0.4540, 0.5055, 0.4451, 0.4327, 0.4756, 0.5093, 0.4793, 0.4792,\n",
       "                       0.4621, 0.4863, 0.4554, 0.4753, 0.4710, 0.5002, 0.4215, 0.4611, 0.4604,\n",
       "                       0.4801, 0.5043, 0.4904, 0.4812, 0.4606, 0.4896, 0.5215, 0.4715, 0.4675,\n",
       "                       0.4592, 0.4832, 0.4588, 0.4709, 0.4646, 0.4810, 0.4653, 0.4663, 0.4781,\n",
       "                       0.5165, 0.4673, 0.4970, 0.4849, 0.5076, 0.4772, 0.4883, 0.1668, 0.4427,\n",
       "                       0.4566, 0.5008, 0.5115, 0.4797, 0.5100, 0.4811, 0.4795, 0.4698, 0.4875,\n",
       "                       0.4703, 0.4467, 0.4627, 0.3506, 0.4656, 0.5081, 0.4543, 0.4497, 0.4958,\n",
       "                       0.4924, 0.4653, 0.5178, 0.4831, 0.4684, 0.4855, 0.4806, 0.4665, 0.4987,\n",
       "                       0.4994, 0.5205, 0.3953, 0.4751, 0.4952, 0.4836, 0.4782, 0.4835, 0.4889,\n",
       "                       0.1642, 0.4626, 0.4932, 0.4684, 0.5044, 0.4847, 0.4536, 0.5169, 0.5158,\n",
       "                       0.4630, 0.4970, 0.4699, 0.4602, 0.4737, 0.4759, 0.4979, 0.4673, 0.4666,\n",
       "                       0.4761, 0.5057, 0.4421, 0.5067, 0.5107, 0.4898, 0.5190, 0.4645, 0.4770,\n",
       "                       0.4554, 0.4707, 0.4841, 0.5017, 0.4853, 0.4904, 0.4678, 0.4637, 0.5344,\n",
       "                       0.4687, 0.4861, 0.4948, 0.1537, 0.4741, 0.4853, 0.4790, 0.4766, 0.5093,\n",
       "                       0.5163, 0.4871, 0.5011, 0.4722, 0.5043, 0.4710, 0.4869, 0.4431, 0.4628,\n",
       "                       0.5070, 0.4822, 0.4951, 0.4909, 0.4507, 0.4909, 0.4745, 0.4910, 0.4758,\n",
       "                       0.4929, 0.5117, 0.5012, 0.5079, 0.4403, 0.4772, 0.4537, 0.5104, 0.4697,\n",
       "                       0.4753, 0.4669, 0.4982, 0.4630, 0.2961, 0.4361, 0.4864, 0.4811, 0.4657,\n",
       "                       0.4852, 0.4643, 0.4871, 0.4865, 0.4953, 0.4882, 0.4690, 0.4437, 0.5005,\n",
       "                       0.5199, 0.4550, 0.4573, 0.4982, 0.4712, 0.4616, 0.4750, 0.4977, 0.4639,\n",
       "                       0.4639, 0.4917, 0.5129, 0.5008, 0.4770, 0.5040, 0.4760, 0.4424, 0.4723,\n",
       "                       0.4408, 0.4819, 0.4664, 0.4510, 0.3999, 0.4643, 0.4661, 0.4843, 0.4868,\n",
       "                       0.2980, 0.4429, 0.4713, 0.4663, 0.4955, 0.4863, 0.4895, 0.4453, 0.4879,\n",
       "                       0.4851, 0.4790, 0.5190, 0.4961, 0.4703, 0.4934, 0.4856, 0.4736, 0.4707,\n",
       "                       0.5237, 0.4774, 0.4591, 0.4879, 0.5249, 0.4620, 0.4983, 0.4460, 0.4772,\n",
       "                       0.5248, 0.4931, 0.4539, 0.4664, 0.4482, 0.4587, 0.4756, 0.4695, 0.5020,\n",
       "                       0.4969, 0.5067, 0.5351, 0.4532, 0.4800, 0.4630, 0.4914, 0.4786, 0.4738,\n",
       "                       0.4813, 0.4653, 0.4757, 0.4660, 0.5156, 0.4748, 0.4585, 0.4702, 0.4744,\n",
       "                       0.5077, 0.4771, 0.4978], device='cuda:0')),\n",
       "              ('model.layers.2.attention.wq.weight',\n",
       "               tensor([[-0.0931, -0.0899, -0.0476,  ..., -0.0388,  0.0160,  0.0684],\n",
       "                       [ 0.0915, -0.0772,  0.0888,  ..., -0.0536,  0.0490,  0.0252],\n",
       "                       [-0.0233,  0.0752,  0.0611,  ..., -0.0291, -0.0597, -0.0169],\n",
       "                       ...,\n",
       "                       [-0.0076,  0.0072,  0.0788,  ..., -0.1305,  0.1074,  0.0527],\n",
       "                       [ 0.1212,  0.0012,  0.0701,  ...,  0.1449,  0.0511,  0.0196],\n",
       "                       [-0.1632,  0.1386, -0.0026,  ...,  0.0246, -0.0138,  0.0764]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.2.attention.wk.weight',\n",
       "               tensor([[-0.0321, -0.0661,  0.0804,  ...,  0.0106,  0.0083,  0.0946],\n",
       "                       [-0.1371,  0.0697,  0.0590,  ...,  0.0139,  0.0206, -0.0732],\n",
       "                       [-0.0840, -0.0456, -0.0267,  ...,  0.0406, -0.1334,  0.0233],\n",
       "                       ...,\n",
       "                       [ 0.0942,  0.0544, -0.0069,  ...,  0.0277,  0.1355, -0.0186],\n",
       "                       [ 0.0808, -0.0282, -0.0750,  ..., -0.1543,  0.1143, -0.2064],\n",
       "                       [-0.0561,  0.0839,  0.1005,  ...,  0.0551,  0.0509,  0.0722]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.2.attention.wv.weight',\n",
       "               tensor([[-0.0786, -0.0714,  0.1672,  ...,  0.2578, -0.1166, -0.0871],\n",
       "                       [-0.1554,  0.0166,  0.2327,  ..., -0.0783, -0.1546, -0.0997],\n",
       "                       [ 0.0281,  0.0403, -0.1071,  ...,  0.1267, -0.2250,  0.0398],\n",
       "                       ...,\n",
       "                       [-0.0444, -0.1805,  0.0633,  ..., -0.3976, -0.0754,  0.0187],\n",
       "                       [-0.0402,  0.1862, -0.0705,  ...,  0.2089, -0.0413,  0.0556],\n",
       "                       [-0.0930,  0.0067, -0.1444,  ...,  0.1743, -0.0089, -0.1559]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.2.attention.wo.weight',\n",
       "               tensor([[ 0.0469, -0.2618, -0.0844,  ...,  0.1054, -0.0209,  0.0891],\n",
       "                       [ 0.0448, -0.1072,  0.0072,  ...,  0.0150, -0.1512, -0.0726],\n",
       "                       [-0.0294, -0.0091,  0.1112,  ..., -0.0756,  0.0413, -0.0953],\n",
       "                       ...,\n",
       "                       [-0.2143,  0.0131, -0.1114,  ...,  0.2341, -0.0880,  0.1006],\n",
       "                       [-0.0345, -0.0916,  0.0510,  ...,  0.2025, -0.1056, -0.1063],\n",
       "                       [-0.1728,  0.0595, -0.0672,  ..., -0.0965,  0.0561,  0.2288]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.2.mlp.linear1.weight',\n",
       "               tensor([[ 0.1162,  0.0618, -0.1480,  ...,  0.0490, -0.1376, -0.0047],\n",
       "                       [ 0.0733, -0.2002,  0.1036,  ...,  0.1217, -0.1062,  0.0718],\n",
       "                       [-0.0519, -0.0881,  0.0924,  ..., -0.1132, -0.0325, -0.1846],\n",
       "                       ...,\n",
       "                       [-0.0913,  0.1152,  0.0178,  ..., -0.1537,  0.1346,  0.0568],\n",
       "                       [ 0.0205, -0.0309, -0.1551,  ...,  0.0325, -0.0835,  0.0673],\n",
       "                       [-0.0164,  0.1002,  0.0081,  ...,  0.2030, -0.1028,  0.0767]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.2.mlp.linear2.weight',\n",
       "               tensor([[-0.0017,  0.0239, -0.0785,  ...,  0.0200, -0.0143, -0.0294],\n",
       "                       [ 0.0746,  0.1261,  0.2434,  ..., -0.2434,  0.0111, -0.1399],\n",
       "                       [ 0.0178, -0.0230,  0.1227,  ..., -0.0609, -0.2859, -0.0543],\n",
       "                       ...,\n",
       "                       [ 0.0475,  0.0169, -0.0600,  ..., -0.0082, -0.0512, -0.0843],\n",
       "                       [ 0.0108,  0.0892, -0.0508,  ..., -0.0138, -0.0311, -0.0184],\n",
       "                       [ 0.1767,  0.0376,  0.1009,  ..., -0.2604,  0.2090, -0.0123]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.2.mlp.linear3.weight',\n",
       "               tensor([[ 0.3222,  0.1445, -0.1316,  ...,  0.1332,  0.1210, -0.0847],\n",
       "                       [-0.1807, -0.0722,  0.2296,  ...,  0.0391, -0.1160,  0.0790],\n",
       "                       [ 0.3821,  0.0148,  0.1512,  ..., -0.0409,  0.1447, -0.0234],\n",
       "                       ...,\n",
       "                       [ 0.2550, -0.2014, -0.0363,  ..., -0.1217,  0.0891,  0.3031],\n",
       "                       [-0.2301,  0.1139,  0.1537,  ...,  0.0460, -0.0917, -0.1570],\n",
       "                       [-0.1362,  0.0547, -0.0808,  ...,  0.0401, -0.1855,  0.0121]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.norms.w',\n",
       "               tensor([0.5723, 0.6154, 0.5936, 0.5990, 0.6149, 0.6304, 0.6243, 0.5052, 0.6174,\n",
       "                       0.5837, 0.5048, 0.6242, 0.6422, 0.5856, 0.5811, 0.6027, 0.5957, 0.5773,\n",
       "                       0.5799, 0.6085, 0.6274, 0.5805, 0.5948, 0.6149, 0.5991, 0.5801, 0.6064,\n",
       "                       0.5522, 0.5765, 0.6006, 0.6015, 0.5722, 0.5841, 0.5619, 0.6182, 0.5351,\n",
       "                       0.5734, 0.5999, 0.5952, 0.6026, 0.5710, 0.5883, 0.5973, 0.6297, 0.5043,\n",
       "                       0.6069, 0.6110, 0.6039, 0.6246, 0.5748, 0.5488, 0.6089, 0.6168, 0.6135,\n",
       "                       0.6345, 0.5933, 0.5767, 0.6083, 0.5959, 0.5890, 0.5897, 0.5921, 0.5978,\n",
       "                       0.6183, 0.5754, 0.6081, 0.6383, 0.6132, 0.5862, 0.5931, 0.5924, 0.5953,\n",
       "                       0.6168, 0.6017, 0.5883, 0.5824, 0.5959, 0.5675, 0.5068, 0.6275, 0.5851,\n",
       "                       0.5843, 0.5827, 0.6058, 0.6178, 0.5814, 0.5999, 0.6026, 0.6262, 0.6096,\n",
       "                       0.6052, 0.5394, 0.5914, 0.5845, 0.6045, 0.5751, 0.5705, 0.6305, 0.5781,\n",
       "                       0.5877, 0.6085, 0.5899, 0.6085, 0.6031, 0.5820, 0.5832, 0.5889, 0.6332,\n",
       "                       0.6189, 0.5969, 0.6329, 0.6644, 0.6271, 0.6143, 0.6065, 0.6472, 0.6019,\n",
       "                       0.6027, 0.5828, 0.5548, 0.6256, 0.5991, 0.6073, 0.6169, 0.3768, 0.5928,\n",
       "                       0.5924, 0.5866, 0.6220, 0.5551, 0.6001, 0.6066, 0.6062, 0.6020, 0.6371,\n",
       "                       0.5852, 0.5838, 0.6359, 0.5986, 0.5873, 0.5901, 0.5843, 0.5914, 0.6211,\n",
       "                       0.6125, 0.5807, 0.6078, 0.5926, 0.5845, 0.5929, 0.6153, 0.5968, 0.6299,\n",
       "                       0.6188, 0.6023, 0.5991, 0.5973, 0.5810, 0.6342, 0.6225, 0.5989, 0.6250,\n",
       "                       0.5787, 0.6229, 0.5815, 0.5806, 0.5664, 0.6525, 0.6246, 0.6255, 0.3937,\n",
       "                       0.5878, 0.6222, 0.6117, 0.6154, 0.6222, 0.6157, 0.6142, 0.6114, 0.5916,\n",
       "                       0.5762, 0.6199, 0.5836, 0.5827, 0.6251, 0.6025, 0.5867, 0.5754, 0.5667,\n",
       "                       0.5816, 0.5871, 0.5739, 0.5911, 0.5625, 0.6292, 0.6084, 0.6225, 0.6381,\n",
       "                       0.6148, 0.6464, 0.5892, 0.5967, 0.6086, 0.6153, 0.5989, 0.6249, 0.5890,\n",
       "                       0.6074, 0.5787, 0.6023, 0.5930, 0.6041, 0.5851, 0.6064, 0.6015, 0.5812,\n",
       "                       0.6239, 0.6119, 0.5944, 0.5854, 0.5870, 0.6159, 0.5895, 0.6048, 0.6171,\n",
       "                       0.5686, 0.5747, 0.5713, 0.5786, 0.6417, 0.5892, 0.5996, 0.6519, 0.6510,\n",
       "                       0.6100, 0.6128, 0.6420, 0.6164, 0.6368, 0.6485, 0.6295, 0.6018, 0.6035,\n",
       "                       0.6171, 0.5989, 0.6228, 0.6142, 0.5763, 0.5897, 0.6527, 0.5886, 0.6006,\n",
       "                       0.5862, 0.6070, 0.5884, 0.6085, 0.6028, 0.6041, 0.6269, 0.6163, 0.5990,\n",
       "                       0.5749, 0.6055, 0.6218, 0.5850, 0.5810, 0.6044, 0.6563, 0.5844, 0.5860,\n",
       "                       0.5880, 0.5829, 0.5793, 0.6300, 0.5805, 0.5650, 0.5837, 0.6054, 0.5937,\n",
       "                       0.6333, 0.5841, 0.5905, 0.5989, 0.6149, 0.6112, 0.6130, 0.5771, 0.5892,\n",
       "                       0.6027, 0.6050, 0.5693, 0.5695, 0.6266, 0.5713, 0.6198, 0.6119, 0.6185,\n",
       "                       0.5882, 0.6305, 0.5894, 0.6164, 0.5775, 0.6258, 0.5828, 0.5736, 0.5892,\n",
       "                       0.6070, 0.5998, 0.6406, 0.5670, 0.6232, 0.5952, 0.5931, 0.6337, 0.5834,\n",
       "                       0.6142, 0.6108, 0.6074, 0.6102, 0.6041, 0.5945, 0.5872, 0.5886, 0.5843,\n",
       "                       0.5713, 0.5408, 0.6241, 0.6096, 0.5726, 0.6220, 0.5824, 0.6123, 0.5948,\n",
       "                       0.6090, 0.6170, 0.6095, 0.5862, 0.6108, 0.6196, 0.5939, 0.6420, 0.6059,\n",
       "                       0.5765, 0.6278, 0.5795, 0.5641, 0.5671, 0.5213, 0.5858, 0.5733, 0.5960,\n",
       "                       0.5834, 0.6093, 0.5500, 0.5717, 0.6071, 0.5988, 0.6124, 0.5676, 0.5508,\n",
       "                       0.6373, 0.5932, 0.5963, 0.5824, 0.5820, 0.5865, 0.6238, 0.5876, 0.6252,\n",
       "                       0.5932, 0.6114, 0.6075, 0.6037, 0.6288, 0.6233, 0.5816, 0.5962, 0.6019,\n",
       "                       0.5949, 0.6362, 0.6123, 0.6332, 0.5694, 0.6142, 0.6044, 0.5972, 0.5614,\n",
       "                       0.5464, 0.6684, 0.6322, 0.6439, 0.5980, 0.6077, 0.5885, 0.6267, 0.5907,\n",
       "                       0.6095, 0.5997, 0.5839, 0.5881, 0.5708, 0.6020, 0.5810, 0.5241, 0.5777,\n",
       "                       0.6073, 0.5981, 0.6111, 0.4148, 0.6006, 0.5948, 0.6299, 0.6226, 0.5251,\n",
       "                       0.5908, 0.5972, 0.6230, 0.5946, 0.6124, 0.6100, 0.5793, 0.6281, 0.5989,\n",
       "                       0.6101, 0.5550, 0.5875, 0.5902, 0.6195, 0.6208, 0.5571, 0.5792, 0.5401,\n",
       "                       0.6104, 0.6068, 0.6275, 0.5968, 0.6112, 0.5912, 0.6043, 0.6115, 0.6525,\n",
       "                       0.6000, 0.6145, 0.3893, 0.5586, 0.6120, 0.5879, 0.6012, 0.5435, 0.6039,\n",
       "                       0.6026, 0.6023, 0.5936, 0.5889, 0.5660, 0.6014, 0.5922, 0.5908, 0.5656,\n",
       "                       0.5931, 0.5830, 0.6153, 0.5799, 0.5997, 0.5928, 0.5922, 0.6197, 0.6044,\n",
       "                       0.6019, 0.5716, 0.6004, 0.5656, 0.6085, 0.6048, 0.5902, 0.5972, 0.6102,\n",
       "                       0.5902, 0.6158, 0.6610, 0.5765, 0.6294, 0.5945, 0.5943, 0.6005, 0.6168,\n",
       "                       0.6031, 0.5793, 0.5831, 0.5951, 0.5755, 0.6245, 0.5700, 0.5961, 0.6144,\n",
       "                       0.5982, 0.6145, 0.5991, 0.6478, 0.5799, 0.6244, 0.5838, 0.6066, 0.5939,\n",
       "                       0.6212, 0.5871, 0.5799, 0.6020, 0.5722, 0.6104, 0.6184, 0.5926, 0.6085,\n",
       "                       0.5813, 0.6092, 0.5792, 0.5950, 0.5888, 0.5893, 0.5879, 0.5896, 0.6028,\n",
       "                       0.6157, 0.6172, 0.5863, 0.6123, 0.6201, 0.6325, 0.5602, 0.5812, 0.6105,\n",
       "                       0.5697, 0.6419, 0.6186, 0.5536, 0.6084, 0.5658, 0.5789, 0.5792, 0.5944,\n",
       "                       0.5631, 0.5766, 0.5740, 0.5742, 0.5999, 0.5911, 0.6002, 0.6256, 0.5928,\n",
       "                       0.5790, 0.5731, 0.6195, 0.5596, 0.6355, 0.6062, 0.5873, 0.3090, 0.6013,\n",
       "                       0.5663, 0.6132, 0.6275, 0.5987, 0.6337, 0.6202, 0.6088, 0.5968, 0.5501,\n",
       "                       0.5824, 0.5441, 0.5872, 0.5469, 0.5958, 0.5924, 0.5838, 0.6049, 0.5861,\n",
       "                       0.5823, 0.6001, 0.5989, 0.5942, 0.5900, 0.6177, 0.5854, 0.5975, 0.5848,\n",
       "                       0.6046, 0.6036, 0.5483, 0.6153, 0.6077, 0.6225, 0.6086, 0.5925, 0.6067,\n",
       "                       0.2417, 0.6028, 0.5869, 0.6060, 0.6188, 0.6319, 0.5866, 0.5940, 0.5881,\n",
       "                       0.5906, 0.6399, 0.6166, 0.6111, 0.5739, 0.5820, 0.6151, 0.6079, 0.5155,\n",
       "                       0.5826, 0.5975, 0.5694, 0.6121, 0.6199, 0.6353, 0.6094, 0.5903, 0.6120,\n",
       "                       0.5869, 0.6239, 0.6193, 0.6137, 0.6206, 0.6324, 0.5781, 0.5923, 0.6182,\n",
       "                       0.6239, 0.6054, 0.5926, 0.2342, 0.6221, 0.6078, 0.6088, 0.5657, 0.5856,\n",
       "                       0.6197, 0.6072, 0.6560, 0.5997, 0.5891, 0.6224, 0.6080, 0.6175, 0.6014,\n",
       "                       0.6125, 0.5899, 0.5920, 0.6178, 0.5977, 0.5985, 0.5803, 0.6148, 0.5911,\n",
       "                       0.5729, 0.6128, 0.6075, 0.6118, 0.6029, 0.6038, 0.5558, 0.6149, 0.5834,\n",
       "                       0.5829, 0.5863, 0.6184, 0.6011, 0.4694, 0.5866, 0.6697, 0.5945, 0.6435,\n",
       "                       0.5807, 0.5675, 0.6200, 0.6625, 0.6197, 0.5868, 0.5811, 0.5445, 0.6037,\n",
       "                       0.5964, 0.5818, 0.6070, 0.6082, 0.6080, 0.5736, 0.6217, 0.5795, 0.6340,\n",
       "                       0.5935, 0.5778, 0.6418, 0.6122, 0.5827, 0.5921, 0.6037, 0.5838, 0.5865,\n",
       "                       0.5788, 0.5949, 0.6047, 0.5955, 0.5650, 0.6019, 0.6036, 0.5877, 0.6087,\n",
       "                       0.4662, 0.5806, 0.6014, 0.5483, 0.5904, 0.5866, 0.6249, 0.5886, 0.5807,\n",
       "                       0.6080, 0.5760, 0.5771, 0.6061, 0.5829, 0.6057, 0.5959, 0.5916, 0.5504,\n",
       "                       0.6402, 0.5777, 0.6199, 0.5666, 0.6179, 0.5921, 0.6115, 0.5840, 0.5723,\n",
       "                       0.6155, 0.5898, 0.6928, 0.5886, 0.5822, 0.5931, 0.6092, 0.6204, 0.5947,\n",
       "                       0.5908, 0.6195, 0.5821, 0.6085, 0.5832, 0.6201, 0.5918, 0.6453, 0.5968,\n",
       "                       0.6174, 0.6228, 0.5880, 0.5676, 0.6126, 0.5896, 0.6317, 0.5680, 0.6273,\n",
       "                       0.5939, 0.5978, 0.6137], device='cuda:0')),\n",
       "              ('model.layers.3.attention.wq.weight',\n",
       "               tensor([[ 0.0396, -0.0143,  0.0630,  ..., -0.0014, -0.0269, -0.0305],\n",
       "                       [ 0.0554, -0.0661,  0.0131,  ..., -0.0504, -0.0302,  0.0654],\n",
       "                       [ 0.0424, -0.0183, -0.0769,  ...,  0.0355,  0.0029, -0.0559],\n",
       "                       ...,\n",
       "                       [ 0.0954, -0.0022,  0.1419,  ..., -0.0585, -0.0677, -0.0126],\n",
       "                       [-0.2231, -0.1602,  0.0848,  ..., -0.0857, -0.0822, -0.0176],\n",
       "                       [ 0.1103, -0.0249,  0.1510,  ..., -0.0240, -0.0522,  0.1056]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.attention.wk.weight',\n",
       "               tensor([[ 0.0200,  0.0385,  0.1217,  ...,  0.0749, -0.0165, -0.0309],\n",
       "                       [-0.0112,  0.0040,  0.0349,  ..., -0.0283,  0.0687, -0.0108],\n",
       "                       [-0.0367, -0.0245,  0.0640,  ...,  0.0759,  0.0051,  0.0111],\n",
       "                       ...,\n",
       "                       [ 0.1576,  0.0651, -0.0335,  ..., -0.0313,  0.0513, -0.0049],\n",
       "                       [ 0.0772,  0.1259, -0.0142,  ...,  0.0429, -0.0924,  0.1966],\n",
       "                       [-0.0989,  0.1777, -0.0286,  ..., -0.0593, -0.1523, -0.0093]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.attention.wv.weight',\n",
       "               tensor([[-0.0575, -0.1895, -0.0210,  ..., -0.1460,  0.1974, -0.1129],\n",
       "                       [ 0.3789, -0.1950,  0.0716,  ...,  0.0932, -0.0422,  0.0404],\n",
       "                       [-0.0853,  0.1598,  0.1277,  ..., -0.0134, -0.0997,  0.1856],\n",
       "                       ...,\n",
       "                       [-0.0887,  0.0173,  0.0518,  ...,  0.2345,  0.4991,  0.1615],\n",
       "                       [ 0.4219, -0.1814, -0.0923,  ...,  0.0854,  0.1034, -0.2985],\n",
       "                       [-0.1640, -0.1190, -0.0490,  ..., -0.0964,  0.3418,  0.0335]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.attention.wo.weight',\n",
       "               tensor([[-0.0883,  0.0308,  0.0576,  ...,  0.2745,  0.0260, -0.1198],\n",
       "                       [ 0.3542, -0.1817,  0.0566,  ..., -0.0936, -0.1333, -0.0979],\n",
       "                       [ 0.1306,  0.0263, -0.0595,  ...,  0.2817,  0.1795, -0.1283],\n",
       "                       ...,\n",
       "                       [ 0.2947,  0.0390, -0.0433,  ..., -0.2384, -0.2184,  0.2514],\n",
       "                       [-0.0028,  0.0421, -0.1024,  ...,  0.0605, -0.0436, -0.2449],\n",
       "                       [-0.0387,  0.0270, -0.1138,  ..., -0.1855, -0.0124, -0.0666]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.mlp.linear1.weight',\n",
       "               tensor([[ 0.0843, -0.0060, -0.0546,  ...,  0.0208,  0.2579,  0.0598],\n",
       "                       [ 0.0395, -0.0029, -0.0089,  ...,  0.0065, -0.0349, -0.0510],\n",
       "                       [-0.0930,  0.1163, -0.1335,  ..., -0.0155, -0.2171,  0.0330],\n",
       "                       ...,\n",
       "                       [-0.1440,  0.0213,  0.0108,  ...,  0.0934, -0.0627, -0.0546],\n",
       "                       [ 0.0982, -0.0302,  0.1047,  ..., -0.0147, -0.2696,  0.0247],\n",
       "                       [ 0.0769, -0.1223,  0.0221,  ...,  0.0933, -0.0773, -0.1046]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.mlp.linear2.weight',\n",
       "               tensor([[-0.0136,  0.0169, -0.2175,  ..., -0.2283, -0.0828, -0.0984],\n",
       "                       [-0.0325,  0.0604, -0.0038,  ...,  0.0453,  0.0484, -0.1098],\n",
       "                       [ 0.0734, -0.0514,  0.0341,  ..., -0.0062,  0.0322, -0.0403],\n",
       "                       ...,\n",
       "                       [ 0.0817,  0.1068, -0.0939,  ..., -0.0323,  0.1072, -0.0041],\n",
       "                       [-0.1357, -0.2519, -0.0276,  ..., -0.0723,  0.0601,  0.1977],\n",
       "                       [ 0.0487, -0.3105,  0.2964,  ...,  0.0700,  0.0403, -0.0137]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.layers.3.mlp.linear3.weight',\n",
       "               tensor([[-0.0939,  0.2861, -0.0044,  ...,  0.0366,  0.1077, -0.0686],\n",
       "                       [-0.1584, -0.0088,  0.0750,  ..., -0.0116,  0.1300, -0.0238],\n",
       "                       [-0.0770,  0.0351,  0.2948,  ..., -0.1092, -0.1495, -0.0161],\n",
       "                       ...,\n",
       "                       [ 0.2314,  0.0021, -0.0026,  ...,  0.0532,  0.0636,  0.0486],\n",
       "                       [-0.0038, -0.0206,  0.0687,  ...,  0.0477, -0.0101, -0.1839],\n",
       "                       [ 0.1989, -0.2370,  0.0826,  ..., -0.0061,  0.0018,  0.3133]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.norm.w',\n",
       "               tensor([1.3040, 1.4584, 1.2607, 1.5102, 1.3036, 1.3770, 1.4489, 1.1113, 1.3322,\n",
       "                       1.2926, 1.3145, 1.2013, 1.3715, 1.3766, 1.3332, 1.2285, 1.4015, 1.5318,\n",
       "                       1.3893, 1.4325, 1.3398, 1.2962, 1.2964, 1.8019, 1.2643, 1.3031, 1.3199,\n",
       "                       3.2042, 1.1455, 1.3905, 1.1837, 1.3179, 1.2688, 1.2223, 1.3189, 1.4870,\n",
       "                       1.6226, 1.3320, 1.3485, 1.3837, 1.3537, 1.2795, 1.3385, 1.3480, 1.6117,\n",
       "                       1.2895, 1.3533, 1.3244, 1.4944, 1.6099, 1.0699, 1.4447, 1.3139, 2.2648,\n",
       "                       1.3770, 1.6408, 1.4498, 1.3391, 1.4044, 1.3943, 1.2731, 1.3879, 1.3294,\n",
       "                       1.3337, 1.3335, 1.3750, 1.4352, 1.3532, 1.2510, 1.2363, 1.2447, 1.3914,\n",
       "                       1.2876, 1.3379, 1.2488, 1.3441, 1.3789, 1.3867, 1.2118, 1.3480, 1.2778,\n",
       "                       1.4108, 1.3282, 1.3219, 1.3070, 1.3135, 1.4252, 1.3385, 1.3623, 1.4744,\n",
       "                       1.3953, 1.4672, 1.4450, 1.2932, 1.4717, 1.2973, 1.4411, 1.3474, 1.5583,\n",
       "                       1.3681, 1.2533, 1.3936, 1.4662, 1.4743, 1.2864, 1.2645, 1.4023, 0.8315,\n",
       "                       1.3211, 1.1973, 1.2355, 1.2401, 1.3724, 1.3543, 1.2970, 1.4589, 1.4709,\n",
       "                       1.4202, 1.4841, 1.3553, 1.3841, 1.4266, 1.2322, 1.3007, 2.0951, 1.3666,\n",
       "                       1.5020, 1.3595, 1.5419, 1.3018, 1.2675, 1.2690, 1.4922, 1.3914, 1.3826,\n",
       "                       1.3293, 1.3720, 1.3155, 1.3588, 1.2400, 1.2352, 1.2817, 1.3112, 1.2979,\n",
       "                       1.4201, 1.4280, 1.2699, 1.3717, 1.5031, 1.4410, 1.2803, 1.4783, 1.3627,\n",
       "                       1.3680, 1.3184, 1.2270, 1.4649, 1.3709, 1.4302, 1.3386, 1.4017, 1.2640,\n",
       "                       1.3418, 1.3090, 1.3758, 1.3424, 1.2607, 1.3349, 1.3643, 1.2763, 0.6834,\n",
       "                       1.4682, 1.3118, 1.4934, 1.3120, 1.3772, 1.3779, 1.5302, 1.3158, 1.4529,\n",
       "                       1.2883, 1.2505, 1.3263, 1.4487, 1.2193, 1.3699, 1.3851, 1.3913, 1.3113,\n",
       "                       1.3889, 1.2839, 1.2635, 1.4425, 1.2698, 1.3564, 1.2383, 1.3692, 2.7880,\n",
       "                       1.3609, 1.5373, 1.4708, 1.3275, 1.3225, 1.2034, 1.2665, 1.5137, 1.4102,\n",
       "                       1.3075, 1.3441, 1.4323, 1.4654, 1.5626, 1.2515, 1.2028, 1.4641, 1.2469,\n",
       "                       1.3398, 1.1899, 1.3728, 1.4424, 1.2732, 1.5686, 1.4327, 1.4265, 1.3534,\n",
       "                       1.2994, 1.1673, 1.1837, 1.4085, 1.1617, 1.3135, 1.3790, 1.4340, 1.3507,\n",
       "                       1.3241, 1.2802, 1.2195, 1.3306, 1.3075, 2.4403, 1.5410, 1.3379, 1.4347,\n",
       "                       1.4544, 1.2413, 1.4266, 1.3027, 1.5309, 1.5134, 1.7792, 1.2773, 1.3193,\n",
       "                       1.4583, 1.3543, 1.3453, 1.3259, 1.3983, 1.5526, 1.2769, 1.2989, 1.2160,\n",
       "                       1.3304, 1.3995, 1.3040, 1.4095, 1.3930, 1.3378, 1.3546, 1.2570, 1.2091,\n",
       "                       1.2146, 2.0151, 1.3701, 1.6218, 1.4133, 1.3803, 1.3069, 1.3803, 1.3839,\n",
       "                       1.3216, 1.3717, 1.2964, 1.4507, 1.3395, 1.6384, 1.2219, 1.3771, 1.1722,\n",
       "                       1.3207, 1.5577, 1.3918, 1.3319, 1.3765, 1.3835, 1.4141, 1.4117, 1.4651,\n",
       "                       1.3958, 1.3926, 1.4033, 1.3894, 1.2815, 1.3147, 1.3814, 1.1564, 1.3245,\n",
       "                       1.2963, 1.3553, 2.3196, 1.2976, 1.3179, 1.2208, 1.3543, 1.3782, 1.3949,\n",
       "                       1.5368, 1.3302, 1.4989, 1.1647, 1.3053, 1.3689, 1.3785, 1.3731, 1.2187,\n",
       "                       1.5268, 1.3381, 1.2042, 1.2815, 1.4491, 1.3647, 1.4115, 1.2785, 1.3142,\n",
       "                       1.3954, 1.5668, 1.3473, 1.3680, 2.0813, 1.3206, 1.3924, 1.5123, 1.2470,\n",
       "                       1.2734, 1.4017, 1.3136, 1.4297, 2.6005, 1.1218, 1.2733, 1.4083, 1.2895,\n",
       "                       1.5610, 1.3386, 1.3873, 1.3327, 1.3962, 1.3660, 1.3824, 1.2987, 1.3089,\n",
       "                       1.2388, 1.2747, 1.2985, 1.3835, 1.4207, 1.3379, 1.3210, 1.3213, 1.4043,\n",
       "                       1.3022, 1.4203, 1.2091, 1.4534, 1.1927, 1.3374, 1.3338, 1.2448, 1.3537,\n",
       "                       1.4019, 1.3203, 1.3305, 1.6271, 1.1928, 1.4045, 1.4436, 1.4215, 1.3612,\n",
       "                       1.3454, 1.4095, 1.2948, 1.2592, 1.2476, 1.3165, 1.4927, 1.4911, 1.2589,\n",
       "                       1.2480, 1.3289, 1.3945, 1.3513, 0.9100, 1.3414, 1.2920, 1.4045, 1.2743,\n",
       "                       1.5279, 1.2920, 1.2346, 1.0656, 1.0894, 1.3417, 1.9723, 1.3903, 1.3137,\n",
       "                       1.4771, 1.4176, 1.3652, 1.5102, 1.4205, 1.3316, 1.2488, 1.3183, 1.2316,\n",
       "                       1.2746, 1.3844, 1.2334, 1.2697, 1.4785, 1.2576, 1.6215, 1.3167, 2.7962,\n",
       "                       1.3092, 1.3330, 1.3440, 1.5439, 1.3071, 1.4006, 1.3557, 1.2675, 1.2991,\n",
       "                       1.3990, 1.2403, 0.4153, 1.2549, 1.4084, 1.2696, 1.3125, 1.2960, 1.3456,\n",
       "                       1.3489, 1.3921, 1.3750, 1.2407, 1.3152, 1.2936, 1.3989, 1.3800, 1.5891,\n",
       "                       1.3220, 1.1512, 1.3008, 1.4502, 1.3057, 1.4263, 1.2180, 1.3197, 1.4010,\n",
       "                       1.3531, 1.2503, 1.4632, 1.2908, 1.3710, 1.4644, 1.3376, 1.5353, 1.3400,\n",
       "                       1.2517, 1.2949, 1.3108, 1.2413, 1.3377, 1.2381, 1.3469, 1.3898, 1.6549,\n",
       "                       1.5326, 1.3636, 1.6660, 1.9324, 1.3187, 1.2948, 1.4186, 1.4979, 1.2781,\n",
       "                       1.3772, 1.2929, 1.4142, 1.1619, 1.4827, 1.3544, 1.3251, 1.3070, 1.3138,\n",
       "                       1.3354, 1.2180, 1.5183, 1.4262, 1.4008, 1.9789, 1.2425, 1.4183, 1.3501,\n",
       "                       1.4728, 1.4975, 1.4165, 1.4783, 1.6144, 1.4862, 1.2110, 1.4552, 1.3792,\n",
       "                       1.3377, 1.3728, 1.3412, 1.2838, 1.3990, 1.3422, 1.4565, 1.4732, 1.4309,\n",
       "                       1.3499, 1.3244, 1.5212, 3.0558, 1.5093, 1.2791, 1.3673, 1.4399, 1.3390,\n",
       "                       1.4358, 1.4208, 1.3767, 2.0519, 1.3620, 1.1495, 1.4683, 1.2370, 1.3384,\n",
       "                       1.3109, 1.3437, 1.4133, 1.2790, 2.1794, 1.3694, 1.4340, 0.7033, 1.3489,\n",
       "                       1.2231, 1.1991, 1.3140, 1.2091, 1.3308, 1.6000, 1.2731, 1.4004, 1.5139,\n",
       "                       1.5767, 1.3487, 1.7359, 1.2539, 1.3715, 1.3703, 1.3833, 1.4717, 1.2509,\n",
       "                       1.2476, 1.3417, 1.5846, 1.1683, 1.3339, 1.4897, 1.3571, 1.3042, 1.4046,\n",
       "                       1.3156, 1.4753, 1.3476, 1.4227, 1.2936, 1.5743, 1.2347, 1.3384, 1.2594,\n",
       "                       0.6225, 1.2578, 1.5127, 1.2868, 1.3433, 1.3299, 1.2744, 1.3048, 1.1624,\n",
       "                       1.2801, 1.2828, 1.3343, 1.2656, 1.4331, 1.2826, 1.3001, 1.3968, 2.2564,\n",
       "                       1.4724, 1.5363, 1.3903, 1.3693, 1.3818, 1.2923, 1.4805, 1.3939, 1.3852,\n",
       "                       1.2728, 1.3955, 1.3389, 1.3701, 1.2322, 1.3784, 1.6343, 1.3553, 1.2057,\n",
       "                       1.4831, 1.2139, 1.4552, 2.1320, 1.3306, 1.3050, 1.3066, 1.3598, 1.3205,\n",
       "                       1.3364, 1.3906, 1.3454, 1.3112, 1.4236, 1.3080, 1.3163, 1.4770, 1.3201,\n",
       "                       1.4160, 1.2479, 1.3088, 1.5043, 1.3817, 1.3995, 1.4323, 1.3326, 1.3318,\n",
       "                       1.3111, 1.4447, 1.3152, 1.5391, 1.3707, 1.3327, 1.2356, 1.3120, 1.5779,\n",
       "                       1.3890, 1.3280, 1.4438, 1.2743, 1.5150, 1.3296, 1.5081, 1.4394, 1.3525,\n",
       "                       1.3953, 1.2434, 1.3784, 1.3521, 1.5215, 1.3938, 1.2729, 1.3706, 1.3464,\n",
       "                       1.6167, 1.4588, 1.4070, 1.3170, 1.1508, 1.3590, 1.5099, 1.5660, 1.4965,\n",
       "                       1.3631, 1.4813, 1.2508, 1.3526, 1.3803, 1.2655, 1.5117, 1.3511, 1.3196,\n",
       "                       1.2133, 1.3857, 1.3962, 1.3181, 1.4943, 1.3382, 1.3241, 1.4704, 1.3628,\n",
       "                       1.3179, 1.6786, 1.4971, 1.3174, 1.6102, 1.2511, 1.3634, 1.3541, 1.4448,\n",
       "                       1.2662, 1.3029, 1.4265, 1.3215, 1.5390, 1.3648, 1.2245, 1.4137, 1.3375,\n",
       "                       1.4988, 1.4877, 1.6557, 1.3571, 1.2700, 1.4828, 1.5108, 1.3532, 1.2914,\n",
       "                       1.3265, 1.2587, 1.9530, 1.3132, 1.2494, 1.3995, 1.4885, 1.3892, 1.3162,\n",
       "                       1.3471, 1.2714, 1.4589, 1.2616, 1.3068, 1.4872, 1.3257, 1.8999, 1.1811,\n",
       "                       1.3179, 1.2886, 1.4297, 1.4076, 1.3134, 1.1388, 1.3382, 1.4866, 1.3278,\n",
       "                       1.3293, 1.1998, 1.3625], device='cuda:0')),\n",
       "              ('model.output.weight',\n",
       "               tensor([[-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "                       [-0.0024,  0.0108, -0.0182,  ...,  0.0005, -0.0436,  0.0270],\n",
       "                       [-0.0827, -0.0160, -0.0518,  ..., -0.1533, -0.0490,  0.0909],\n",
       "                       ...,\n",
       "                       [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0188],\n",
       "                       [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "                       [-0.0406, -0.0110, -0.0283,  ...,  0.0344, -0.0347, -0.0188]],\n",
       "                      device='cuda:0')),\n",
       "              ('output.weight',\n",
       "               tensor([[-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "                       [-0.0024,  0.0108, -0.0182,  ...,  0.0005, -0.0436,  0.0270],\n",
       "                       [-0.0827, -0.0160, -0.0518,  ..., -0.1533, -0.0490,  0.0909],\n",
       "                       ...,\n",
       "                       [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0188],\n",
       "                       [-0.0407, -0.0110, -0.0283,  ...,  0.0344, -0.0348, -0.0187],\n",
       "                       [-0.0406, -0.0110, -0.0283,  ...,  0.0344, -0.0347, -0.0188]],\n",
       "                      device='cuda:0'))])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a93960-508e-475b-8f27-22d173bdbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_dict, MODEL_REGISTRY + \"blm-instruct-v2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b282d3-2117-4d4a-975f-f68b3d5309b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
