{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaab60b-ca3e-4bcc-950f-ddab0abe8d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION : 2.2.0\n",
      "GPU  :  cuda\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "print(\"TORCH VERSION :\", version(\"torch\"))\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backend.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(\"GPU  : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b042382-d341-48c3-b6ef-576b8bd076af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdc3b65-9f33-430c-9f2b-3d9fb0175266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740],\n",
      "        [0.8665, 0.1366, 0.1025, 0.1841, 0.7264],\n",
      "        [0.3153, 0.6871, 0.0756, 0.1966, 0.3164]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4634, 0.4620, 0.1549, 0.3933, 0.3337],\n",
       "        [0.5948, 0.3645, 0.1299, 0.3031, 0.4719],\n",
       "        [0.4890, 0.4525, 0.1410, 0.3508, 0.3723]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Self Attention Implementation\n",
    "inputs = torch.rand(3, 5)\n",
    "print(inputs)\n",
    "attention_scores = inputs @ inputs.T\n",
    "attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "attention_weights @ inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc084034-c890-4fdb-bba6-90f3d4616cc8",
   "metadata": {},
   "source": [
    "#### This self-attention mechanism is also called \"scaled dot-product attention\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63b7cb5-c4bb-488b-8251-ddfb3594be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self attention implementationw ith trainable weights\n",
    "class SingleHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, blocksize, dropout=0.0, mask=False, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if mask:\n",
    "            self.register_buffer(\"mask\", torch.triu(torch.ones(blocksize, blocksize), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, token_count, _ = x.shape\n",
    "\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        attention_scores = queries @ keys.transpose(1, 2)\n",
    "\n",
    "        if hasattr(self, \"mask\"):\n",
    "            attention_scores.masked_fill_(self.mask.bool()[:token_count, :token_count], -torch.inf)\n",
    "\n",
    "        attention_weights = F.softmax(attention_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        context_vector = attention_weights @ values\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94328c42-af8d-4214-b092-43c59cd4fafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand(1, 10, 12)\n",
    "d_in = d_out = inp.shape[-1]\n",
    "sha = SingleHeadAttention(d_in, d_out, inp.shape[1], mask=True)\n",
    "result = sha(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57ddc68-7c4b-4e50-a3bf-9b81e0c1c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot(inp, result):\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     # Create a figure with two subplots side by side\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "#     # Plot the same plot on both subplots\n",
    "#     cax1 = axs[0].matshow(inp.squeeze(0))\n",
    "#     fig.colorbar(cax1, ax=axs[0])\n",
    "#     cax2 = axs[1].matshow(result.detach().numpy().squeeze(0))\n",
    "#     fig.colorbar(cax2, ax=axs[1])\n",
    "\n",
    "#     axs[0].set_title(\"Input tensor\")\n",
    "#     axs[1].set_title(\"After applying self attention\")\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# plot(inp, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46023db3-3382-4bef-ace5-4727f908a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head Self Attention\n",
    "class MultiHeadAttention_v1(nn.Module):\n",
    "    def __init__(self, heads, d_in, d_out, blocksize, dropout=0.0, mask=False, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                SingleHeadAttention(d_in, d_out, blocksize, dropout, mask, qkv_bias)\n",
    "                for _ in range(heads)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(d_out * heads, d_out * heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context_vec = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.linear(context_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f7c17e-091a-4af4-9df9-843f639ccf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for embedding_dim = 512 , head = 8\n",
    "# d_in = 512/8 = 64\n",
    "\n",
    "mha = MultiHeadAttention_v1(2, 12, 6, 10)\n",
    "result = mha(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f14f11-06df-4d4b-9804-e942d0190f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(inp,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2578c5a7-38ab-4d62-8480-48c835665ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(SingleHeadAttention):\n",
    "    def __init__(self, num_heads, d_model, blocksize, dropout=0.0, mask=False, qkv_bias=False):\n",
    "        super().__init__(d_model, d_model, blocksize, dropout, mask, qkv_bias)\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, num_token, embedding_dim = x.shape\n",
    "\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        queries = queries.view(batch, num_token, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = keys.view(batch, num_token, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(batch, num_token, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attention_scores = torch.matmul(queries, keys.transpose(-2, -1))\n",
    "        if hasattr(self, \"mask\"):\n",
    "            attention_scores.masked_fill_(self.mask.bool()[:num_token, :num_token], -float(\"inf\"))\n",
    "\n",
    "        attention_weights = F.softmax(attention_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vector = torch.matmul(attention_weights, values)\n",
    "        context_vector = (\n",
    "            context_vector.transpose(1, 2).contiguous().view(batch, num_token, embedding_dim)\n",
    "        )\n",
    "        return self.linear(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1becd4a7-cd47-4ee1-9d1a-125a07eeacfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttention(2, 12, 10)\n",
    "result = mha(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16c10bb-2f15-4716-9502-bae6d2b14a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(inp,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77343001-dba5-41b6-b76f-270ba079cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionPyTorchSDP(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, block_size, mask=False, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.block_size = block_size\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.qkv = nn.Linear(d_model, 3 * d_model, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(block_size, block_size), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.reshape(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv.unbind(0)\n",
    "\n",
    "        use_dropout = 0.0 if not self.training else self.dropout\n",
    "        context_vec = nn.functional.scaled_dot_product_attention(\n",
    "            queries, keys, values, attn_mask=None, dropout_p=use_dropout, is_causal=True\n",
    "        )\n",
    "\n",
    "        # Combine heads, where self.d_model = self.num_heads * self.head_dim\n",
    "        context_vec = (\n",
    "            context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, embed_dim)\n",
    "        )\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb98e6a-f9c2-4831-8a74-1ca411d96226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhap = MultiHeadAttentionPyTorchSDP(2, 12, 10)\n",
    "result = mhap(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4e9506-9211-49d9-aab0-34d68c64e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(inp,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcfe486-8459-40d4-9733-41f52b6f0cc2",
   "metadata": {},
   "source": [
    "### Benchmark Test - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56dcffa6-250a-40f2-8706-c55f371396e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "batch = 32\n",
    "max_len = 1024\n",
    "embedding_dim = 768\n",
    "num_heads = 12\n",
    "\n",
    "x = torch.rand(batch, max_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d757f2a-ecdf-4678-a0e1-991f4bb0805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 ms ± 8.85 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit SingleHeadAttention(embedding_dim,embedding_dim,x.shape[1],mask=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9163ae78-6f13-49be-8711-7c2401b2acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676 ms ± 31 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttention_v1(num_heads,embedding_dim,embedding_dim//num_heads,max_len)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2061fe7f-f40c-4b65-a452-4027354464f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698 ms ± 33.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttention(num_heads,embedding_dim,max_len)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7114c39-42c9-4f59-86c1-e21a629d09d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 ms ± 5.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttentionPyTorchSDP(num_heads,embedding_dim,max_len)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8564b-880b-409a-910b-1242bb92a517",
   "metadata": {},
   "source": [
    "### GPU Benchmark Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6bc7c93-6008-4efb-a77e-aac1803172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0f77f0b-9e74-4a9d-9740-8bc9d1f3ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ms ± 1.65 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit SingleHeadAttention(embedding_dim,embedding_dim,x.shape[1],mask=True).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "483ed669-8caa-42c5-9ad4-d8d0bed714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.1 ms ± 691 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = x.to(device)\n",
    "%timeit MultiHeadAttention_v1(num_heads,embedding_dim,embedding_dim//num_heads,max_len).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6e94d5d-e242-4e46-9f32-a931f57212a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.8 ms ± 908 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttention(num_heads,embedding_dim,max_len).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "276428f0-da33-4992-b295-ac91b750e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 ms ± 20.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttentionPyTorchSDP(num_heads,embedding_dim,max_len).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9346f6d3-05a6-43d8-be4b-42854cca0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ms ± 9.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit nn.Linear(embedding_dim,embedding_dim).to(device)(nn.MultiheadAttention(embedding_dim, num_heads).to(device)(x,x,x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51bb8600-1a85-4297-bd48-c09a40c8b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e854ae0c-0a6c-40a9-bd5e-884721d03123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up with batch_size=1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 675.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module MultiHeadAttentionPyTorchSDP is treated as a zero-op.\n",
      "Warning! No positional inputs found for a module, assuming batch size is 1.\n",
      "MultiHeadAttentionPyTorchSDP(\n",
      "  2.36 M, 100.000% Params, 1.81 GMac, 100.000% MACs, \n",
      "  (qkv): Linear(1.77 M, 74.976% Params, 1.81 GMac, 100.000% MACs, in_features=768, out_features=2304, bias=False)\n",
      "  (proj): Linear(590.59 k, 25.024% Params, 0.0 Mac, 0.000% MACs, in_features=768, out_features=768, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up with batch_size=1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 844.26it/s]\n",
      "STAGE:2024-05-02 00:47:26 139476:139476 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-05-02 00:47:26 139476:139476 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-05-02 00:47:26 139476:139476 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Measuring inference for batch_size=1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 544.64it/s]\n",
      "Unable to measure energy consumption. Device must be a NVIDIA Jetson.\n",
      "Warming up with batch_size=32: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.74it/s]\n",
      "STAGE:2024-05-02 00:47:26 139476:139476 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-05-02 00:47:26 139476:139476 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-05-02 00:47:26 139476:139476 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Measuring inference for batch_size=32: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.26it/s]\n",
      "Unable to measure energy consumption. Device must be a NVIDIA Jetson.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_benchmark\n",
    "\n",
    "model = MultiHeadAttentionPyTorchSDP(num_heads, embedding_dim, max_len).to(\"cuda\")\n",
    "\n",
    "# Create a benchmark object\n",
    "results = pytorch_benchmark.benchmark(\n",
    "    model, sample=x.to(\"cuda\"), num_runs=10, batch_size=32, print_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf7017b1-26e2-4aab-9269-596887e92525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "flops: 1811939328\n",
      "machine_info:\n",
      "  cpu:\n",
      "    architecture: x86_64\n",
      "    cores:\n",
      "      physical: 24\n",
      "      total: 32\n",
      "    frequency: 4.79 GHz\n",
      "    model: 13th Gen Intel(R) Core(TM) i9-13900F\n",
      "  gpus:\n",
      "  - memory: 12282.0 MB\n",
      "    name: NVIDIA GeForce RTX 4070 Ti\n",
      "  memory:\n",
      "    available: 22.17 GB\n",
      "    total: 31.06 GB\n",
      "    used: 8.29 GB\n",
      "  system:\n",
      "    node: pranav-pc-Legion-T5-26IRB8\n",
      "    release: 6.5.0-28-generic\n",
      "    system: Linux\n",
      "memory:\n",
      "  batch_size_1:\n",
      "    max_inference: 133.13 MB\n",
      "    max_inference_bytes: 139594752\n",
      "    post_inference: 117.13 MB\n",
      "    post_inference_bytes: 122817536\n",
      "    pre_inference: 117.13 MB\n",
      "    pre_inference_bytes: 122817536\n",
      "  batch_size_32:\n",
      "    max_inference: 597.13 MB\n",
      "    max_inference_bytes: 626134016\n",
      "    post_inference: 117.13 MB\n",
      "    post_inference_bytes: 122817536\n",
      "    pre_inference: 117.13 MB\n",
      "    pre_inference_bytes: 122817536\n",
      "params: 2360064\n",
      "timing:\n",
      "  batch_size_1:\n",
      "    cpu_to_gpu:\n",
      "      human_readable:\n",
      "        batch_latency: 554.061 us +/- 76.428 us [500.202 us, 765.324 us]\n",
      "        batches_per_second: 1.83 K +/- 201.37 [1.31 K, 2.00 K]\n",
      "      metrics:\n",
      "        batches_per_second_max: 1999.1916110581506\n",
      "        batches_per_second_mean: 1832.4390541097932\n",
      "        batches_per_second_min: 1306.6367601246106\n",
      "        batches_per_second_std: 201.36867021305426\n",
      "        seconds_per_batch_max: 0.0007653236389160156\n",
      "        seconds_per_batch_mean: 0.0005540609359741211\n",
      "        seconds_per_batch_min: 0.0005002021789550781\n",
      "        seconds_per_batch_std: 7.642834344314412e-05\n",
      "    gpu_to_cpu:\n",
      "      human_readable:\n",
      "        batch_latency: 550.222 us +/- 17.260 us [531.435 us, 586.271 us]\n",
      "        batches_per_second: 1.82 K +/- 55.46 [1.71 K, 1.88 K]\n",
      "      metrics:\n",
      "        batches_per_second_max: 1881.697622252131\n",
      "        batches_per_second_mean: 1819.1859004978025\n",
      "        batches_per_second_min: 1705.694997966653\n",
      "        batches_per_second_std: 55.455852253593\n",
      "        seconds_per_batch_max: 0.0005862712860107422\n",
      "        seconds_per_batch_mean: 0.000550222396850586\n",
      "        seconds_per_batch_min: 0.0005314350128173828\n",
      "        seconds_per_batch_std: 1.7259858511267358e-05\n",
      "    on_device_inference:\n",
      "      human_readable:\n",
      "        batch_latency: -698124.796 us +/- 221.401 ms [-1218111.992 us, -510591.984\n",
      "          us]\n",
      "        batches_per_second: -1.55 +/- 0.38 [-1.96, -0.82]\n",
      "      metrics:\n",
      "        batches_per_second_max: -0.8209425788959847\n",
      "        batches_per_second_mean: -1.5501188146499536\n",
      "        batches_per_second_min: -1.9585109671466554\n",
      "        batches_per_second_std: 0.38075413457659196\n",
      "        seconds_per_batch_max: -0.510591983795166\n",
      "        seconds_per_batch_mean: -0.6981247961521149\n",
      "        seconds_per_batch_min: -1.2181119918823242\n",
      "        seconds_per_batch_std: 0.22140093789449306\n",
      "    total:\n",
      "      human_readable:\n",
      "        batch_latency: 1.814 ms +/- 242.191 us [1.585 ms, 2.277 ms]\n",
      "        batches_per_second: 560.61 +/- 69.17 [439.10, 630.72]\n",
      "      metrics:\n",
      "        batches_per_second_max: 630.7224060150376\n",
      "        batches_per_second_mean: 560.612611401233\n",
      "        batches_per_second_min: 439.10217755443887\n",
      "        batches_per_second_std: 69.17310716049774\n",
      "        seconds_per_batch_max: 0.002277374267578125\n",
      "        seconds_per_batch_mean: 0.0018135547637939454\n",
      "        seconds_per_batch_min: 0.0015854835510253906\n",
      "        seconds_per_batch_std: 0.00024219146033425086\n",
      "  batch_size_32:\n",
      "    cpu_to_gpu:\n",
      "      human_readable:\n",
      "        batch_latency: 7.228 ms +/- 392.235 us [6.814 ms, 7.980 ms]\n",
      "        batches_per_second: 138.75 +/- 7.36 [125.32, 146.75]\n",
      "      metrics:\n",
      "        batches_per_second_max: 146.7463438527745\n",
      "        batches_per_second_mean: 138.74662580819287\n",
      "        batches_per_second_min: 125.31532715864954\n",
      "        batches_per_second_std: 7.3565860604803355\n",
      "        seconds_per_batch_max: 0.007979869842529297\n",
      "        seconds_per_batch_mean: 0.00722815990447998\n",
      "        seconds_per_batch_min: 0.006814479827880859\n",
      "        seconds_per_batch_std: 0.00039223494621845443\n",
      "    gpu_to_cpu:\n",
      "      human_readable:\n",
      "        batch_latency: 27.008 ms +/- 373.622 us [26.587 ms, 27.726 ms]\n",
      "        batches_per_second: 37.03 +/- 0.51 [36.07, 37.61]\n",
      "      metrics:\n",
      "        batches_per_second_max: 37.61201632067435\n",
      "        batches_per_second_mean: 37.033045875046696\n",
      "        batches_per_second_min: 36.067313893594516\n",
      "        batches_per_second_std: 0.50780971086581\n",
      "        seconds_per_batch_max: 0.027725934982299805\n",
      "        seconds_per_batch_mean: 0.02700803279876709\n",
      "        seconds_per_batch_min: 0.026587247848510742\n",
      "        seconds_per_batch_std: 0.0003736220491615088\n",
      "    on_device_inference:\n",
      "      human_readable:\n",
      "        batch_latency: -10540992.069 us +/- 570.098 ms [-11600288.391 us, -9841055.870\n",
      "          us]\n",
      "        batches_per_second: -0.10 +/- 0.00 [-0.10, -0.09]\n",
      "      metrics:\n",
      "        batches_per_second_max: -0.08620475338924137\n",
      "        batches_per_second_mean: -0.09513522621950261\n",
      "        batches_per_second_min: -0.10161511256558836\n",
      "        batches_per_second_std: 0.004951171784359727\n",
      "        seconds_per_batch_max: -9.841055870056152\n",
      "        seconds_per_batch_mean: -10.540992069244385\n",
      "        seconds_per_batch_min: -11.600288391113281\n",
      "        seconds_per_batch_std: 0.5700984989100456\n",
      "    total:\n",
      "      human_readable:\n",
      "        batch_latency: 44.784 ms +/- 1.045 ms [43.688 ms, 46.761 ms]\n",
      "        batches_per_second: 22.34 +/- 0.51 [21.39, 22.89]\n",
      "      metrics:\n",
      "        batches_per_second_max: 22.88979966055261\n",
      "        batches_per_second_mean: 22.341232189635942\n",
      "        batches_per_second_min: 21.385435096288667\n",
      "        batches_per_second_std: 0.5137971463186092\n",
      "        seconds_per_batch_max: 0.04676079750061035\n",
      "        seconds_per_batch_mean: 0.0447843074798584\n",
      "        seconds_per_batch_min: 0.04368758201599121\n",
      "        seconds_per_batch_std: 0.0010445368610745049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "print(yaml.dump(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f06e8-3f05-403d-a1e1-05d9f1d41452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
