{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaab60b-ca3e-4bcc-950f-ddab0abe8d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION : 2.2.2\n",
      "GPU  :  cuda\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "print(\"TORCH VERSION :\", version(\"torch\"))\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backend.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(\"GPU  : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b042382-d341-48c3-b6ef-576b8bd076af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdc3b65-9f33-430c-9f2b-3d9fb0175266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740],\n",
      "        [0.8665, 0.1366, 0.1025, 0.1841, 0.7264],\n",
      "        [0.3153, 0.6871, 0.0756, 0.1966, 0.3164]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4070, 0.2828, 0.3103],\n",
       "        [0.2295, 0.5150, 0.2555],\n",
       "        [0.3217, 0.3264, 0.3519]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Self Attention Implementation\n",
    "inputs = torch.rand(3, 5)\n",
    "print(inputs)\n",
    "attention_scores = inputs @ inputs.T\n",
    "attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc084034-c890-4fdb-bba6-90f3d4616cc8",
   "metadata": {},
   "source": [
    "This self-attention mechanism is also called \"scaled dot-product attention\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63b7cb5-c4bb-488b-8251-ddfb3594be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self attention implementationw ith trainable weights\n",
    "class SingleHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, blocksize, dropout=0.0, mask=False, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if mask:\n",
    "            self.register_buffer(\"mask\", torch.triu(torch.ones(blocksize, blocksize), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, token_count, _ = x.shape\n",
    "\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        attention_scores = queries @ keys.transpose(1, 2)\n",
    "\n",
    "        if hasattr(self, \"mask\"):\n",
    "            attention_scores.masked_fill_(self.mask.bool()[:token_count, :token_count], -torch.inf)\n",
    "\n",
    "        attention_weights = F.softmax(attention_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        context_vector = attention_weights @ values\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94328c42-af8d-4214-b092-43c59cd4fafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand(1, 10, 12)\n",
    "d_in = d_out = inp.shape[-1]\n",
    "sha = SingleHeadAttention(d_in, d_out, inp.shape[1], mask=True)\n",
    "result = sha(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57ddc68-7c4b-4e50-a3bf-9b81e0c1c1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzcAAAGVCAYAAADDmg8WAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaVUlEQVR4nO3deXxU1fnH8e8kIQlbAkgWlmgAF0BWE4ksVpTUoEhL6wIWZRHRHxJFgtZghYAoEYsUESSCIqhBaFUslcUiiHVBoihWLatsEQ1LKQmLZJm5vz9opozJXDKZuZnJ5PPu675sbu597pnJMM+cec49x2YYhiEAAAAAqOVC/N0AAAAAAPAFOjcAAAAAggKdGwAAAABBgc4NAAAAgKBA5wYAAABAUKBzAwAAACAo0LkBAAAAEBTo3AAAAAAICmH+bgAABKozZ86opKTEJ7HCw8MVGRnpk1gAgLqL3GSOzg0AVOLMmTNqc1EjFRy2+yRefHy89u7dG3RJBABQc8hN50fnBgAqUVJSooLDdu3fkqioxt6N4C064dBFSftUUlISVAkEAFCzyE3nR+cGAEw0amxTo8Y2r2I45N35AACci9zkHp0bADBhNxyyG97HAADAV8hN7jFbGgAAAICgQOUGAEw4ZMgh774e8/Z8AADORW5yj8oNAJhw+Oh/AAD4ij9z07x585SYmKjIyEilpKQoLy/P9Pjjx49r7NixatGihSIiInTppZdq9erV1bp2VVC5AQAAAHBey5cvV0ZGhnJycpSSkqLZs2crLS1NO3bsUGxsbIXjS0pK9Mtf/lKxsbF644031KpVK+3fv19NmjSxrI10bgDAhN0wZDe8K917ez4AAOfyV26aNWuWRo8erZEjR0qScnJytGrVKi1atEiZmZkVjl+0aJGOHTumTz75RPXq1ZMkJSYmetXu82FYGgCYKB/X7O0GAICv+CM3lZSUaMuWLUpNTXXuCwkJUWpqqjZt2lTpOStXrlTPnj01duxYxcXFqVOnTpo+fbrsdt8sQloZKjcAAABAHVVUVOTyc0REhCIiIiocd/ToUdntdsXFxbnsj4uL0/bt2yuNvWfPHm3YsEFDhw7V6tWrtXv3bt13330qLS1VVlaW7x7EOajcAIAJhwzZvdyo3AAAfMmXuSkhIUHR0dHOLTs723ftdDgUGxurBQsWKCkpSYMHD9Yf/vAH5eTk+OwaP0flBgBMMN0mACDQ+DI35efnKyoqyrm/sqqNJDVv3lyhoaE6dOiQy/5Dhw4pPj6+0nNatGihevXqKTQ01LmvQ4cOKigoUElJicLDw716DJWhcgMAAADUUVFRUS6bu85NeHi4kpKStH79euc+h8Oh9evXq2fPnpWe07t3b+3evVsOx/+mnd65c6datGhhScdGonMDAKbKZ6TxdgMAwFf8lZsyMjK0cOFCLVmyRNu2bdOYMWN06tQp5+xpw4YN08SJE53HjxkzRseOHdO4ceO0c+dOrVq1StOnT9fYsWN99lz8HMPSAMCE47+btzEAAPAVf+WmwYMH68iRI5o8ebIKCgrUrVs3rV271jnJwIEDBxQS8r/aSUJCgt59912NHz9eXbp0UatWrTRu3Dg98sgjXrbePZth8JUiAPxcUVGRoqOjtX1bnBo39q7IfeKEQ+07HFJhYaHLuGYAADxBbjo/KjcAYKJ8VhlvYwAA4CvkJvfo3ACACbtxdvM2BgAAvkJuco8JBQAAAAAEBSo3AGCCCQUAAIGG3OQenRsAMOGQTXbZvI4BAICvkJvcY1gaAAAAgKBA5QYATDiMs5u3MQAA8BVyk3t0bgDAhN0HpX9vzwcA4FzkJvcYlgYAAAAgKFC5AQATfDsGAAg05Cb36NwAgAmHYZPD8HJGGi/PBwDgXOQm9xiWBgAAACAo0LkBABPlpX9vN6A6Xn31VbVv31716tVTkyZN/N0cv7DZbJoyZYrH502ZMkU2W+3/tzdixAglJia67Dt58qTuvvtuxcfHy2az6cEHH/RL22pSsPw9fYXc5B6dmyC3ePFi2Ww2ff755/5uiiTp9OnTmjJlijZu3Fil4//1r39pypQp2rdvn6XtAtyxK8QnG/Bzzz//vGw2m1JSUir9/fbt2zVixAi1a9dOCxcu1IIFCzx+D0Vwmj59uhYvXqwxY8bo1Vdf1Z133ul1zOeff16LFy+usL8m8zCv76ojN7kXnI8KAev06dOaOnWqR52bqVOn0rkBEHRyc3OVmJiovLw87d69u8LvN27cKIfDoWeffVYjRozQbbfd5vF7aF322GOP6aeffvJ3MyyxYcMGXXXVVcrKytIdd9yhpKQkr2OadW5qKg+bvb6D+e8J36JzA9SQM2fOyOFw+LsZ8JDx35s2vdmMIL1pE9W3d+9effLJJ5o1a5ZiYmKUm5tb4ZjDhw9LUo0MRzt16pTl16hpYWFhioyM9HczLHH48OE6N0wxmP+e1UFuco/OTR00YsQINWrUSAcPHtSgQYPUqFEjxcTE6KGHHpLdbncet2/fPtlsNs2cOVN/+tOfdNFFF6l+/fq65ppr9M0337jE7Nu3r/r27VvptcrHCu/bt08xMTGSpKlTp8pms5mOpV68eLFuvfVWSdK1117rPP7cb3TWrFmjq6++Wg0bNlTjxo01YMAAffvtt9V6vJK0bNkyJSUlqXHjxoqKilLnzp317LPPuhyzZ88e3XrrrWrWrJkaNGigq666SqtWrXI5ZuPGjbLZbFq2bJkee+wxtWrVSg0aNFBRUVGljxWBi3HNsEJubq6aNm2qAQMG6JZbbqnQuUlMTFRWVpYkKSYmRjabTSNGjDjve+j27dt1yy23qFmzZoqMjFRycrJWrlzpErt8uPIHH3yg++67T7GxsWrdurXbtpaUlGjy5MlKSkpSdHS0GjZsqKuvvlrvv/++y3Ge5Izy9+U9e/YoLS1NDRs2VMuWLfX444/LMNwvm/7+++/LZrNpxYoVFX63dOlS2Ww2bdq0SVLl92jYbDalp6fr7bffVqdOnRQREaHLL79ca9eurRBv48aNSk5OVmRkpNq1a6cXXnihyvd97Nq1SzfffLPi4+MVGRmp1q1ba8iQISosLHQ57rXXXlNSUpLq16+vZs2aaciQIcrPz3cbtzy37N27V6tWrXK+BsyqKi+//LKuu+46xcbGKiIiQh07dtT8+fNdjklMTNS3336rDz74wBmzb9++NZqHz/cZobLnvqysTNOmTVO7du0UERGhxMREPfrooyouLq7w+G666SZ99NFH6tGjhyIjI9W2bVu98sorbp+3QEduco+poOsou92utLQ0paSkaObMmXrvvff0zDPPqF27dhozZozLsa+88opOnDihsWPH6syZM3r22Wd13XXX6euvv1ZcXFyVrxkTE6P58+drzJgx+s1vfqPf/va3kqQuXbpUevwvfvELPfDAA5ozZ44effRRdejQQZKc/3311Vc1fPhwpaWlacaMGTp9+rTmz5+vPn366Msvv3S5AbMqj3fdunW6/fbb1a9fP82YMUOStG3bNn388ccaN26cJOnQoUPq1auXTp8+rQceeEAXXHCBlixZol/96ld644039Jvf/MblMUybNk3h4eF66KGHVFxcrPDw8Co/XwCCV25urn77298qPDxct99+u+bPn6/PPvtMV155pSRp9uzZeuWVV7RixQrNnz9fjRo1UufOnXXVVVe5fQ/99ttv1bt3b7Vq1UqZmZlq2LCh/vznP2vQoEF68803K7w/3XfffYqJidHkyZNNKzdFRUV68cUXdfvtt2v06NE6ceKEXnrpJaWlpSkvL0/dunVzOb6qOcNut6t///666qqr9PTTT2vt2rXKyspSWVmZHn/88Urb0rdvXyUkJCg3N7fC48nNzVW7du3Us2dP0+f+o48+0ltvvaX77rtPjRs31pw5c3TzzTfrwIEDuuCCCyRJX375pfr3768WLVpo6tSpstvtevzxx50fvs2UlJQoLS1NxcXFuv/++xUfH6+DBw/qnXfe0fHjxxUdHS1JevLJJzVp0iTddtttuvvuu3XkyBE999xz+sUvfqEvv/yy0spMhw4d9Oqrr2r8+PFq3bq1JkyYIEmm7Zo/f74uv/xy/epXv1JYWJj+9re/6b777pPD4dDYsWMlnX293X///WrUqJH+8Ic/SJLi4uLUrl27GsvDnn5GkKS7775bS5Ys0S233KIJEyZo8+bNys7O1rZt2yp0gHfv3q1bbrlFo0aN0vDhw7Vo0SKNGDFCSUlJuvzyy83+pKhtDAS1l19+2ZBkfPbZZ859w4cPNyQZjz/+uMux3bt3N5KSkpw/792715Bk1K9f3/j++++d+zdv3mxIMsaPH+/cd8011xjXXHNNhesPHz7cuOiii5w/HzlyxJBkZGVlVan9f/nLXwxJxvvvv++y/8SJE0aTJk2M0aNHu+wvKCgwoqOjXfZX9fGOGzfOiIqKMsrKyty258EHHzQkGR9++KFLW9q0aWMkJiYadrvdMAzDeP/99w1JRtu2bY3Tp09X6bEisBQWFhqSjDX/bGP8Y287r7Y1/2xjSDIKCwv9/bAQAD7//HNDkrFu3TrDMAzD4XAYrVu3NsaNG+dyXFZWliHJOHLkiHOf2Xtov379jM6dOxtnzpxx7nM4HEavXr2MSy65xLmvPC/06dPH9P2uXFlZmVFcXOyy7z//+Y8RFxdn3HXXXc59nuSM8vfl+++/36WtAwYMMMLDw10e888f78SJE42IiAjj+PHjzn2HDx82wsLCXI4rf/7OJckIDw83du/e7dz31VdfGZKM5557zrlv4MCBRoMGDYyDBw869+3atcsICwurEPPnvvzyS0OS8Ze//MXtMfv27TNCQ0ONJ5980mX/119/bYSFhbns/3keNQzDuOiii4wBAwaYtqNcZTkoLS3NaNu2rcu+yy+/vNI8XpN52Oz1/fO/59atWw1Jxt133+1y3EMPPWRIMjZs2ODcd9FFFxmSjH/84x/OfYcPHzYiIiKMCRMmVLhWICM3nR/D0uqw//u//3P5+eqrr9aePXsqHDdo0CC1atXK+XOPHj2UkpKi1atXW95Gd9atW6fjx4/r9ttv19GjR51baGioUlJSKgyXkM7/eJs0aaJTp05p3bp1bq+7evVq9ejRQ3369HHua9Soke655x7t27dP//rXv1yOHz58uOrXr1/dh4kA4JBNDoV4uQVn6R/Vk5ubq7i4OF177bWSzg6VGjx4sJYtW1ZhqGxVHTt2TBs2bNBtt92mEydOON8T//3vfystLU27du3SwYMHXc4ZPXq0QkNDzxs7NDTUWXV2OBw6duyYysrKlJycrC+++KLC8Z7kjPT0dOf/Lx8yVlJSovfee89te4YNG6bi4mK98cYbzn3Lly9XWVmZ7rjjjvM+ntTUVLVr1875c5cuXRQVFeXMB3a7Xe+9954GDRqkli1bOo+7+OKLdcMNN5w3fnll5t1339Xp06crPeatt96Sw+HQbbfd5pLD4uPjdckll1Saw6rr3BxUWFioo0eP6pprrtGePXsqDJPzhBV52BPlr6eMjAyX/eXVrJ8PF+/YsaOuvvpq588xMTG67LLLqn19fyM3uUfnpo6KjIysUMZu2rSp/vOf/1Q49pJLLqmw79JLL/XrDGa7du2SJF133XWKiYlx2f7+9787b8QtV5XHe9999+nSSy/VDTfcoNatW+uuu+6qMA57//79uuyyyyq0p7xEv3//fpf9bdq0qf6DBBB07Ha7li1bpmuvvVZ79+7V7t27tXv3bqWkpOjQoUNav359teLu3r1bhmFo0qRJFd4Ty+/d+fn7oifvT0uWLFGXLl0UGRmpCy64QDExMVq1alWlH46rmjNCQkLUtm3bCsdJMs0v7du315VXXulyn1Jubq6uuuoqXXzxxed9LBdeeGGFfefmg8OHD+unn36qNFZV4rdp00YZGRl68cUX1bx5c6WlpWnevHkuz9WuXbtkGIYuueSSCn+vbdu2VfhbeePjjz9WamqqGjZsqCZNmigmJkaPPvqoJHnVubEiD3ti//79CgkJqfA3iY+PV5MmTSrk4/P93RE8uOemjqrKt3WesNlsld4EWt1vIc+nfNaxV199VfHx8RV+Hxbm+tKuyuONjY3V1q1b9e6772rNmjVas2aNXn75ZQ0bNkxLliypVjup2tR+vrjpMlhv2oTnNmzYoB9//FHLli3TsmXLKvw+NzdX119/vcdxy98TH3roIaWlpVV6zM8/BFb1/em1117TiBEjNGjQID388MOKjY1VaGiosrOz9d1333ncVl8YNmyYxo0bp++//17FxcX69NNPNXfu3Cqd6y4fVJbDquuZZ57RiBEj9Ne//lV///vf9cADDyg7O1uffvqpWrduLYfDIZvNpjVr1lTankaNGvmkHd9995369eun9u3ba9asWUpISFB4eLhWr16tP/3pT17N4GlFHq6Oqi7sWRN/95pEbnKPzg3Oq/zbmXPt3LnT5UbBpk2bVlra/fk3J56uLuzu+PIhBbGxsUpNTfUoppnw8HANHDhQAwcOlMPh0H333acXXnhBkyZN0sUXX6yLLrpIO3bsqHDe9u3bJUkXXXSRz9qCwGA3QmT3cgSvvZYmT/hebm6uYmNjNW/evAq/e+utt7RixQrl5OS47Xi4e08sr4DUq1fPp++JkvTGG2+obdu2euutt1yuX14R+rmq5Azp7IfjPXv2OKs15cdJqnDszw0ZMkQZGRl6/fXX9dNPP6levXoaPHhwFR+RudjYWEVGRla69lBl+9zp3LmzOnfurMcee0yffPKJevfurZycHD3xxBNq166dDMNQmzZtXB6/r/3tb39TcXGxVq5c6VK5qGzImLvXVk3mYU8+I1x00UVyOBzatWuXc/SEdHbin+PHjwd9PiY3ucewNJzX22+/7TJWOy8vT5s3b3YZe9yuXTtt375dR44cce776quv9PHHH7vEatCggSTp+PHjVbp2w4YNKz0+LS1NUVFRmj59ukpLSyucd247qurf//63y88hISHOWVrKp5W88cYblZeX55xqVDq7PsSCBQuUmJiojh07enxdAHXDTz/9pLfeeks33XSTbrnllgpbenq6Tpw4UWHq5nO5ew+NjY1V37599cILL+jHH3+scF513hPLlX/jfe433Js3b3Z5HzxXVXJGuXOrLYZhaO7cuapXr5769etn2qbmzZvrhhtu0Guvvabc3Fz1799fzZs39+hxuRMaGqrU1FS9/fbb+uGHH5z7d+/erTVr1pz3/KKiIpWVlbns69y5s0JCQpy55Le//a1CQ0M1derUCpUDwzAq5KPqquxvV1hYqJdffrnCsQ0bNqw0N9dkHvbkM8KNN94o6exMb+eaNWuWJGnAgAEeXx/BgcoNzuviiy9Wnz59NGbMGBUXF2v27Nm64IIL9Pvf/955zF133aVZs2YpLS1No0aN0uHDh5WTk6PLL7/cZW2X+vXrq2PHjlq+fLkuvfRSNWvWTJ06dVKnTp0qvXa3bt0UGhqqGTNmqLCwUBEREc75+ufPn68777xTV1xxhYYMGaKYmBgdOHBAq1atUu/evas8RKHc3XffrWPHjum6665T69attX//fj333HPq1q2b81uhzMxMvf7667rhhhv0wAMPqFmzZlqyZIn27t2rN998UyEhfF8QbM7etOld6T5Yb9qEZ1auXKkTJ07oV7/6VaW/v+qqq5wLerqrQpi9h86bN099+vRR586dNXr0aLVt21aHDh3Spk2b9P333+urr76qVrtvuukmvfXWW/rNb36jAQMGaO/evcrJyVHHjh118uTJCsdXJWdIZ+/BWLt2rYYPH66UlBStWbNGq1at0qOPPlqlKZeHDRumW265RdLZafd9acqUKfr73/+u3r17a8yYMbLb7Zo7d646deqkrVu3mp67YcMGpaen69Zbb9Wll16qsrIyvfrqqwoNDdXNN98s6ewXgk888YQmTpyoffv2adCgQWrcuLH27t2rFStW6J577tFDDz3k9eO4/vrrnSMS7r33Xp08eVILFy5UbGxshU5wUlKS5s+fryeeeEIXX3yxYmNjdd1119VoHvbkM0LXrl01fPhwLViwQMePH9c111yjvLw8LVmyRIMGDXJO2BGsyE3u0bnBeQ0bNkwhISGaPXu2Dh8+rB49emju3Llq0aKF85gOHTrolVde0eTJk5WRkaGOHTvq1Vdf1dKlS10W+5KkF198Uffff7/Gjx+vkpISZWVlue3cxMfHKycnR9nZ2Ro1apTsdrvef/99xcbG6ne/+51atmypp556Sn/84x9VXFysVq1a6eqrr9bIkSM9fpx33HGHFixYoOeff17Hjx9XfHy8Bg8erClTpjg7LXFxcfrkk0/0yCOP6LnnntOZM2fUpUsX/e1vf+NboiDlUIjsXha5HQrO0j88k5ubq8jISP3yl7+s9PchISEaMGCAcnNzTb+5d/ce2rFjR33++eeaOnWqFi9erH//+9+KjY1V9+7dNXny5Gq3e8SIESooKNALL7ygd999Vx07dtRrr72mv/zlLxXe36Wq5QzpbFVh7dq1GjNmjB5++GE1btxYWVlZVW7rwIED1bRpUzkcDrcdxupKSkrSmjVr9NBDD2nSpElKSEjQ448/rm3btjmHIbvTtWtXpaWl6W9/+5sOHjyoBg0aqGvXrlqzZo2uuuoq53GZmZm69NJL9ac//UlTp06VJCUkJOj666/32eO57LLL9MYbb+ixxx7TQw89pPj4eOeaMnfddZfLsZMnT9b+/fv19NNP68SJE7rmmmt03XXX1Wgeljz7jPDiiy+qbdu2Wrx4sVasWKH4+HhNnDjR7ZDJYEJucs9m1NY7qWC5ffv2qU2bNvrjH//ok2+QgNqkqKhI0dHR+stX7dWgsXc3wp4+YdetXbersLBQUVFRPmohEFg8yRkjRozQG2+8UWnlp6rKysrUsmVLDRw4UC+99FK143hi0KBB+vbbbyu9rwioCeSm86NyAwAmuGkTCExvv/22jhw5omHDhlkS/6effnKZ2GHXrl1avXq1hg8fbsn1AE+Qm9yjcwMAJsoXO/MuRnAmEMAfNm/erH/+85+aNm2aunfvrmuuucaS67Rt21YjRoxQ27ZttX//fs2fP1/h4eEV7h0C/IHc5B6dGwAAUGvMnz9fr732mrp166bFixdbdp3+/fvr9ddfV0FBgSIiItSzZ09Nnz690kVKAQQO7rkBgEqUj2t+9cvOPhnXfGf3r4NuXDMAoGaRm86Pyg0AmLD7YEYae5CW/gEA/kFuco9FOQAAAAAEBSo3AGDCYYTI4eWMNA5G/wIAfIjc5B6VGwAwUV7693YDAMBX/Jmb5s2bp8TEREVGRiolJUV5eXlVOm/ZsmWy2WwaNGhQta5bVQGdcav75PlTdna2rrzySjVu3FixsbEaNGiQduzY4e9mVctTTz0lm82mBx980N9NqZKDBw/qjjvu0AUXXKD69eurc+fO+vzzz/3drPOy2+2aNGmS2rRpo/r166tdu3aaNm2aAnGuj3/84x8aOHCgWrZsKZvNprffftvl94ZhaPLkyWrRooXq16+v1NRUFrtD0CE3+U9ty0sSuakmkJtqzvLly5WRkaGsrCx98cUX6tq1q9LS0nT48GHT8/bt26eHHnpIV199teVtDNjOTXWfPH/74IMPNHbsWH366adat26dSktLdf311+vUqVP+bppHPvvsM73wwgvq0qWLv5tSJf/5z3/Uu3dv1atXT2vWrNG//vUvPfPMM2ratKm/m3ZeM2bM0Pz58zV37lxt27ZNM2bM0NNPP63nnnvO302r4NSpU+ratavmzZtX6e+ffvppzZkzRzk5Odq8ebMaNmyotLQ0nTlzpoZb6jsOSXbD5tXm8PeDgM+Qm/yntuUlidxUU8hNNZebZs2apdGjR2vkyJHq2LGjcnJy1KBBAy1atMjtOXa7XUOHDtXUqVPVtm3baj/mqgrYqaBTUlJ05ZVXau7cuZIkh8OhhIQE3X///crMzPRz66ruyJEjio2N1QcffKBf/OIX/m5OlZw8eVJXXHGFnn/+eT3xxBPq1q2bZs+e7e9mmcrMzNTHH3+sDz/80N9N8dhNN92kuLg4vfTSS859N998s+rXr6/XXnvNjy0zZ7PZtGLFCmd52TAMtWzZUhMmTNBDDz0kSSosLFRcXJwWL16sIUOG+LG1niufbnP+F1eqfiPvbk/86WSZxlzxWdBNt1kXkZv8ozbmJYnc5A/kpqrzNDeVlJSoQYMGeuONN1yGlg0fPlzHjx/XX//610rPy8rK0j//+U+tWLFCI0aM0PHjxytU13wpICs3JSUl2rJli1JTU537QkJClJqaqk2bNvmxZZ4rLCyUJDVr1szPLam6sWPHasCAAS7Pf6BbuXKlkpOTdeuttyo2Nlbdu3fXwoUL/d2sKunVq5fWr1+vnTt3SpK++uorffTRR7rhhhv83DLP7N27VwUFBS6vm+joaKWkpNS6f7dAZchN/lMb85JEbgoE5KbzKyoqctmKi4srPe7o0aOy2+2Ki4tz2R8XF6eCgoJKz/noo4/00ksv1ejrPiBnSzN78rZv3+6nVnnO4XDowQcfVO/evdWpUyd/N6dKli1bpi+++EKfffaZv5vikT179mj+/PnKyMjQo48+qs8++0wPPPCAwsPDNXz4cH83z1RmZqaKiorUvn17hYaGym6368knn9TQoUP93TSPlL+xefKmVxvYjRDZvZyRxtvzERjITf5RW/OSRG4KBOQm8xiSlJCQ4LI/KytLU6ZM8Sq2JJ04cUJ33nmnFi5cqObNm3sdr6oCsnMTLMaOHatvvvlGH330kb+bUiX5+fkaN26c1q1bp8jISH83xyMOh0PJycmaPn26JKl79+765ptvlJOTE/AJ5M9//rNyc3O1dOlSXX755dq6dasefPBBtWzZMuDbXhc4ZJNDNq9jAIGiNuWm2pyXJHITrOPL3JSfn+8yLC0iIqLS45s3b67Q0FAdOnTIZf+hQ4cUHx9f4fjvvvtO+/bt08CBA/93TcfZO33CwsK0Y8cOtWvXzqvHUJmA/DrR0ycvEKWnp+udd97R+++/r9atW/u7OVWyZcsWHT58WFdccYXCwsIUFhamDz74QHPmzFFYWJjsdru/m+hWixYt1LFjR5d9HTp00IEDB/zUoqp7+OGHlZmZqSFDhqhz58668847NX78eGVnZ/u7aR4p/7dZm//dAmbITTWvNuclidwUCMhN5xcVFeWyuevchIeHKykpSevXr3fuczgcWr9+vXr27Fnh+Pbt2+vrr7/W1q1bnduvfvUrXXvttdq6dWuFipGvBGTnxtMnL5AYhqH09HStWLFCGzZsUJs2bfzdpCrr169fhRdhcnKyhg4dqq1btyo0NNTfTXSrd+/eFaY13blzpy666CI/tajqTp8+rZAQ13+KoaGhzm83aos2bdooPj7e5d9tUVGRNm/eHPD/bs2Ul/693VD7kZtqXm3OSxK5KRCQm3ybmzIyMrRw4UItWbJE27Zt05gxY3Tq1CmNHDlSkjRs2DBNnDhRkhQZGalOnTq5bE2aNFHjxo3VqVMnhYeH+/Q5KReww9IyMjI0fPhwJScnq0ePHpo9e7bLkxeoxo4dq6VLl+qvf/2rGjdu7BzPGR0drfr16/u5debKX2znatiwoS644IKAH5c9fvx49erVS9OnT9dtt92mvLw8LViwQAsWLPB3085r4MCBevLJJ3XhhRfq8ssv15dffqlZs2bprrvu8nfTKjh58qR2797t/Hnv3r3aunWrmjVrpgsvvFAPPvignnjiCV1yySVq06aNJk2apJYtW1q+YJeVfLEIJ4t4Bg9yU82qzXlJIjfVFHJT9WN4avDgwTpy5IgmT56sgoICdevWTWvXrnXe03TgwIEKneKaFrBTQUvS3Llz9cc//tH55M2ZM0cpKSn+bpYpm63y8Y8vv/yyRowYUbON8YG+ffvWmik333nnHU2cOFG7du1SmzZtlJGRodGjR/u7Wed14sQJTZo0SStWrNDhw4fVsmVL3X777Zo8ebJl32pU18aNG3XttddW2D98+HAtXrxYhmEoKytLCxYs0PHjx9WnTx89//zzuvTSS/3QWu+UT7c58/M+Pplu86Hkj5gKOkiQm/yrNuUlidxUE8hN1ROsuSmgOzcA4C/lCeTpz672SQL5/ZUfBl0CAQDULHLT+QXssDQACAQOH5T+HQxLAwD4ELnJveB8VAAAAADqHCo3AGDCYYTI4eVsZ96eDwDAuchN7tG5AQATdtlk93KhNG/PBwDgXOQm94KzywYAAACgzqFyAwAmKP0DAAINuck9OjcAYMIu70v3dt80BQAASeQmMwHdZSsuLtaUKVNUXFzs76Z4jLb7B233j9rcdsBTtfn1Ttv9g7b7R21uO6ovoBfxLF+oqDYuLkTb/YO2+0dtbrs75Y/psU+vV2Sjel7FOnOyVE9c9fegen7qstr8eqft/kHb/aM2t90dctP5MSwNAEzYjRDZvRyX7O35AACci9zkXnA+KgAIAvPmzVNiYqIiIyOVkpKivLw80+Nnz56tyy67TPXr11dCQoLGjx+vM2fO1FBrAQDwvxqv3DgcDv3www9q3LixbDbzG6GKiopc/lub0Hb/oO3+EUhtNwxDJ06cUMuWLRUS4v33N4Zscnh506ZRjfOXL1+ujIwM5eTkKCUlRbNnz1ZaWpp27Nih2NjYCscvXbpUmZmZWrRokXr16qWdO3dqxIgRstlsmjVrllftD3ae5CUpsF7vnqLt/kHb/SOQ2h4suak2qPF7br7//nslJCTU5CUB1EH5+flq3bp1tc8vH9f88CcDFOHluObik6X6Y69VHo1rTklJ0ZVXXqm5c+dKOvsBPCEhQffff78yMzMrHJ+enq5t27Zp/fr1zn0TJkzQ5s2b9dFHH3nV/mBHXgJQU2p7bqoNarxy07hxY0nSxWMmKzQi0ufxW//tkM9jnqvv0q8ti730lVTLYktSeN9/WxZ7dNsPLYstSU9/kWZZ7MgGpZbFlqT3k16zLPavJ95rWWxJKr79uGWxI15vYklce+kZffnOk873mtqopKREW7Zs0cSJE537QkJClJqaqk2bNlV6Tq9evfTaa68pLy9PPXr00J49e7R69WrdeeedNdXsWqv8tZL4+0kKsSAvOcJ9HtJFt6t2WRa7TxPrYkvS6mus61QeWmRth7Vof7Rlsbt3/86y2JL09ScXWxZ71m9etiy2JD2150bLYh/8sZllsR0/ndEPE56q1bmptqjxzk15yT80ItKSzk1YaITPY54rspF1T5kVz4dL/AbWPTf1LXxeJCmkgXXPTWgDa289i2psXfyweta+ZsosfM1Y3faqDC+qCodhk8PwLlb5+T8fGhEREaGIiIrP8dGjR2W32xUXF+eyPy4uTtu3b6/0Gr/73e909OhR9enTR4ZhqKysTP/3f/+nRx991Ku21wXlr5WQiEiFRFrwurS4c1OvoXUXsPq9PcxmXdutzHmSFFLfuvcwK/+mkqx5nf9Xw8ahlsWWpLCG1v1drfyblgvE3BRsmFAAAEzYFeKTTZISEhIUHR3t3LKzs33Wzo0bN2r69Ol6/vnn9cUXX+itt97SqlWrNG3aNJ9dAwAQGHyZm4INU0EDQA3Jz893GddcWdVGkpo3b67Q0FAdOuQ6zPbQoUOKj4+v9JxJkybpzjvv1N133y1J6ty5s06dOqV77rlHf/jDH3xyAysAAIGObAcAJspL/95ukhQVFeWyuevchIeHKykpyWVyAIfDofXr16tnz56VnnP69OkKHZjQ0LPDQwJ4rWYAQDX4MjcFGyo3AGDCoRA5vPweqDrnZ2RkaPjw4UpOTlaPHj00e/ZsnTp1SiNHjpQkDRs2TK1atXIObRs4cKBmzZql7t27KyUlRbt379akSZM0cOBAZycHABAc/JWbaoNqPSpPF5YDAHhm8ODBmjlzpiZPnqxu3bpp69atWrt2rXOSgQMHDujHH390Hv/YY49pwoQJeuyxx9SxY0eNGjVKaWlpeuGFF/z1EGocuQkA4HHlxtOF5QCgNrMbNtm9LN1X9/z09HSlp6dX+ruNGze6/BwWFqasrCxlZWVV61q1HbkJQF3iz9wU6Dyu3MyaNUujR4/WyJEj1bFjR+Xk5KhBgwZatGiRFe0DAL9iXHPtQG4CUJeQm9zzqHNTvrBcaur/Fps838JyAABYidwEACjn0bC06iwsV1xcrOLiYufPP1/EDgACmWGEyGF4d9Ol4eX5MOdpbiIvAajtyE3uWf6osrOzXRatS0hIsPqSAOAzdtl8siFwkJcA1HbkJvc86txUZ2G5iRMnqrCw0Lnl5+dXv7UAAPyMp7mJvAQAwcujzk11FpaLiIiosHAdANQWDsMXN276+1EEN09zE3kJQG1HbnLP46mgz7ewHAAEE4cPxjV7ez7Oj9wEoC4hN7nncedm8ODBOnLkiCZPnqyCggJ169bNZWE5AABqGrkJACBVo3MjmS8sBwDBxCGbHF7edOnt+agachOAuoLc5F61OjcAUFewCjQAINCQm9wLzsF2AAAAAOocKjcAYIKbNgEAgYbc5B6dGwAw4dDZKTO9jQEAgK+Qm9wLzi4bAAAAAJ+bN2+eEhMTFRkZqZSUFOXl5bk9duHChbr66qvVtGlTNW3aVKmpqabH+4LfKjfj7nxL9Rv5/vKt7v2Pz2Oea2bnFMtiv/qvWZbFlqTpB2+0LPYbBUmWxZaki1scsSz2tLYrLIstSckvPGhZ7DYffmdZbEn6IaadZbGjdlrzb7XMXuzTeIYPZqQxgvTbMVSNPc63r8mfy/su0bLY2destCy2JL1d0sKy2EVF9S2LLUkKtW4FxMjQUstiS5LNbl3sS+oVWhdcUoN6JZbFbh5bZFls++life/DeP7KTcuXL1dGRoZycnKUkpKi2bNnKy0tTTt27FBsbGyF4zdu3Kjbb79dvXr1UmRkpGbMmKHrr79e3377rVq1auVV+92hcgMAJrxfAdr7oQMAAJzLX7lp1qxZGj16tEaOHKmOHTsqJydHDRo00KJFiyo9Pjc3V/fdd5+6deum9u3b68UXX5TD4dD69eu9fQrconMDAAAA1FFFRUUuW3Fx5dXmkpISbdmyRampqc59ISEhSk1N1aZNm6p0rdOnT6u0tFTNmjXzSdsrQ+cGAEyUz0jj7QYAgK/4MjclJCQoOjrauWVnZ1d6zaNHj8putysuLs5lf1xcnAoKCqrU7kceeUQtW7Z06SD5GrOlAYAJXwwrY1gaAMCXfJmb8vPzFRUV5dwfERHhVVx3nnrqKS1btkwbN25UZGSkJdeQ6NwAAAAAdVZUVJRL58ad5s2bKzQ0VIcOHXLZf+jQIcXHx5ueO3PmTD311FN677331KVLF6/aez6MlQAAE47/zkjj7QYAgK/4IzeFh4crKSnJZTKA8skBevbs6fa8p59+WtOmTdPatWuVnJxc7cdcVVRuAMAEw9IAAIHGX7kpIyNDw4cPV3Jysnr06KHZs2fr1KlTGjlypCRp2LBhatWqlfO+nRkzZmjy5MlaunSpEhMTnffmNGrUSI0aNfKq/e7QuQEAAABwXoMHD9aRI0c0efJkFRQUqFu3blq7dq1zkoEDBw4oJOR/A8Pmz5+vkpIS3XLLLS5xsrKyNGXKFEvaSOcGAExQuQEABBp/5qb09HSlp6dX+ruNGze6/Lxv375qXcMbdG4AwASdGwBAoCE3uceEAgAAAACCApUbADDBt2MAgEBDbnKPzg0AmDAkr6dyNnzTFAAAJJGbzDAsDQAAAEBQoHIDACYo/QMAAg25yT06NwBgggQCAAg05Cb3GJYGAAAAIChQuQEAE3w7BgAINOQm9+jcAIAJEggAINCQm9xjWBoAAACAoEDlBgBMGIZNhpffbnl7PgAA5yI3uUfnBgBMOGTzeqE0b88HAOBc5Cb3GJYGAAAAICj4rXIz/YNfKaR+pM/jNtxv7UNqfk2pZbFve6WrZbElafNdsyyL3WNxhmWxJam0sWFZ7JHrx1kWW5LOXFpsWew5m9+0LLYkvXI8xbLY7/3qMkvilp0qln7ru3jctFl3OMIlhfs+rmG3+HvEYuvif/hTomWxJckoK7MsdnikdbElyX7Q959hyp0sjbAstiSVRjksi90sxNrPYXbDutd7RJh1r5myUN/GJje5x7A0ADDBuGYAQKAhN7nHsDQAAAAAQYHKDQCYoPQPAAg05Cb36NwAgAlK/wCAQENuco9haQAAAACCApUbADBh+KD0H6zfjgEA/IPc5J5HlZvs7GxdeeWVaty4sWJjYzVo0CDt2LHDqrYBgN8ZkgzDy83fDyLIkZsA1DXkJvc86tx88MEHGjt2rD799FOtW7dOpaWluv7663Xq1Cmr2gcAgClyEwCgnEfD0tauXevy8+LFixUbG6stW7boF7/4hU8bBgCBwCGbbPJyRhovz4c5chOAuobc5J5X99wUFhZKkpo1a+aTxgBAoGFGmtqH3AQg2JGb3Kt258bhcOjBBx9U79691alTJ7fHFRcXq7i42PlzUVFRdS8JAICpquQm8hIABK9qTwU9duxYffPNN1q2bJnpcdnZ2YqOjnZuCQkJ1b0kANS48oXSvN1QM6qSm8hLAGo7cpN71ercpKen65133tH777+v1q1bmx47ceJEFRYWOrf8/PxqNRQA/MHr2Wj+u8F6Vc1N5CUAtR25yT2PhqUZhqH7779fK1as0MaNG9WmTZvznhMREaGIiIhqNxAAADOe5ibyEgAEL486N2PHjtXSpUv117/+VY0bN1ZBQYEkKTo6WvXr17ekgQDgT9y0GfjITQDqGnKTex4NS5s/f74KCwvVt29ftWjRwrktX77cqvYBgF+VJxBvN1iH3ASgriE3uefxsDQAAAIJuQkAUM6rdW4AINg5DJtsXn67Fawz0gAA/IPc5B6dGwAw4YsZZSgsAAB8idzkXrXXuQEAAABQt8ybN0+JiYmKjIxUSkqK8vLyTI//y1/+ovbt2ysyMlKdO3fW6tWrLW0fnRsAMHH22zFvb9r096MAAAQTf+Wm5cuXKyMjQ1lZWfriiy/UtWtXpaWl6fDhw5Ue/8knn+j222/XqFGj9OWXX2rQoEEaNGiQvvnmGy+fAffo3ACACWakAQAEGn/lplmzZmn06NEaOXKkOnbsqJycHDVo0ECLFi2q9Phnn31W/fv318MPP6wOHTpo2rRpuuKKKzR37lxvnwK3/HbPTb0mxQpp4PuEX9b8J5/HPJcttciy2CH/aGVZbEkacvG1lsW+MNna5/2Z13Isiz1o1TjLYktSh0mHLIv9y2nWtn3pLxZYFntzckNL4pYZpZbERfALOSOFWhDXiLBbEPV/7DbrSoOnHdYudmqrF25Z7NISaz/ihJZZFzs6/Ix1wSUZDa17TdazWfGv6H/i6p+wLPYhNbYsdlm9wM1NRUWun23dLXRcUlKiLVu2aOLEic59ISEhSk1N1aZNmyqNvWnTJmVkZLjsS0tL09tvv+19w92gcgMAJgwfbQAA+Iovc1NCQoKio6OdW3Z2dqXXPHr0qOx2u+Li4lz2x8XFORdP/rmCggKPjvcFZksDABOsAg0ACDS+zE35+fmKiopy7q+salOb0LkBAAAA6qioqCiXzo07zZs3V2hoqA4dch1uf+jQIcXHx1d6Tnx8vEfH+wLD0gDADOPSAACBxg+5KTw8XElJSVq/fr1zn8Ph0Pr169WzZ89Kz+nZs6fL8ZK0bt06t8f7ApUbADDji9nOGJYGAPAlP+WmjIwMDR8+XMnJyerRo4dmz56tU6dOaeTIkZKkYcOGqVWrVs77dsaNG6drrrlGzzzzjAYMGKBly5bp888/14IF1k1YROUGAAKUpwulHT9+XGPHjlWLFi0UERGhSy+91PLF0gAAdcfgwYM1c+ZMTZ48Wd26ddPWrVu1du1a56QBBw4c0I8//ug8vlevXlq6dKkWLFigrl276o033tDbb7+tTp06WdZGKjcAYOLsQmnex/BU+UJpOTk5SklJ0ezZs5WWlqYdO3YoNja2wvElJSX65S9/qdjYWL3xxhtq1aqV9u/fryZNmnjXeABAwPFXbpKk9PR0paenV/q7jRs3Vth366236tZbb63exaqBzg0AmPDXbGnnLpQmSTk5OVq1apUWLVqkzMzMCscvWrRIx44d0yeffKJ69epJkhITE71qNwAgMDGTp3sMSwOAAFO+UFpqaqpz3/kWSlu5cqV69uypsWPHKi4uTp06ddL06dNlt1u7gCQAAIGEyg0AmDFs3k8I8N/zq7oKtNlCadu3b6/0Env27NGGDRs0dOhQrV69Wrt379Z9992n0tJSZWVledd+AEBg8WFuCjZUbgDARPm4Zm83qeqrQFeHw+FQbGysFixYoKSkJA0ePFh/+MMflJOT47NrAAACgy9zU7ChcgMANaSqq0BXZ6G0Fi1aqF69egoNDXXu69ChgwoKClRSUqLw8HAfPAIAAAIblRsAMOPDhdLKV4Eu39x1bqqzUFrv3r21e/duORwO576dO3eqRYsWdGwAINiwwLRbdG4AwET5jDTebp7KyMjQwoULtWTJEm3btk1jxoypsFDaxIkTncePGTNGx44d07hx47Rz506tWrVK06dP19ixY332XAAAAoO/clNtwLA0AAhAgwcP1pEjRzR58mQVFBSoW7duFRZKCwn53/dTCQkJevfddzV+/Hh16dJFrVq10rhx4/TII4/46yEAAFDj6NwAwPn4qXTv6UJpPXv21KeffmpxqwAAASFIh5V5i84NAJhgoTQAQKAhN7nHPTcAAAAAggKVGwAw44sZZRg6AADwJXKTW3RuAMCU7b+btzEAAPAVcpM7DEsDAAAAEBSo3ACAGUr/AIBAQ25yi84NAJghgQAAAg25yS2/dW4S59oVFmr3edzjlzXyecxz7U9pYFnsxictCy1J2pd5hWWxL5zyiWWxJemJ7wdYFnvtTbMsiy1JuX16WBbbcae1r/dpWYOsC/6uw5q4p4qlm6wJjSAXIhkWDNZ22C0e127hdK4/ljaxLLYkhUQ3tiy2vTjUstiSZAu3Lva/ixtaF1ySrZ5F77+Svi8rtiy2JB36ybrXTKjNuufFsDA2XFG5AQAzhs37D49BupYAAMBPyE1u0bkBABOGcXbzNgYAAL5CbnKP2dIAAAAABAUqNwBghps2AQCBhtzkFp0bADDDuGYAQKAhN7nFsDQAAAAAQcGrzs1TTz0lm82mBx980EfNAYDAYjN8s6HmkJsABDtyk3vVHpb22Wef6YUXXlCXLl182R4ACCyMa65VyE0A6gRyk1vVqtycPHlSQ4cO1cKFC9W0aVNftwkAAI+RmwAA1ercjB07VgMGDFBqaqqv2wMAgaX8pk1vN1iO3ASgziA3ueXxsLRly5bpiy++0GeffVal44uLi1VcXOz8uaioyNNLAoD/UPqvFTzJTeQlALUeucktjyo3+fn5GjdunHJzcxUZGVmlc7KzsxUdHe3cEhISqtVQAAAq42luIi8BQPDyqHOzZcsWHT58WFdccYXCwsIUFhamDz74QHPmzFFYWJjsdnuFcyZOnKjCwkLnlp+f77PGA4DlDB9tsIynuYm8BKDWIze55dGwtH79+unrr7922Tdy5Ei1b99ejzzyiEJDQyucExERoYiICO9aCQD+Quk/4Hmam8hLAGo9cpNbHnVuGjdurE6dOrnsa9iwoS644IIK+wEAqAnkJgBAuWqvcwMAdYIvZpQJ0hlpAAB+Qm5yy+vOzcaNG33QDAAITL5YxTlYV4EOZOQmAMGM3ORetda5AQAAAIDKHDt2TEOHDlVUVJSaNGmiUaNG6eTJk6bH33///brssstUv359XXjhhXrggQdUWFjo8bXp3ACAGWakAQAEmgDPTUOHDtW3336rdevW6Z133tE//vEP3XPPPW6P/+GHH/TDDz9o5syZ+uabb7R48WKtXbtWo0aN8vja3HMDAAAAwCe2bdumtWvX6rPPPlNycrIk6bnnntONN96omTNnqmXLlhXO6dSpk958803nz+3atdOTTz6pO+64Q2VlZQoLq3qXhcoNAAAAAJ/YtGmTmjRp4uzYSFJqaqpCQkK0efPmKscpLCxUVFSURx0bicoNAJiyyQc3bfqkJQAAnOXL3FRUVOSy39u1wAoKChQbG+uyLywsTM2aNVNBQUGVYhw9elTTpk0zHcrmjt86N98NbqSQyEifx7248/c+j3mu6H7Wxd87vadlsSXpkd+ssCz2mn7WriXx+RftLIt944GxlsWWpLDd9S2L3aJFqWWxJel0t6aWxY7KOmNJXHuZj+My3WadYYSe3XzNZvGUREaZda+vBiEllsWWJFWy+Lev2EIsft4tjO+w+D3DsNfe96Qyh3WDjkIs/JsaAZwHEhISXH7OysrSlClTKhyXmZmpGTNmmMbatm2b1+0pKirSgAED1LFjx0rbcT5UbgAAAIDaxIdfvOXn5ysqKsq5213VZsKECRoxYoRpyLZt2yo+Pl6HDx922V9WVqZjx44pPj7e9PwTJ06of//+aty4sVasWKF69epV4YG4onMDAGZ8MaMMs6UBAHzJh7kpKirKpXPjTkxMjGJiYs57XM+ePXX8+HFt2bJFSUlJkqQNGzbI4XAoJSXF7XlFRUVKS0tTRESEVq5cqchqjvBiQgEAAAAAPtGhQwf1799fo0ePVl5enj7++GOlp6dryJAhzpnSDh48qPbt2ysvL0/S2Y7N9ddfr1OnTumll15SUVGRCgoKVFBQILvd7tH1qdwAgBkqNwCAQBPguSk3N1fp6enq16+fQkJCdPPNN2vOnDnO35eWlmrHjh06ffq0JOmLL75wzqR28cUXu8Tau3evEhMTq3xtOjcAYMJm+GBGGjo3AAAfCvTc1KxZMy1dutTt7xMTE2UY/2tA3759XX72BsPSAAAAAAQFKjcAYCbAS/8AgDqI3OQWnRsAMEMCAQAEGnKTWwxLAwAAABAUqNwAgIlAv2kTAFD3kJvco3MDAGZ8uAo0AAA+QW5yi2FpAAAAAIIClRsAMMNNmwCAQENucovODQCYYFwzACDQkJvcY1gaAAAAgKBA5QYAzFD6BwAEGnKTW3RuAMCMD0r/wZpAAAB+Qm5yi2FpAAAAAIIClRsAMEPpHwAQaMhNbtG5AQAzJBAAQKAhN7nFsDQAAAAAQYHKDQCYYC0BAECgITe5R+UGAAAAQFDwW+Vm0Y0vqGFj3/etXjnax+cxz7VlTTvLYl/8wCHLYktS/G3HLYu993gzy2JLUuYv/2ZZ7EVP/sqy2JJ0bMBpy2L/fdQiy2JLUs7xtpbF7hyZb0ncUyfs+kdXS0IjyNlKpZBQ38e123wfs6YuUGpY8IScwzj9k2WxQ+o5LIstSSGl1j3vYTZr224Lse4r+7hQaz9ahoVY99w0rFdsWezSeiWWxYYrhqUBgBlu2gQABBpyk1t0bgDABOOaAQCBhtzkHvfcAAAAAAgKVG4A4HyC9NstAEAtRm6qFJ0bADDDuGYAQKAhN7nFsDQAAAAAQcHjzs3Bgwd1xx136IILLlD9+vXVuXNnff7551a0DQD8rvymTW83WIvcBKAuITe559GwtP/85z/q3bu3rr32Wq1Zs0YxMTHatWuXmjZtalX7AMC/KP0HPHITgDqH3OSWR52bGTNmKCEhQS+//LJzX5s2bXzeKAAAqorcBAAo59GwtJUrVyo5OVm33nqrYmNj1b17dy1cuNCqtgGA31H6D3zkJgB1DbnJPY86N3v27NH8+fN1ySWX6N1339WYMWP0wAMPaMmSJW7PKS4uVlFRkcsGALWG4aMNlvE0N5GXANR65Ca3PBqW5nA4lJycrOnTp0uSunfvrm+++UY5OTkaPnx4pedkZ2dr6tSp3rcUAIBKeJqbyEsAELw8qty0aNFCHTt2dNnXoUMHHThwwO05EydOVGFhoXPLz8+vXksBwB/8+O3YvHnzlJiYqMjISKWkpCgvL69K5y1btkw2m02DBg2q3oVrGU9zE3kJQK1H5cYtjyo3vXv31o4dO1z27dy5UxdddJHbcyIiIhQREVG91gGAn/liXHJ1zl++fLkyMjKUk5OjlJQUzZ49W2lpadqxY4diY2Pdnrdv3z499NBDuvrqq71oce3iaW4iLwGo7fyVm2oDjyo348eP16effqrp06dr9+7dWrp0qRYsWKCxY8da1T4AqJNmzZql0aNHa+TIkerYsaNycnLUoEEDLVq0yO05drtdQ4cO1dSpU9W2bdsabK1/kZsAAOU86txceeWVWrFihV5//XV16tRJ06ZN0+zZszV06FCr2gcA/uWH0n9JSYm2bNmi1NRU576QkBClpqZq06ZNbs97/PHHFRsbq1GjRnl2wVqO3ASgzgnwYWnHjh3T0KFDFRUVpSZNmmjUqFE6efJklc41DEM33HCDbDab3n77bY+v7dGwNEm66aabdNNNN3l8IQColXyRAP57/s9n5XI3POro0aOy2+2Ki4tz2R8XF6ft27dXeomPPvpIL730krZu3eplY2snchOAOsWHuckKQ4cO1Y8//qh169aptLRUI0eO1D333KOlS5ee99zZs2fLZrNV+9oeVW4AANWXkJCg6Oho55adne2TuCdOnNCdd96phQsXqnnz5j6JCQBAdWzbtk1r167Viy++qJSUFPXp00fPPfecli1bph9++MH03K1bt+qZZ54xHYJ9Ph5XbgCgLvHlTZv5+fmKiopy7nd3U3vz5s0VGhqqQ4cOuew/dOiQ4uPjKxz/3Xffad++fRo4cKBzn8PhkCSFhYVpx44dateunXcPAgAQMAJ5QoFNmzapSZMmSk5Odu5LTU1VSEiINm/erN/85jeVnnf69Gn97ne/07x58yrNdVVF5wYAzPiw9B8VFeXSuXEnPDxcSUlJWr9+vXM6Z4fDofXr1ys9Pb3C8e3bt9fXX3/tsu+xxx7TiRMn9OyzzyohIcHLBwAACCh+GDJdVQUFBRVm9QwLC1OzZs1UUFDg9rzx48erV69e+vWvf13ta0t0bgAgIGVkZGj48OFKTk5Wjx49NHv2bJ06dUojR46UJA0bNkytWrVSdna2IiMj1alTJ5fzmzRpIkkV9gMAcK6ffwGWlZWlKVOmVDguMzNTM2bMMI21bdu2arVh5cqV2rBhg7788stqnX8uOjcAYMJfpf/BgwfryJEjmjx5sgoKCtStWzetXbvWOcnAgQMHFBLCbZMAUBf5Y8j0hAkTNGLECNOYbdu2VXx8vA4fPuyyv6ysTMeOHXM73GzDhg367rvvnF/Mlbv55pt19dVXa+PGjabXPZffOjdjF45RaESkz+M+ee9in8c8197BLSyL/a/fu1+Yzxee+T/rpkUt62ztgnjPrxtkWezC3mWWxZakD3vPsyz2yP3Wzg716ab2lsV+bMBblsT9qaxM0ne+C+jHGWnS09MrHYYm6bxv9IsXL67eReswm90mm736M/S4ZfFCeZa0uYbYwutZFttRZu3zEmq3LrZD1rbdFmLdi7JRiO8/26ESfhgyHRMTo5iYmPMe17NnTx0/flxbtmxRUlKSpLOdF4fDoZSUlErPyczM1N133+2yr3PnzvrTn/7kcj9pVVC5AQAAAOATHTp0UP/+/TV69Gjl5OSotLRU6enpGjJkiFq2bClJOnjwoPr166dXXnlFPXr0UHx8fKVVnQsvvFBt2rTx6PqMaQAAMwG+UBoAoA4K8NyUm5ur9u3bq1+/frrxxhvVp08fLViwwPn70tJS7dixQ6dPn/b5tancAIAJ2383b2MAAOArgZ6bmjVrZrpgZ2JiogzDvHd1vt+7Q+UGAAAAQFCgcgMAZvw4oQAAAJUiN7lF5wYATATyKtAAgLqJ3OQew9IAAAAABAUqNwBghtI/ACDQkJvconMDAOcTpAkAAFCLkZsqxbA0AAAAAEGByg0AmOCmTQBAoCE3uUfnBgDMMK4ZABBoyE1uMSwNAAAAQFCgcgMAJij9AwACDbnJPTo3AGCG0j8AINCQm9xiWBoAAACAoEDlBgBMUPoHAAQacpN7dG4AwAylfwBAoCE3ucWwNAAAAABBgcoNAJjh2zEAQKAhN7lF5wYATDCuGQAQaMhN7jEsDQAAAEBQoHIDAGYo/QMAAg25yS2/dW6a7ixTWL0yn8f967+v8HnMc303ooVlsRvst1kWW5L2DrbuVdzh6QLLYkvStt9fYFnsuFb/sSy2JB1zWPfPbNuSDpbFlqT43xyyLPaIqMOWxC2yOZTuw3g2w5DN8O7fjrfno2bYDMnm8H1cw157B0mccdTzdxOqzSirvc+7w7D284At1Lr3JLthwT+ic/xUat1rMjr8J8tih/h4DBi5yb3a+y8fAAAAAM7BsDQAMEPpHwAQaMhNbtG5AQATzEgDAAg05Cb3GJYGAAAAIChQuQEAM5T+AQCBhtzkFp0bADBB6R8AEGjITe55NCzNbrdr0qRJatOmjerXr6927dpp2rRpMoJ0KjkAQOAjNwEAynlUuZkxY4bmz5+vJUuW6PLLL9fnn3+ukSNHKjo6Wg888IBVbQQA/6H0H/DITQDqHHKTWx51bj755BP9+te/1oABAyRJiYmJev3115WXl2dJ4wDA3yj9Bz5yE4C6htzknkfD0nr16qX169dr586dkqSvvvpKH330kW644QZLGgcAwPmQmwAA5Tyq3GRmZqqoqEjt27dXaGio7Ha7nnzySQ0dOtTtOcXFxSouLnb+XFRUVP3WAkBNo/Qf8DzNTeQlALUeucktjyo3f/7zn5Wbm6ulS5fqiy++0JIlSzRz5kwtWbLE7TnZ2dmKjo52bgkJCV43GgBqUnn5v7obrOVpbiIvAQgG5KbKedS5efjhh5WZmakhQ4aoc+fOuvPOOzV+/HhlZ2e7PWfixIkqLCx0bvn5+V43GgCAcp7mJvISAAQvjzo3p0+fVkiI6ymhoaFyOBxuz4mIiFBUVJTLBgC1hmH4ZoNlPM1N5CUAtV6A56Zjx45p6NChioqKUpMmTTRq1CidPHnyvOdt2rRJ1113nRo2bKioqCj94he/0E8//eTRtT2652bgwIF68skndeGFF+ryyy/Xl19+qVmzZumuu+7y6KIAUFswI03gIzcBqGsCPTcNHTpUP/74o9atW6fS0lKNHDlS99xzj5YuXer2nE2bNql///6aOHGinnvuOYWFhemrr76q8OXV+XjUuXnuuec0adIk3XfffTp8+LBatmype++9V5MnT/boogAA+Aq5CQACx7Zt27R27Vp99tlnSk5OlnT2ffrGG2/UzJkz1bJly0rPGz9+vB544AFlZmY691122WUeX9+jrlDjxo01e/Zs7d+/Xz/99JO+++47PfHEEwoPD/f4wgBQKxg+2mAZchOAOieAc9OmTZvUpEkTZ8dGklJTUxUSEqLNmzdXes7hw4e1efNmxcbGqlevXoqLi9M111yjjz76yOPre1bnAYA6xubwzQYAgK/4MjcVFRW5bOdOlV8dBQUFio2NddkXFhamZs2aqaCgoNJz9uzZI0maMmWKRo8erbVr1+qKK65Qv379tGvXLo+uT+cGAAAAqKMSEhJcpsd3N9NkZmambDab6bZ9+/ZqtaF8Aph7771XI0eOVPfu3fWnP/1Jl112mRYtWuRRLI/uuQGAOoeF0gAAgcaHuSk/P99l1siIiIhKD58wYYJGjBhhGrJt27aKj4/X4cOHXfaXlZXp2LFjio+Pr/S8Fi1aSJI6duzosr9Dhw46cOCA6TV/js4NAJgI9BlpAAB1jy9zU1WnxI+JiVFMTMx5j+vZs6eOHz+uLVu2KCkpSZK0YcMGORwOpaSkVHpOYmKiWrZsqR07drjs37lzp2644YbzXvNcDEsDAAAA4BMdOnRQ//79NXr0aOXl5enjjz9Wenq6hgwZ4pwp7eDBg2rfvr3y8vIkSTabTQ8//LDmzJmjN954Q7t379akSZO0fft2jRo1yqPr+61yU9owREY93/etZrVe5/OY5xq4peP5D6qmJhmeld08darUupmD8p9uZFlsSXqh82LLYk/O8uwfjadu/6118c9cZm1JIG6cdd9/dL3hPkvi2ovPSHrUdwF9sdAZi3jWCkaIZIT6Pq4t1NoZJQwmrKicw2ZpeCteK+UchrVtt1KorfZ+bx4eYrcsts3XsQM8N+Xm5io9PV39+vVTSEiIbr75Zs2ZM8f5+9LSUu3YsUOnT5927nvwwQd15swZjR8/XseOHVPXrl21bt06tWvXzqNrMywNAEwwLA0AEGgCPTc1a9bMdMHOxMREGZV0rjIzM13WuamO2tu9BgAAAIBzULkBADPMlgYACDTkJrfo3ACAiUAv/QMA6h5yk3sMSwMAAAAQFKjcAICZAJ+RBgBQB5Gb3KJzAwAmKP0DAAINuck9hqUBAAAACApUbgDADDPSAAACDbnJLTo3AGCC0j8AINCQm9xjWBoAAACAoEDlBgDMOIyzm7cxAADwFXKTW3RuAMAM45oBAIGG3OQWw9IAAAAABAUqNwBgwiYf3LTpk5YAAHAWuck9OjcAYIZVoAEAgYbc5BbD0gAAAAAEBSo3AGCCtQQAAIGG3OQenRsAMMOMNACAQENucothaQAAAACCAp0bADBhMwyfbNUxb948JSYmKjIyUikpKcrLy3N77MKFC3X11VeradOmatq0qVJTU02PBwDUXv7MTYGOzg0AmHH4aPPQ8uXLlZGRoaysLH3xxRfq2rWr0tLSdPjw4UqP37hxo26//Xa9//772rRpkxISEnT99dfr4MGDnl8cABDY/JSbaoMav+fG+G8v0V56xpL4RSes/UuVWdRuSSo9VWJZbEkqK7Wuh24/Xc+y2JJ06oTdstj2Euv+ppJkP11sWWzHGWuf9zK7dW23F1vzvJf/PY1a/o3UrFmzNHr0aI0cOVKSlJOTo1WrVmnRokXKzMyscHxubq7Lzy+++KLefPNNrV+/XsOGDauRNtdW5a8Vh0WvScdpa99jjJ+sy3vFJ0stiy1JZQ7r8p7jJ2ufd8cZ6z5ClZ2y7r1XsvY1afnnMAufm9IQ616P5Z/xantuqg1qvHNz4sQJSdLWlU9YEj/xTUvCnmOydaFXWRe6trvF0uiPWRpdf7Y2vJUOWBl8l5XBz77XREdHex3HF6V7T88vKSnRli1bNHHiROe+kJAQpaamatOmTVWKcfr0aZWWlqpZs2YeXbsuKs9Le2c97ueWBJ5Z/m6AN+73dwOqb6+/G+CFppZf4VnLIn9mWeT/qc25qbao8c5Ny5YtlZ+fr8aNG8tmM18btaioSAkJCcrPz1dUVFQNtdA3aLt/0Hb/CKS2G4ahEydOqGXLlj4KKJ/NSFNUVOSyOyIiQhERERUOP3r0qOx2u+Li4lz2x8XFafv27VW65COPPKKWLVsqNTW1em2uQzzJS1Jgvd49Rdv9g7b7RyC1PZBzU7Cp8c5NSEiIWrdu7dE5UVFRfn9RVhdt9w/a7h+B0nZffCtmhYSEBJefs7KyNGXKFJ9f56mnntKyZcu0ceNGRUZG+jx+sKlOXpIC5/VeHbTdP2i7fwRK2wM1NwUb1rkBADOGcXbzNoZU4dvDyqo2ktS8eXOFhobq0KFDLvsPHTqk+Ph400vNnDlTTz31lN577z116dLFu3YDAAKTD3NTsGG2NAAwUb4KtLeb9L9vD8s3d52b8PBwJSUlaf369c59DodD69evV8+ePd229emnn9a0adO0du1aJScn+/R5AAAEDl/mpmAT0JWbiIgIZWVluf0AEMhou3/Qdv+ozW0PVBkZGRo+fLiSk5PVo0cPzZ49W6dOnXLOnjZs2DC1atVK2dnZkqQZM2Zo8uTJWrp0qRITE1VQUCBJatSokRo1auS3xxGMavPrnbb7B233j9rcdlSfzWBOOgCooKioSNHR0bqm52MKC/PuvpWysjP6YNMTKiws9Gjc99y5c/XHP/5RBQUF6tatm+bMmaOUlBRJUt++fZWYmKjFixdLkhITE7V///4KMay6rwcAUPMCITcFuoCu3ACAv9kcZzdvY1RHenq60tPTK/3dxo0bXX7et29f9S4CAKh1/JmbAh333AAAAAAIClRuAMAMM9IAAAINucktOjcAYIaF0gAAgYbc5BbD0gAAAAAEBSo3AGDCZhiyeVm69/Z8AADORW5yj8oNAJgpH9fs7QYAgK8EeG46duyYhg4dqqioKDVp0kSjRo3SyZMnTc8pKCjQnXfeqfj4eDVs2FBXXHGF3nzzTY+vTecGAAAAgM8MHTpU3377rdatW6d33nlH//jHP3TPPfeYnjNs2DDt2LFDK1eu1Ndff63f/va3uu222/Tll196dG06NwBgxpDk8HKjcAMA8KUAzk3btm3T2rVr9eKLLyolJUV9+vTRc889p2XLlumHH35we94nn3yi+++/Xz169FDbtm312GOPqUmTJtqyZYtH16dzAwAmysc1e7sBAOArvsxNRUVFLltxcbFXbdu0aZOaNGmi5ORk577U1FSFhIRo8+bNbs/r1auXli9frmPHjsnhcGjZsmU6c+aM+vbt69H16dwAAAAAdVRCQoKio6OdW3Z2tlfxCgoKFBsb67IvLCxMzZo1U0FBgdvz/vznP6u0tFQXXHCBIiIidO+992rFihW6+OKLPbo+s6UBgBlDPlgozSctAQDgLB/mpvz8fEVFRTl3R0REVHp4ZmamZsyYYRpy27Zt1W7OpEmTdPz4cb333ntq3ry53n77bd1222368MMP1blz5yrHoXMDAGZYBRoAEGh8mJuioqJcOjfuTJgwQSNGjDA9pm3btoqPj9fhw4dd9peVlenYsWOKj4+v9LzvvvtOc+fO1TfffKPLL79cktS1a1d9+OGHmjdvnnJycqrwgM6icwMAAADAVExMjGJiYs57XM+ePXX8+HFt2bJFSUlJkqQNGzbI4XAoJSWl0nNOnz4tSQoJcb1jJjQ0VA6Hw6N2cs8NAJjxdjaa8g0AAF8J4NzUoUMH9e/fX6NHj1ZeXp4+/vhjpaena8iQIWrZsqUk6eDBg2rfvr3y8vIkSe3bt9fFF1+se++9V3l5efruu+/0zDPPaN26dRo0aJBH16dzAwAmmC0NABBoAj035ebmqn379urXr59uvPFG9enTRwsWLHD+vrS0VDt27HBWbOrVq6fVq1crJiZGAwcOVJcuXfTKK69oyZIluvHGGz26NsPSAAAAAPhMs2bNtHTpUre/T0xMlPGzztUll1yiN9980+tr07kBADNMKAAACDTkJrfo3ACAGRIIACDQkJvc4p4bAAAAAEGByg0AmOHbMQBAoCE3uUXnBgDMOCTZfBADAABfITe5xbA0AAAAAEGByg0AmPDFWgCscwMA8CVyk3t0bgDADOOaAQCBhtzkFsPSAAAAAAQFKjcAYMZhSDYvv91yBOe3YwAAPyE3uUXnBgDMUPoHAAQacpNbDEsDAAAAEBSo3ACAKR98O6bg/HYMAOAv5CZ36NwAgBlK/wCAQENucothaQAAAACCApUbADDjMOR16T5IZ6QBAPgJucktOjcAYMZwnN28jQEAgK+Qm9xiWBoAAACAoEDlBgDMcNMmACDQkJvconMDAGYY1wwACDTkJrcYlgYAAAAgKFC5AQAzlP4BAIGG3OQWnRsAMGPIBwnEJy0BAOAscpNbDEsDAAAAEBSo3ACAGUr/AIBAQ25yi84NAJhxOCR5udCZIzgXSgMA+Am5yS2GpQEAAAAIClRuAMAMpX8AQKAhN7lF5wYAzJBAAACBhtzkFsPSAAAAAAQFKjcAYMZhyOvFABzB+e0YAMBPyE1u0bkBABOG4ZBheDejjLfnAwBwLnKTewxLAwAAABAUqNwAgBnD8L50H6Q3bQIA/ITc5BaVGwAwUz4jjbcbAAC+EuC56cknn1SvXr3UoEEDNWnSpIoPydDkyZPVokUL1a9fX6mpqdq1a5fH16ZzAwAAAMBnSkpKdOutt2rMmDFVPufpp5/WnDlzlJOTo82bN6thw4ZKS0vTmTNnPLo2w9IAwIzDIdm8vOkySG/aBAD4SYDnpqlTp0qSFi9eXLWmGIZmz56txx57TL/+9a8lSa+88ori4uL09ttva8iQIVW+NpUbADAT4KV/AEAd5MPcVFRU5LIVFxfX+MPZu3evCgoKlJqa6twXHR2tlJQUbdq0yaNYdG4AAACAOiohIUHR0dHOLTs7u8bbUFBQIEmKi4tz2R8XF+f8XVUxLA0ATBgOhwwvS//BupYAAMA/fJmb8vPzFRUV5dwfERFR6fGZmZmaMWOGacxt27apffv2XrXLW3RuAMCM4YNVoBmWBgDwJR/mpqioKJfOjTsTJkzQiBEjTI9p27ZttZoSHx8vSTp06JBatGjh3H/o0CF169bNo1h0bgAAAACYiomJUUxMjCWx27Rpo/j4eK1fv97ZmSkqKtLmzZs9mnFN4p4bADDnMHyzAQDgKwGemw4cOKCtW7fqwIEDstvt2rp1q7Zu3aqTJ086j2nfvr1WrFghSbLZbHrwwQf1xBNPaOXKlfr66681bNgwtWzZUoMGDfLo2lRuAMCMYUjydrpNOjcAAB8K8Nw0efJkLVmyxPlz9+7dJUnvv/+++vbtK0nasWOHCgsLncf8/ve/16lTp3TPPffo+PHj6tOnj9auXavIyEiPrm0zDLIuAPxcUVGRoqOjdV34rQqz1fMqVplRqg0lf1FhYWGVxjUDAFAZctP5UbkBABOGw5Bh8+47IL5DAgD4ErnJPTo3AGDGcMj70j9TQQMAfIjc5BYTCgAAAAAIClRuAMAEpX8AQKAhN7lH5wYAzFD6BwAEGnKTW3RuAMBEmUq9XgS6TKW+aQwAACI3maFzAwCVCA8PV3x8vD4qWO2TePHx8QoPD/dJLABA3URuOj/WuQEAN86cOaOSkhKfxAoPD/d4ITIAAH6O3GSOzg0AAACAoMBU0AAAAACCAp0bAAAAAEGBzg0AAACAoEDnBgAAAEBQoHMDAAAAICjQuQEAAAAQFOjcAAAAAAgK/w+yYdHJBL4+PQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(inp, result):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot the same plot on both subplots\n",
    "    cax1 = axs[0].matshow(inp.squeeze(0))\n",
    "    fig.colorbar(cax1, ax=axs[0])\n",
    "    cax2 = axs[1].matshow(result.detach().numpy().squeeze(0))\n",
    "    fig.colorbar(cax2, ax=axs[1])\n",
    "\n",
    "    axs[0].set_title(\"Input tensor\")\n",
    "    axs[1].set_title(\"After applying self attention\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot(inp, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46023db3-3382-4bef-ace5-4727f908a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head Self Attention\n",
    "class MultiHeadAttention_v1(nn.Module):\n",
    "    def __init__(self, heads, d_in, d_out, blocksize, dropout=0.0, mask=False, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                SingleHeadAttention(d_in, d_out, blocksize, dropout, mask, qkv_bias)\n",
    "                for _ in range(heads)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(d_out * heads, d_out * heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context_vec = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.linear(context_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f7c17e-091a-4af4-9df9-843f639ccf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for embedding_dim = 512 , head = 8\n",
    "# d_in = 512/8 = 64\n",
    "\n",
    "mha = MultiHeadAttention_v1(2, 12, 6, 10)\n",
    "result = mha(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f14f11-06df-4d4b-9804-e942d0190f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(inp,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2578c5a7-38ab-4d62-8480-48c835665ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(SingleHeadAttention):\n",
    "    def __init__(self, num_heads, d_model, blocksize, dropout=0.0, mask=False, qkv_bias=False):\n",
    "        super().__init__(d_model, d_model, blocksize, dropout, mask, qkv_bias)\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, num_token, embedding_dim = x.shape\n",
    "\n",
    "        queries = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        queries = queries.view(batch, num_token, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = keys.view(batch, num_token, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(batch, num_token, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attention_scores = torch.matmul(queries, keys.transpose(-2, -1))\n",
    "        if hasattr(self, \"mask\"):\n",
    "            attention_scores.masked_fill_(self.mask.bool()[:num_token, :num_token], -float(\"inf\"))\n",
    "\n",
    "        attention_weights = F.softmax(attention_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vector = torch.matmul(attention_weights, values)\n",
    "        context_vector = (\n",
    "            context_vector.transpose(1, 2).contiguous().view(batch, num_token, embedding_dim)\n",
    "        )\n",
    "        return self.linear(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1becd4a7-cd47-4ee1-9d1a-125a07eeacfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttention(2, 12, 10)\n",
    "result = mha(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16c10bb-2f15-4716-9502-bae6d2b14a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(inp,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77343001-dba5-41b6-b76f-270ba079cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionPyTorchSDP(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, block_size, mask=False, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.block_size = block_size\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.qkv = nn.Linear(d_model, 3 * d_model, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(block_size, block_size), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.reshape(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv.unbind(0)\n",
    "\n",
    "        use_dropout = 0.0 if not self.training else self.dropout\n",
    "        context_vec = nn.functional.scaled_dot_product_attention(\n",
    "            queries, keys, values, attn_mask=None, dropout_p=use_dropout, is_causal=True\n",
    "        )\n",
    "\n",
    "        # Combine heads, where self.d_model = self.num_heads * self.head_dim\n",
    "        context_vec = (\n",
    "            context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, embed_dim)\n",
    "        )\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb98e6a-f9c2-4831-8a74-1ca411d96226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhap = MultiHeadAttentionPyTorchSDP(2, 12, 10)\n",
    "result = mhap(inp)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd41a72-5f3a-41a3-a7d9-81efaacbc122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9823268-7006-447c-ac5e-02cb88c4b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecd36e-83ae-4f26-ad58-c675e32cd43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89c1a3-16c1-442c-ba31-a04b35a9a888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad47e99-5b26-4817-8fd3-daaac995cce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1031dd8-090c-46a6-9964-f4d5c952316a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0cb8e-a281-4f66-9116-6fc684296aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64ba69-1b53-4dea-9d48-5d6a5e097cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b1090-ff72-4e5b-a310-555f4462c3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163af4f-f064-45eb-8ef3-fefa4debc5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792440c-ec74-49bf-b956-cef271571fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ec599-2f94-434e-b123-e3327b1200ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f9555-a9ab-41dc-a7c6-c77c9fd71f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868149a-d8c2-4c03-b92a-ab83ca7340b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6fea2-b848-4160-a16a-32c41fe4b9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66684ac3-8b84-4c80-a560-3ee848dd4100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133ac5e-20e5-4154-87f5-4e97718dd448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9aceba-8a3c-4501-9e63-d6185a1d86e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5cb48-9af0-4ca5-9184-7664edd6ffd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4e9506-9211-49d9-aab0-34d68c64e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(inp,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac37548-ab3b-48bf-ac4b-87a551716e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmark Test - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56dcffa6-250a-40f2-8706-c55f371396e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "batch = 64\n",
    "max_len = 1024\n",
    "embedding_dim = 768\n",
    "num_heads = 16\n",
    "\n",
    "x = torch.rand(batch, max_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d757f2a-ecdf-4678-a0e1-991f4bb0805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534 ms ± 29.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit SingleHeadAttention(embedding_dim,embedding_dim,x.shape[1],mask=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9163ae78-6f13-49be-8711-7c2401b2acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.62 s ± 119 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttention_v1(num_heads,embedding_dim,embedding_dim//num_heads,max_len)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061fe7f-f40c-4b65-a452-4027354464f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit MultiHeadAttention(num_heads,embedding_dim,max_len)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7114c39-42c9-4f59-86c1-e21a629d09d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 s ± 65.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttentionPyTorchSDP(num_heads,embedding_dim,max_len)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f184e7-aa5a-4dd9-81ea-4d6100607792",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU Benchmark Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6bc7c93-6008-4efb-a77e-aac1803172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0f77f0b-9e74-4a9d-9740-8bc9d1f3ec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47 s ± 69.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit SingleHeadAttention(embedding_dim,embedding_dim,x.shape[1],mask=True).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "483ed669-8caa-42c5-9ad4-d8d0bed714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 48.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.71 s ± 1.09 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x = x.to(device)\n",
    "%timeit MultiHeadAttention_v1(num_heads,embedding_dim,embedding_dim//num_heads,max_len).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e94d5d-e242-4e46-9f32-a931f57212a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 11.72 GiB of which 2.06 GiB is free. Including non-PyTorch memory, this process has 9.39 GiB memory in use. Of the allocated memory 9.15 GiB is allocated by PyTorch, and 15.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMultiHeadAttention(num_heads,embedding_dim,max_len).to(device)(x)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/IPython/core/magics/execution.py:1185\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1184\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1185\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     attention_scores\u001b[38;5;241m.\u001b[39mmasked_fill_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mbool()[:num_token, :num_token], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 27\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_weights)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Combine heads, where self.d_out = self.num_heads * self.head_dim\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/torch/nn/functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 11.72 GiB of which 2.06 GiB is free. Including non-PyTorch memory, this process has 9.39 GiB memory in use. Of the allocated memory 9.15 GiB is allocated by PyTorch, and 15.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttention(num_heads,embedding_dim,max_len).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "276428f0-da33-4992-b295-ac91b750e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 ms ± 11.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit MultiHeadAttentionPyTorchSDP(num_heads,embedding_dim,max_len).to(device)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9346f6d3-05a6-43d8-be4b-42854cca0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 ms ± 17.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit nn.Linear(embedding_dim,embedding_dim).to(device)(nn.MultiheadAttention(embedding_dim, num_heads).to(device)(x,x,x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51bb8600-1a85-4297-bd48-c09a40c8b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e854ae0c-0a6c-40a9-bd5e-884721d03123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up with batch_size=1: 100%|██████████████| 1/1 [00:00<00:00, 464.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module MultiHeadAttentionPyTorchSDP is treated as a zero-op.\n",
      "Warning! No positional inputs found for a module, assuming batch size is 1.\n",
      "MultiHeadAttentionPyTorchSDP(\n",
      "  2.36 M, 100.000% Params, 1.81 GMac, 100.000% MACs, \n",
      "  (qkv): Linear(1.77 M, 74.976% Params, 1.81 GMac, 100.000% MACs, in_features=768, out_features=2304, bias=False)\n",
      "  (proj): Linear(590.59 k, 25.024% Params, 0.0 Mac, 0.000% MACs, in_features=768, out_features=768, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up with batch_size=1: 100%|██████████████| 1/1 [00:00<00:00, 454.17it/s]\n",
      "STAGE:2024-03-15 23:24:22 102445:102445 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-15 23:24:22 102445:102445 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-15 23:24:22 102445:102445 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Measuring inference for batch_size=1: 100%|████| 10/10 [00:00<00:00, 492.12it/s]\n",
      "Unable to measure energy consumption. Device must be a NVIDIA Jetson.\n",
      "Warming up with batch_size=32: 100%|██████████████| 1/1 [00:00<00:00,  8.42it/s]\n",
      "STAGE:2024-03-15 23:24:22 102445:102445 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-15 23:24:22 102445:102445 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-15 23:24:22 102445:102445 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n",
      "Measuring inference for batch_size=32: 100%|████| 10/10 [00:01<00:00,  7.85it/s]\n",
      "Unable to measure energy consumption. Device must be a NVIDIA Jetson.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_benchmark\n",
    "\n",
    "model = MultiHeadAttentionPyTorchSDP(num_heads, embedding_dim, max_len).to(\"cuda\")\n",
    "\n",
    "# Create a benchmark object\n",
    "results = pytorch_benchmark.benchmark(\n",
    "    model, sample=x.to(\"cuda\"), num_runs=10, batch_size=32, print_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf7017b1-26e2-4aab-9269-596887e92525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "flops: 1811939328\n",
      "machine_info:\n",
      "  cpu:\n",
      "    architecture: x86_64\n",
      "    cores:\n",
      "      physical: 24\n",
      "      total: 32\n",
      "    frequency: 4.79 GHz\n",
      "    model: 13th Gen Intel(R) Core(TM) i9-13900F\n",
      "  gpus:\n",
      "  - memory: 12282.0 MB\n",
      "    name: NVIDIA GeForce RTX 4070 Ti\n",
      "  memory:\n",
      "    available: 25.11 GB\n",
      "    total: 31.06 GB\n",
      "    used: 5.38 GB\n",
      "  system:\n",
      "    node: pranav-pc-Legion-T5-26IRB8\n",
      "    release: 6.5.0-25-generic\n",
      "    system: Linux\n",
      "memory:\n",
      "  batch_size_1:\n",
      "    max_inference: 49.38 MB\n",
      "    max_inference_bytes: 51779584\n",
      "    post_inference: 34.38 MB\n",
      "    post_inference_bytes: 36050944\n",
      "    pre_inference: 34.38 MB\n",
      "    pre_inference_bytes: 36050944\n",
      "  batch_size_32:\n",
      "    max_inference: 994.38 MB\n",
      "    max_inference_bytes: 1042683904\n",
      "    post_inference: 34.38 MB\n",
      "    post_inference_bytes: 36050944\n",
      "    pre_inference: 34.38 MB\n",
      "    pre_inference_bytes: 36050944\n",
      "params: 2360064\n",
      "timing:\n",
      "  batch_size_1:\n",
      "    cpu_to_gpu:\n",
      "      human_readable:\n",
      "        batch_latency: 623.298 us +/- 106.085 us [542.641 us, 880.718 us]\n",
      "        batches_per_second: 1.64 K +/- 229.01 [1.14 K, 1.84 K]\n",
      "      metrics:\n",
      "        batches_per_second_max: 1842.8400702987697\n",
      "        batches_per_second_mean: 1643.079403483561\n",
      "        batches_per_second_min: 1135.4369247428262\n",
      "        batches_per_second_std: 229.00873133118674\n",
      "        seconds_per_batch_max: 0.0008807182312011719\n",
      "        seconds_per_batch_mean: 0.0006232976913452149\n",
      "        seconds_per_batch_min: 0.0005426406860351562\n",
      "        seconds_per_batch_std: 0.00010608523290019507\n",
      "    gpu_to_cpu:\n",
      "      human_readable:\n",
      "        batch_latency: 691.938 us +/- 41.661 us [640.154 us, 767.708 us]\n",
      "        batches_per_second: 1.45 K +/- 83.89 [1.30 K, 1.56 K]\n",
      "      metrics:\n",
      "        batches_per_second_max: 1562.1243947858472\n",
      "        batches_per_second_mean: 1450.2592898005842\n",
      "        batches_per_second_min: 1302.5788819875777\n",
      "        batches_per_second_std: 83.88966641463904\n",
      "        seconds_per_batch_max: 0.0007677078247070312\n",
      "        seconds_per_batch_mean: 0.0006919384002685546\n",
      "        seconds_per_batch_min: 0.0006401538848876953\n",
      "        seconds_per_batch_std: 4.166091622122122e-05\n",
      "    on_device_inference:\n",
      "      human_readable:\n",
      "        batch_latency: -679747.206 us +/- 94.170 ms [-834240.019 us, -574400.008 us]\n",
      "        batches_per_second: -1.50 +/- 0.19 [-1.74, -1.20]\n",
      "      metrics:\n",
      "        batches_per_second_max: -1.1986957911865521\n",
      "        batches_per_second_mean: -1.4979818880241247\n",
      "        batches_per_second_min: -1.7409470517959582\n",
      "        batches_per_second_std: 0.1945018023958574\n",
      "        seconds_per_batch_max: -0.574400007724762\n",
      "        seconds_per_batch_mean: -0.6797472059726715\n",
      "        seconds_per_batch_min: -0.8342400193214417\n",
      "        seconds_per_batch_std: 0.09416983425259735\n",
      "    total:\n",
      "      human_readable:\n",
      "        batch_latency: 2.006 ms +/- 177.374 us [1.791 ms, 2.370 ms]\n",
      "        batches_per_second: 502.32 +/- 43.12 [421.92, 558.42]\n",
      "      metrics:\n",
      "        batches_per_second_max: 558.4215151111703\n",
      "        batches_per_second_mean: 502.318754436454\n",
      "        batches_per_second_min: 421.91972638567546\n",
      "        batches_per_second_std: 43.12089009946145\n",
      "        seconds_per_batch_max: 0.002370119094848633\n",
      "        seconds_per_batch_mean: 0.002005934715270996\n",
      "        seconds_per_batch_min: 0.001790761947631836\n",
      "        seconds_per_batch_std: 0.00017737394513938796\n",
      "  batch_size_32:\n",
      "    cpu_to_gpu:\n",
      "      human_readable:\n",
      "        batch_latency: 26.433 ms +/- 904.881 us [25.772 ms, 28.963 ms]\n",
      "        batches_per_second: 37.87 +/- 1.21 [34.53, 38.80]\n",
      "      metrics:\n",
      "        batches_per_second_max: 38.801298833455135\n",
      "        batches_per_second_mean: 37.87343554447156\n",
      "        batches_per_second_min: 34.52727242792934\n",
      "        batches_per_second_std: 1.2101772074973869\n",
      "        seconds_per_batch_max: 0.02896261215209961\n",
      "        seconds_per_batch_mean: 0.02643263339996338\n",
      "        seconds_per_batch_min: 0.0257723331451416\n",
      "        seconds_per_batch_std: 0.0009048814901991011\n",
      "    gpu_to_cpu:\n",
      "      human_readable:\n",
      "        batch_latency: 77.319 ms +/- 26.624 ms [67.314 ms, 157.151 ms]\n",
      "        batches_per_second: 13.79 +/- 2.48 [6.36, 14.86]\n",
      "      metrics:\n",
      "        batches_per_second_max: 14.8556653927753\n",
      "        batches_per_second_mean: 13.787064567459769\n",
      "        batches_per_second_min: 6.363307284199539\n",
      "        batches_per_second_std: 2.480769869415175\n",
      "        seconds_per_batch_max: 0.1571509838104248\n",
      "        seconds_per_batch_mean: 0.07731852531433106\n",
      "        seconds_per_batch_min: 0.06731438636779785\n",
      "        seconds_per_batch_std: 0.02662366488925396\n",
      "    on_device_inference:\n",
      "      human_readable:\n",
      "        batch_latency: -23011670.685 us +/- 1.200 s [-26606496.811 us, -22573375.702\n",
      "          us]\n",
      "        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]\n",
      "      metrics:\n",
      "        batches_per_second_max: -0.03758480521155396\n",
      "        batches_per_second_mean: -0.043560281593493295\n",
      "        batches_per_second_min: -0.04429997591878293\n",
      "        batches_per_second_std: 0.0019957737048530407\n",
      "        seconds_per_batch_max: -22.573375701904297\n",
      "        seconds_per_batch_mean: -23.011670684814455\n",
      "        seconds_per_batch_min: -26.606496810913086\n",
      "        seconds_per_batch_std: 1.2000128103333603\n",
      "    total:\n",
      "      human_readable:\n",
      "        batch_latency: 126.772 ms +/- 27.449 ms [116.013 ms, 208.924 ms]\n",
      "        batches_per_second: 8.13 +/- 1.12 [4.79, 8.62]\n",
      "      metrics:\n",
      "        batches_per_second_max: 8.6197376452189\n",
      "        batches_per_second_mean: 8.130978728490113\n",
      "        batches_per_second_min: 4.786433714866083\n",
      "        batches_per_second_std: 1.1226491655024387\n",
      "        seconds_per_batch_max: 0.2089238166809082\n",
      "        seconds_per_batch_mean: 0.12677175998687745\n",
      "        seconds_per_batch_min: 0.1160128116607666\n",
      "        seconds_per_batch_std: 0.02744905416686344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(yaml.dump(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7d397c2-dad3-431f-ba7e-283596711b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>cpu</th>\n",
       "      <th>memory</th>\n",
       "      <th>gpus</th>\n",
       "      <th>batch_size_1</th>\n",
       "      <th>batch_size_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine_info</th>\n",
       "      <td>{'system': 'Linux', 'node': 'pranav-pc-Legion-...</td>\n",
       "      <td>{'model': '13th Gen Intel(R) Core(TM) i9-13900...</td>\n",
       "      <td>{'total': '31.06 GB', 'used': '5.38 GB', 'avai...</td>\n",
       "      <td>[{'name': 'NVIDIA GeForce RTX 4070 Ti', 'memor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device</th>\n",
       "      <td>cuda</td>\n",
       "      <td>cuda</td>\n",
       "      <td>cuda</td>\n",
       "      <td>cuda</td>\n",
       "      <td>cuda</td>\n",
       "      <td>cuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>2360064</td>\n",
       "      <td>2360064</td>\n",
       "      <td>2360064</td>\n",
       "      <td>2360064</td>\n",
       "      <td>2360064</td>\n",
       "      <td>2360064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1811939328</td>\n",
       "      <td>1811939328</td>\n",
       "      <td>1811939328</td>\n",
       "      <td>1811939328</td>\n",
       "      <td>1811939328</td>\n",
       "      <td>1811939328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timing</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'on_device_inference': {'metrics': {'batches_...</td>\n",
       "      <td>{'on_device_inference': {'metrics': {'batches_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memory</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'pre_inference_bytes': 36050944, 'max_inferen...</td>\n",
       "      <td>{'pre_inference_bytes': 36050944, 'max_inferen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         system  \\\n",
       "machine_info  {'system': 'Linux', 'node': 'pranav-pc-Legion-...   \n",
       "device                                                     cuda   \n",
       "params                                                  2360064   \n",
       "flops                                                1811939328   \n",
       "timing                                                      NaN   \n",
       "memory                                                      NaN   \n",
       "\n",
       "                                                            cpu  \\\n",
       "machine_info  {'model': '13th Gen Intel(R) Core(TM) i9-13900...   \n",
       "device                                                     cuda   \n",
       "params                                                  2360064   \n",
       "flops                                                1811939328   \n",
       "timing                                                      NaN   \n",
       "memory                                                      NaN   \n",
       "\n",
       "                                                         memory  \\\n",
       "machine_info  {'total': '31.06 GB', 'used': '5.38 GB', 'avai...   \n",
       "device                                                     cuda   \n",
       "params                                                  2360064   \n",
       "flops                                                1811939328   \n",
       "timing                                                      NaN   \n",
       "memory                                                      NaN   \n",
       "\n",
       "                                                           gpus  \\\n",
       "machine_info  [{'name': 'NVIDIA GeForce RTX 4070 Ti', 'memor...   \n",
       "device                                                     cuda   \n",
       "params                                                  2360064   \n",
       "flops                                                1811939328   \n",
       "timing                                                      NaN   \n",
       "memory                                                      NaN   \n",
       "\n",
       "                                                   batch_size_1  \\\n",
       "machine_info                                                NaN   \n",
       "device                                                     cuda   \n",
       "params                                                  2360064   \n",
       "flops                                                1811939328   \n",
       "timing        {'on_device_inference': {'metrics': {'batches_...   \n",
       "memory        {'pre_inference_bytes': 36050944, 'max_inferen...   \n",
       "\n",
       "                                                  batch_size_32  \n",
       "machine_info                                                NaN  \n",
       "device                                                     cuda  \n",
       "params                                                  2360064  \n",
       "flops                                                1811939328  \n",
       "timing        {'on_device_inference': {'metrics': {'batches_...  \n",
       "memory        {'pre_inference_bytes': 36050944, 'max_inferen...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(results).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
