{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a553b64-e7cf-48dd-8c60-2ac3fe65e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import functools\n",
    "\n",
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca72f82-8bd1-4eac-9b72-2415f121d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyStoriesDataloader(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, data_path_train, data_path_val, tokenizer_path, batch_size, num_workers\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_path_train = data_path_train\n",
    "        self.data_path_val = data_path_val\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.tokenizer = self._load_tokenizer(tokenizer_path)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def _load_tokenizer(self, tokenizer_path):\n",
    "        from src.tokenize.tokenizer import Tokenizer\n",
    "\n",
    "        return Tokenizer(tokenizer_path)\n",
    "\n",
    "    def _collate_fn(self, batch: int, padding_id: int):\n",
    "        batch = pad_sequence(\n",
    "            (torch.LongTensor(_[\"idx\"]) for _ in batch),\n",
    "            batch_first=True,\n",
    "            padding_value=padding_id,\n",
    "        )  # TODO : ShortTensor suffice our need but nn.Embedding don't support it. Using LOngTensor is a unnecessary waste of GPU memory\n",
    "        x_batch = torch.stack(\n",
    "            [en[:-1] for en in batch]\n",
    "        )  # Extract x (remove last token)\n",
    "        y_batch = torch.stack(\n",
    "            [en[1:] for en in batch]\n",
    "        )  # Extract y (remove first token)\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def setup(self, stage):\n",
    "\n",
    "        self.train_data = load_from_disk(self.data_path_train)\n",
    "        self.val_data = load_from_disk(self.data_path_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=functools.partial(\n",
    "                self._collate_fn, padding_id=self.tokenizer.eos_id()\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=functools.partial(\n",
    "                self._collate_fn, padding_id=self.tokenizer.eos_id()\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b25a704-64fe-4f9e-89e7-95e7e10c5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"/home/pranav-pc/projects/OpenTransformer/multiformer\"\n",
    "data_path_train = BASE_URL + \"/data/interim/TinyStories_train_65>tk>512.hf\"\n",
    "data_path_val = BASE_URL + \"/data/interim/TinyStories_val_65>tk>512.hf\"\n",
    "tokenizer_path = BASE_URL + \"/tokenizer_checkpoints\"\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 26\n",
    "ds = TinyStoriesDataloader(\n",
    "    data_path_train, data_path_val, tokenizer_path, batch_size, num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233681cc-8e08-485f-bb57-f4944419e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_disk(BASE_URL + \"/data/interim/TinyStories_train_65>tk>512.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cb37790-c411-406b-be27-9a047b47e6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'displaying realized pocket garden leadingYes forcesoring ball hear patientatience StevenWatch collected finishlaimroom wings guard fell arrow bigger accomplished piece kick earthThere helpful ter aon orange decidedes datisreit thearle fasteral m surpriseedomioningiane talkedelas iniringet l couldn to Ichil ofam S A Although and strangeol vimadut guridig is M yveceieendodetermentation for L you bely performedte it on polarus \" wh Comeirck an riverayand that vest fightumateess as withpe k circleiaantub jlaue do woods mom :( un thiske - judge The not thinillineopiz).og or was at priceaingeagene carry completedile by us z skills have can Inind from sleepable ch \\' are sh trard he butwed herselfureackans playingple managedormak daughterase ifudite truthfer anywayive so smiled joined smokeies wild my we ment everywhere your seeing all battery er which par\",oundishesactgratedier chanceally envportimmingll dependonearyma work earlier his useder will getousinkug noThank one upwe diver walked out newryoth would thereish setex returnail any It when go had ending hashed part like journal man then class using some addles carriedrowearah wasn needough triangleumps bin whatasuresled disappearsetsh grab hopingven... faces somewhereick want rain gr only favoriteely shouldement alsoings You weress materials they uniformond more her quicklyfterlockrogze Thisadoull other safe how justange time sickical first He finding doesraceys successful If them into itsese brown over Luke way lazycess comfortable whereient valueestsater their donty try same helped twooldey could ringurr act aboutmer mudna who been runlive acceptedaddy know see himning succeedates As end followpect trip So look problem beach trust And stonesred strength than fake questionins For afteramp eatashax unable insect she wideorer line brokenadd But case makeilly.\"ating heavyotherative answer let fish here back did neighbour closerfly eachcy off find nowwork remaineduleake mouse used kindseverined suchful Sus We afternoon examine thinkave numbermyiftsashed hand novel because restore happened beautiful start helpts forget willing basketorn post tasks very...\"ek waited dinner fr every before smileats forgot again Davenyract Flo longually found bodies right food said endedool show danger chain Beizard wellzy met through while pays something most car dance true spoterta much birds newsitedTheway lab even apple print Finally still happyby ensure cup down unknown loved year surprised today being\". solution adviceuntane There pour wondering else represented sister luck,\" play knows bothbecause gentle open What without ! event our made mar corn good many encountered dogs another rest might sign trying Can must keyible showed say dangerous last doesn nose Emmaling.) sure realdo obey version highopus Ever determined tried wall best model those own Billy put trap When leavingantsacks Noidoade row possible sincevesared imageures Ab escape mistakeolly Then bravekey arms bl poem called decor request eventually instead why person ... drove oldks bread come queen consider placeonders sk too fun greatennretch wonicing harm take Sometimes expecturance vision left All At wore given final perform spentWhenoss far little able pathtime filled chosen topides better Jane John prizeNow forenesscerHer Herepy happening understand child recorded really extreme She count people already done smallaved ear fixley mail always waiting headily got coffee never battle tap givetable alive laugh Fl sw challengebye putting lived explore decision loop superJack years gir original next day thoughster spend serious neck wheelpper plane trees turn relief bush cloudsara dressmet havingaps success permission wants care Now trebedAny peace bitbodyolen clim bar doing planningrane powers May appear side starsili tell thing fresh sent shorerel going later Would impact They milk smallestently laughed cry things thoughtriesirt runningious glad until whenever once discoveredcome anger inside learnednie crowd contentamed End Let gettingumber Ell Will around clear Seeining seem life few SarahAndury After actually design stopped hard understood kind surrender sightwards Joe approach Littleola idea With nearpped full came appreciate bird wise keepimmer guitar four?\" cold feeling sell Anna door miss lake hatoral looking timeshost creation moments nothing power stayed coin anything bathIt style West hair guilty fly bag world lady mirrorged winnerlie least traditionitingCome supplyeman level course Mr tw moment furppingDa bear home newspaper enjoyedpa leadcing didn lot onto recognitionama enoughamingcomingunch fortuneiness serv wholeised memory pool Thank drawingrun suddenly friendly truly mighty dust along gift task friendshipMy doctorump listen looks okJohn promise away yet People mind Add imaginationyard window listening colours courageYou eager isn wentcket skill helping acceptella tightyedThen flower body persistentummy light robotativity extraordinary Adam bright seenively His summer Train took available horizon parentsoo From\\'\" waves himselfNot faced Samliesevenatures house face makes Paulasure Whyfall albumTHENo arrived storepta sand worked happen box close)! team giantLet words daysories!\"He Don stick became Charlie loops ever Po family Dan Sal Amy slide thanks rough heavily Ana huge critThis measurementsinding injurediration othersiest oftenming Ag sense brick gateway empty save owner gratefuliger water Sue important bra Ben neighbor repeat Pat young everything returned guess tricky entire FridayAt cheap studied together draw normal castle Finila Jimmy special Lucy watched cityitude pray\\'.aver runner jump wonderful needed discovery shown bad difference offered!\\' step Tom move paid pin fixed childrenaring kingdomlight reward dreamolf mistakes stone protect okay figure matterored bringing nearby Spark caught asked setting saw bald itemsBen feel differences mess wait passed burst rolled solve forgotten spokedy received clelocked counted:) hurried strongowed front takenFrom grandaling Lifeises night believe mystery welcome cookies started began musicrown soon town recommendation valuable Meteared seatfuthyogether easy fatherBob white air big extraWe Finn hold boatiding comfort animal problems watchingids gave someone yes takesiny believed perfect focusedpressed machine heldcker provided become soft hopeizz joboney mole pie stop prettyhes eyesaking learn Charlotte handed friendughing wanted!. wisdom lookedisyounceitter fast necessary replace heart talk ol enjoy human mouthTomppa afraid slow eggs hero amount covering Always Lauraetaino hurtsl comeshd importancemp Peterf.y,w playedk)(-:ISC\" attack\\'xzEM calm*L; loveAfter38 forest outsideJK taste holding?Y useful uniqueying! distanceZ told futureleep“ grew Andy tree remembered”rot Jack nature amaz maybeargaTim longerœ drinkonds€ scar knowing cop taking© mother famous followed measureecause walking pet clothes lost roomandy village behind sn storyfatherasing ways gathered mistanda energy finds meet movie lose park‹ Louis forever pleased Max proud\\\\\" clean™ ground extremely leave benefit becoming joinvet branchesiday slowly promised sometimes sound¦ themselves allowed storm heard THE warm woman addition jam higher everyone seemed loud triesocoa.\\' achieved allowing Mary mountain hours indeed speed None yesterday setup shareoco bell aheadBut attacked party GrandasticSo brought happiness ran knewered forward lotsMaybe flying bitter wishievedesty cheer walls sad Inside coming situation showing completelyighter thank remember poor deep opened darkiling watch learning turning discover fair moral grow sky study handsannyauc sunSam bed figured presents scattericious lap weather cat haySinceheart Bill Patrick walkplace ice sailogacycle spring aer ones choose painted beginning servedLook continue easier suffering pain brandokes animals snowMe givingAm dare meant smart teach exit reliable feet money anymore Joseph practiceoke bringadow king tired secretThat pup clever worth felt surface sharp towards ordinary stronger safely delight knowledge joy safety finally saveddedMonieving beauty Bear effort singing morning blue shared experience million thinkingoe goal agreed shadow voiceppy adm ash choice flagicks dryThey alone :-) reachedtons trouble unexpectedazz magic vain yourself treat ratkeeper creature planet Every continued nice fruit satisfied placesiser picture dwell Ruby wouldn yours performing rock storiespto gone princeLu finished ship Even refused excited worry honestelling straight carefuliona girl Those sit cave Value Tim friends drive mineitten lear carefully expecting green hiddenaled train confident bullet stay ready adult`` baby perfectly proposedMax blocked wet Bob taught Big Len landscape ago boy interestingilled spark Ann flight crash brother swing Alice kept journeyissa owberry hop destroy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.tokenizer.decode_ids(list(set(i[-1] for i in data[\"idx\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a2d929-e13b-4b61-a0f9-6081aab56c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation = load_dataset(\n",
    "    BASE_URL + \"/data/downloads/TinyStories\",\n",
    "    split=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d0f8022-52f9-41af-ad22-097184922b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\\n\\nAfter playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_validation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b83c24cc-d0e3-4adf-9fe0-9a4e4342e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2tokens(\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    batch_size: int,\n",
    "    batched: int,\n",
    "    num_proc: int,\n",
    "    text_col: str = \"text\",\n",
    "):\n",
    "    dataset = dataset.map(\n",
    "        lambda x: {\"text\": [en.strip() for en in x[text_col]]},\n",
    "        batch_size=batch_size,\n",
    "        batched=batched,\n",
    "        num_proc=num_proc,\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda example: {\"idx\": print(tokenizer.encode(example[\"text\"]))},\n",
    "        batch_size=batch_size,\n",
    "        batched=batched,\n",
    "        num_proc=num_proc,\n",
    "        remove_columns=[\"text\"],\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecda33f3-7c49-47d6-9e42-c9ee6bbecdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0c3166856142d7ad9fb0c2dfbbd97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f410b0750784e779af1cdc0e7a94ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1706, 327, 29889, 1706, 327, 4446, 278, 528, 4901, 1559, 322, 1497, 29892, 376, 29956, 340, 29892, 476, 986, 29891, 29892, 596, 1559, 338, 577, 11785, 322, 5941, 3850, 476, 986, 29891, 25156, 322, 10352, 29892, 376, 25271, 366, 29892, 1706, 327, 29889, 306, 1248, 728, 372, 1432, 2462, 1213, 13, 13, 13555, 8743, 411, 278, 1559, 29892, 476, 986, 29891, 322, 1706, 327, 7091, 266, 765, 29891, 29889, 2688, 1476, 263, 2319, 282, 898, 411, 2821, 4094, 29889, 2688, 270, 10003, 278, 4094, 322, 7091, 1407, 9796, 29889, 2688, 5318, 4208, 599, 2462, 322, 3897, 1900, 7875, 29889]]\n",
      "[[4335, 322, 365, 2354, 892, 1900, 7875, 29889, 2688, 23289, 304, 1708, 8090, 322, 1809, 12516, 4208, 29889, 3118, 2462, 29892, 896, 1476, 263, 4802, 9200, 6710, 297, 278, 14089, 29889, 739, 471, 528, 4901, 322, 4628, 322, 750, 263, 1472, 8014, 29889, 13, 13, 29908, 29956, 340, 29892, 1106, 472, 445, 3850, 4335, 1497, 29889, 376, 12024, 29915, 29879, 1018, 372, 3850, 13, 13, 15597, 3614, 12169, 304, 4808, 278, 9200, 6710, 322, 1207, 2090, 1460, 694, 4637, 29889, 2688, 19090, 322, 750, 2090, 29889, 1987, 365, 2354, 750, 385, 2969, 29889, 13, 13, 29908, 12024, 29915, 29879, 21039, 263, 7035, 304, 1269, 916, 1699, 1183, 1497, 29889, 376, 6246, 1016, 29915, 29873, 2649, 5019, 1683, 29892, 20759, 3026, 13, 13, 29908, 20434, 388, 1699, 4335, 1497, 29889, 940, 20793, 287, 3802, 304, 278, 9200, 6710, 322, 21039, 287, 1554, 297, 365, 2354, 29915, 29879, 2326, 29889, 365, 2354, 25156, 322, 18778, 7176, 29889, 1987, 1183, 21039, 287, 1554, 297, 4335, 29915, 29879, 2326, 29889, 4335, 285, 4708, 287, 322, 5148, 14610, 29889, 13, 13, 29908, 5618, 1258, 366, 1827, 3026, 540, 4433, 29889, 13, 13, 29908, 29902, 1497, 306, 1016, 29915, 29873, 763, 366, 15128, 1699, 365, 2354, 1497, 29889, 376, 3492, 526, 2099, 322, 289, 8253, 322, 306, 1016, 29915, 29873, 864, 304, 367, 596, 5121, 1213, 13, 13, 21599, 7091, 263, 4802, 21682, 297, 670, 5192, 29889, 940, 13700, 278, 9200, 6710, 322, 6350, 3448, 29892, 10901, 292, 29889, 365, 2354, 19090, 322, 18691, 701, 278, 9200, 6710, 29889, 2296, 3282, 29915, 29873, 2562, 1048, 4335, 29889, 2296, 871, 5131, 304, 1708, 411, 278, 9200, 6710, 29889, 13, 13, 6246, 1183, 3282, 29915, 29873, 1073, 393, 278, 9200, 6710, 471, 451, 263, 304, 29891, 29889, 739, 471, 263, 1855, 9200, 6710, 393, 28911, 304, 263, 767, 1058, 3796, 297, 278, 14089, 29889, 940, 1304, 372, 304, 5193, 304, 278, 2305, 1058, 2996, 304, 1074, 278, 15006, 322, 278, 18281, 29889, 940, 750, 2175, 372, 373, 263, 3856, 305, 1550, 540, 3512, 304, 679, 777, 4094, 29889, 13, 13, 10401, 540, 2996, 1250, 29892, 540, 6091, 365, 2354, 29915, 29879, 7314, 373, 278, 22526, 5965, 5790, 29889, 940, 6091, 902, 1827, 393, 1183, 3282, 29915, 29873, 763, 4335, 322, 393, 540, 471, 2099, 322, 289, 8253, 29889, 940, 884, 6091, 4335, 29915, 29879, 10901, 322, 4446, 1075, 1065, 3448, 29889, 940, 471, 1407, 26230, 322, 14610, 29889, 940, 17096, 701, 304, 365, 2354, 322, 3614, 278, 9200, 6710, 515, 902, 29889, 13, 13, 29908, 29950, 1032, 29892, 825, 526, 366, 2599, 3026, 365, 2354, 1497, 29889, 376, 29954, 573, 372, 1250, 3850, 13, 13, 29908, 3782, 29892, 306, 2113, 29915, 29873, 1699, 278, 767, 1497, 29889, 376, 4013, 338, 451, 263, 304, 29891, 29889, 910, 338, 590, 9200, 6710, 29889, 1126, 366, 526, 263, 1407, 4319, 7826, 29889, 887, 21682, 596, 5121, 29915, 29879, 21737, 411, 596, 2099, 3838, 29889, 887, 881, 367, 23723, 2795, 310, 7535, 1213, 13, 13, 29931, 2354, 7091, 885, 1965, 322, 7423, 29889, 2296, 5131, 304, 1827, 7423, 304, 4335, 322, 304, 278, 767, 29892, 541, 1183, 8496, 29915, 29873, 29889, 450, 767, 3614, 902, 491, 278, 1361, 322, 5331, 902, 304, 278, 14089, 8034, 29889, 940, 2000, 902, 11825, 322, 5429, 963, 825, 1183, 750, 2309, 29889, 2688, 2996, 322, 18691, 902, 701, 29889, 2688, 892, 1407, 26230, 322, 14610, 2086, 29889, 2688, 885, 1025, 287, 902, 322, 3614, 3448, 902, 304, 952, 29889, 2688, 1497, 1183, 750, 304, 367, 2924, 322, 7575, 304, 4045, 29892, 470, 1183, 723, 505, 694, 7875, 29889, 13, 13, 29931, 2354, 10680, 322, 10680, 29889, 2296, 20024, 1183, 750, 2360, 1476, 278, 9200, 6710, 29889, 2296, 20024, 1183, 750, 2360, 21039, 287, 393, 7035, 29889, 2296, 20024, 1183, 750, 1063, 2924, 304, 4335, 29889, 1205, 372, 471, 2086, 5683, 29889, 2296, 750, 5714, 902, 1900, 5121, 322, 902, 2090, 29889, 2296, 750, 263, 1407, 4319, 2462, 29889]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Provided `function` which is applied to all elements of table returns a `dict` of types [<class 'NoneType'>]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(<class 'list'>, <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>, <class 'torch.Tensor'>)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/pranav-pc/.env/lib/python3.11/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/home/pranav-pc/.env/lib/python3.11/site-packages/datasets/utils/py_utils.py\", line 623, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"/home/pranav-pc/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 3482, in _map_single\n    batch = apply_function_on_filtered_inputs(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/pranav-pc/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 3372, in apply_function_on_filtered_inputs\n    validate_function_output(processed_inputs, indices)\n  File \"/home/pranav-pc/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 3338, in validate_function_output\n    raise TypeError(\nTypeError: Provided `function` which is applied to all elements of table returns a `dict` of types [<class 'NoneType'>]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(<class 'list'>, <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>, <class 'torch.Tensor'>)`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtext2tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 16\u001b[0m, in \u001b[0;36mtext2tokens\u001b[0;34m(dataset, tokenizer, batch_size, batched, num_proc, text_col)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext2tokens\u001b[39m(\n\u001b[1;32m      2\u001b[0m     dataset,\n\u001b[1;32m      3\u001b[0m     tokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     text_col: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m ):\n\u001b[1;32m      9\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [en\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m en \u001b[38;5;129;01min\u001b[39;00m x[text_col]]},\n\u001b[1;32m     11\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     12\u001b[0m         batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m     13\u001b[0m         num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m     14\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43midx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    556\u001b[0m }\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/arrow_dataset.py:3197\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3191\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3193\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3194\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3195\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3196\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miflatmap_unordered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs_per_job\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/utils/py_utils.py:663\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m         \u001b[43m[\u001b[49m\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masync_result\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masync_results\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/datasets/utils/py_utils.py:663\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/.env/lib/python3.11/site-packages/multiprocess/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mTypeError\u001b[0m: Provided `function` which is applied to all elements of table returns a `dict` of types [<class 'NoneType'>]. When using `batched=True`, make sure provided `function` returns a `dict` of types like `(<class 'list'>, <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>, <class 'torch.Tensor'>)`."
     ]
    }
   ],
   "source": [
    "tokens = text2tokens(data_validation, ds.tokenizer, int(1), True, 2, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dd64f0c-8b56-48f7-835b-4b4fbc0161c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': [9038,\n",
       "  2501,\n",
       "  263,\n",
       "  931,\n",
       "  29892,\n",
       "  727,\n",
       "  471,\n",
       "  263,\n",
       "  2217,\n",
       "  17354,\n",
       "  11203,\n",
       "  4257,\n",
       "  1706,\n",
       "  327,\n",
       "  29889,\n",
       "  940,\n",
       "  18012,\n",
       "  304,\n",
       "  1708,\n",
       "  411,\n",
       "  670,\n",
       "  8287,\n",
       "  297,\n",
       "  278,\n",
       "  14089,\n",
       "  29889,\n",
       "  3118,\n",
       "  6575,\n",
       "  1460,\n",
       "  2462,\n",
       "  29892,\n",
       "  1706,\n",
       "  327,\n",
       "  4446,\n",
       "  263,\n",
       "  4802,\n",
       "  7306,\n",
       "  373,\n",
       "  278,\n",
       "  916,\n",
       "  2625,\n",
       "  310,\n",
       "  278,\n",
       "  14089,\n",
       "  29889,\n",
       "  940,\n",
       "  5131,\n",
       "  304,\n",
       "  679,\n",
       "  670,\n",
       "  8287,\n",
       "  964,\n",
       "  278,\n",
       "  7306,\n",
       "  29889,\n",
       "  13,\n",
       "  13,\n",
       "  5592,\n",
       "  327,\n",
       "  6350,\n",
       "  5172,\n",
       "  411,\n",
       "  278,\n",
       "  8287,\n",
       "  297,\n",
       "  670,\n",
       "  13394,\n",
       "  29889,\n",
       "  940,\n",
       "  1898,\n",
       "  304,\n",
       "  24817,\n",
       "  278,\n",
       "  8287,\n",
       "  964,\n",
       "  278,\n",
       "  7306,\n",
       "  29892,\n",
       "  541,\n",
       "  540,\n",
       "  471,\n",
       "  2086,\n",
       "  2319,\n",
       "  29889,\n",
       "  1706,\n",
       "  327,\n",
       "  4687,\n",
       "  304,\n",
       "  21117,\n",
       "  29889,\n",
       "  940,\n",
       "  1898,\n",
       "  1449,\n",
       "  322,\n",
       "  1449,\n",
       "  29892,\n",
       "  541,\n",
       "  278,\n",
       "  8287,\n",
       "  723,\n",
       "  451,\n",
       "  748,\n",
       "  297,\n",
       "  29889,\n",
       "  13,\n",
       "  13,\n",
       "  11760,\n",
       "  29892,\n",
       "  1706,\n",
       "  327,\n",
       "  750,\n",
       "  385,\n",
       "  2969,\n",
       "  29889,\n",
       "  940,\n",
       "  4433,\n",
       "  670,\n",
       "  5121,\n",
       "  29892,\n",
       "  263,\n",
       "  4802,\n",
       "  17354,\n",
       "  10435,\n",
       "  4257,\n",
       "  7038,\n",
       "  4518,\n",
       "  29892,\n",
       "  363,\n",
       "  1371,\n",
       "  29889,\n",
       "  7038,\n",
       "  4518,\n",
       "  413,\n",
       "  17840,\n",
       "  278,\n",
       "  8287,\n",
       "  411,\n",
       "  670,\n",
       "  4549,\n",
       "  21152,\n",
       "  29889,\n",
       "  450,\n",
       "  8287,\n",
       "  9115,\n",
       "  29893,\n",
       "  964,\n",
       "  278,\n",
       "  7306,\n",
       "  29991,\n",
       "  1706,\n",
       "  327,\n",
       "  471,\n",
       "  577,\n",
       "  9796,\n",
       "  29889,\n",
       "  940,\n",
       "  322,\n",
       "  7038,\n",
       "  4518,\n",
       "  5318,\n",
       "  4208,\n",
       "  599,\n",
       "  2462,\n",
       "  1472,\n",
       "  29889]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3457738c-99a7-4af8-8d68-96ddfd7c8a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 262])\n"
     ]
    }
   ],
   "source": [
    "ds.setup(\"val\")\n",
    "val_dataloader = ds.val_dataloader()\n",
    "for data in next(iter(val_dataloader)):\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "841be42e-2391-4e1b-b791-9268659d19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04148564-fedc-4086-9967-eed754357cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  2296, 18691,  ...,  1568,   901,  2090],\n",
       "        [    1,    13,    13,  ..., 29889,   450,  1095],\n",
       "        [ 9038,  2501,   263,  ...,   347, 29915, 29879],\n",
       "        ...,\n",
       "        [ 9038,  2501,   263,  ...,   278,  6501,  4646],\n",
       "        [ 9038,   727,   471,  ..., 29899, 23057,   287],\n",
       "        [ 9038,  2501,   263,  ...,  1708,   777,   901]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0e312cb-b366-4ca5-a92f-c31b6e61fd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2296, 18691,   701,  ...,   901,  2090,  1213],\n",
       "        [   13,    13, 29931,  ...,   450,  1095, 29889],\n",
       "        [ 2501,   263,   931,  ..., 29915, 29879, 29889],\n",
       "        ...,\n",
       "        [ 2501,   263,   931,  ...,  6501,  4646, 29889],\n",
       "        [  727,   471,   263,  ..., 23057,   287, 29889],\n",
       "        [ 2501,   263,   931,  ...,   777,   901, 29889]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46df564d-fc0b-4df5-81a2-1ae3f6e5b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': [1, 2296, 18691, 701, 263, 12070, 322, 281, 10511, 372, 472, 278, 11460, 29889, 2296, 21272, 287, 322, 18318, 25702, 472, 372, 29889, 2296, 24936, 372, 723, 748, 3448, 29889, 13, 13, 1576, 11460, 471, 12327, 28133, 491, 365, 2354, 29915, 29879, 12070, 322, 25702, 29889, 739, 8459, 393, 4111, 322, 670, 1559, 892, 451, 7088, 278, 7458, 29889, 739, 5807, 18054, 322, 17096, 3448, 29892, 3063, 363, 385, 6775, 5807, 547, 29889, 13, 13, 20841, 7450, 278, 5970, 310, 278, 6872, 322, 298, 688, 3192, 365, 2354, 29889, 940, 471, 528, 5086, 322, 10901, 292, 29889, 940, 471, 7423, 363, 1641, 19281, 4939, 322, 17928, 728, 29889, 940, 6452, 287, 365, 2354, 363, 14238, 1075, 29889, 13, 13, 29908, 29902, 29915, 29885, 7423, 29892, 365, 2354, 29892, 366, 892, 1492, 29889, 450, 6872, 471, 451, 263, 14378, 29889, 739, 471, 451, 4023, 828, 404, 29889, 739, 471, 885, 653, 322, 4319, 29889, 306, 881, 505, 29616, 304, 366, 29889, 887, 526, 263, 1781, 5121, 29889, 3374, 366, 363, 19912, 592, 1213, 13, 13, 29931, 2354, 298, 688, 3192, 4111, 1250, 29889, 2296, 471, 10932, 540, 471, 9109, 29889, 2296, 18879, 1351, 1075, 363, 1641, 24866, 29889, 2296, 471, 263, 1781, 5121, 2086, 29889, 13, 13, 29908, 3112, 29915, 29879, 20759, 29892, 4111, 29892, 306, 29915, 29885, 10932, 366, 29915, 276, 20759, 29889, 450, 6872, 471, 451, 263, 2058, 304, 1708, 29889, 739, 471, 263, 2058, 304, 4772, 29889, 887, 10972, 596, 3109, 265, 29889, 8084, 931, 29892, 1235, 29915, 29879, 7952, 373, 278, 17455, 29889, 739, 29915, 29879, 1568, 901, 2090, 1213]}\n",
      "{'idx': [1, 13, 13, 29931, 2354, 1560, 5475, 322, 18906, 29892, 376, 25271, 366, 29892, 11203, 29889, 887, 526, 7575, 29889, 306, 29915, 29885, 7423, 306, 3614, 596, 3056, 29889, 1815, 591, 367, 7875, 3026, 450, 11203, 18778, 29879, 322, 289, 17862, 29889, 940, 4188, 267, 365, 2354, 29889, 940, 18906, 29892, 376, 8241, 29892, 591, 508, 367, 7875, 29889, 1205, 2446, 931, 29892, 2244, 1434, 366, 2125, 1554, 29889, 9280, 3026, 13, 13, 29931, 2354, 18778, 29879, 322, 18906, 29892, 376, 8949, 29889, 306, 674, 29889, 306, 10972, 590, 3109, 265, 29889, 306, 674, 451, 2125, 2712, 393, 526, 451, 7903, 29889, 306, 674, 367, 7575, 322, 1248, 568, 29889, 306, 674, 1804, 29892, 525, 12703, 306, 505, 372, 29892, 3113, 29973, 11838, 13, 13, 18650, 16823, 298, 16926, 902, 322, 18906, 29892, 376, 29902, 29915, 29885, 22314, 310, 366, 29892, 365, 2354, 29889, 887, 1754, 263, 10171, 29892, 541, 366, 4343, 372, 29889, 887, 1497, 7423, 322, 366, 4846, 1250, 278, 3056, 29889, 887, 1754, 263, 716, 5121, 29889, 887, 526, 263, 1781, 7826, 1213, 13, 13, 29931, 2354, 298, 16926, 902, 16823, 322, 18906, 29892, 376, 29902, 5360, 366, 29892, 16823, 29889, 887, 526, 278, 1900, 29889, 1815, 591, 748, 1708, 373, 278, 2381, 886, 1286, 3026, 13, 13, 18650, 16823, 18906, 29892, 376, 8241, 29892, 591, 508, 29889, 16760, 373, 29892, 1235, 29915, 29879, 748, 1213, 2688, 6686, 304, 278, 2381, 886, 29892, 13587, 6567, 29889, 450, 11203, 4477, 963, 29892, 591, 4362, 670, 3056, 29889, 2688, 526, 9796, 29889, 2688, 1804, 322, 10569, 322, 1708, 29889, 450, 1095, 29889]}\n",
      "{'idx': [9038, 2501, 263, 931, 29892, 727, 471, 263, 4802, 4552, 561, 424, 4257, 11001, 347, 29889, 11001, 347, 471, 1407, 10668, 29891, 322, 2337, 8126, 902, 5716, 5941, 29889, 3118, 2462, 29892, 902, 5121, 1601, 1989, 2996, 304, 6493, 902, 29889, 2598, 1989, 1497, 29892, 376, 29923, 645, 347, 29892, 596, 5716, 338, 577, 10668, 29891, 29991, 1815, 366, 6860, 592, 920, 304, 10668, 29891, 590, 5716, 2086, 3026, 11001, 347, 10352, 29892, 376, 29903, 545, 29892, 306, 508, 9080, 408, 596, 15703, 322, 1510, 366, 920, 304, 10668, 29891, 701, 1213, 13, 13, 29923, 645, 347, 4687, 18819, 2598, 1989, 920, 304, 10668, 29891, 701, 670, 5716, 29889, 2296, 1497, 29892, 376, 6730, 29892, 591, 817, 304, 5839, 701, 599, 278, 304, 952, 322, 1925, 963, 297, 1009, 1571, 2058, 29889, 1987, 29892, 591, 817, 304, 1207, 278, 6592, 322, 900, 29881, 278, 9654, 1691, 29889, 9788, 29892, 591, 817, 304, 7901, 1022, 278, 11904, 322, 1207, 1854, 4129, 338, 297, 967, 1492, 7688, 1213, 2598, 1989, 471, 9796, 304, 5110, 322, 1497, 29892, 376, 25271, 366, 29892, 11001, 347, 29991, 887, 526, 1316, 263, 2107, 15703, 1213, 29871, 13, 13, 29923, 645, 347, 25156, 322, 1497, 29892, 376, 3112, 471, 590, 15377, 304, 9080, 408, 596, 15703, 29889, 2567, 29892, 1235, 29915, 29879, 505, 777, 2090, 322, 1708, 411, 1749, 304, 952, 3850, 450, 1023, 7875, 5318, 322, 750, 263, 2107, 931, 297, 11001, 347, 29915, 29879, 10668, 29891, 5716, 29889, 3645, 393, 2462, 373, 29892, 2598, 1989, 2337, 8126, 670, 5716, 10668, 29891, 925, 763, 11001, 347, 29915, 29879, 29889]}\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "\n",
    "for idx, data in enumerate(ds.val_dataloader().dataset):\n",
    "    print(data)\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fe3a938-3a3e-458a-86e4-814bd5bb5984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': Dataset({\n",
       "     features: ['idx'],\n",
       "     num_rows: 12501\n",
       " }),\n",
       " 'num_workers': 26,\n",
       " 'prefetch_factor': 2,\n",
       " 'pin_memory': True,\n",
       " 'pin_memory_device': '',\n",
       " 'timeout': 0,\n",
       " 'worker_init_fn': None,\n",
       " '_DataLoader__multiprocessing_context': None,\n",
       " '_dataset_kind': 0,\n",
       " 'batch_size': 16,\n",
       " 'drop_last': False,\n",
       " 'sampler': <torch.utils.data.sampler.SequentialSampler at 0x7fd4f262db90>,\n",
       " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x7fd4f262fc90>,\n",
       " 'generator': None,\n",
       " 'collate_fn': functools.partial(<bound method TinyStoriesDataloader._collate_fn of <__main__.TinyStoriesDataloader object at 0x7fd4f2599850>>, padding_id=2),\n",
       " 'persistent_workers': False,\n",
       " '_DataLoader__initialized': True,\n",
       " '_IterableDataset_len_called': None,\n",
       " '_iterator': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.val_dataloader().__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdd5b2-eeea-4b05-80bc-2e92486b365e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
