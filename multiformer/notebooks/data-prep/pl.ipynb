{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a553b64-e7cf-48dd-8c60-2ac3fe65e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as pl\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import functools\n",
    "\n",
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ca72f82-8bd1-4eac-9b72-2415f121d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyStoriesDataloader(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, data_path_train, data_path_val, tokenizer_path, batch_size, num_workers\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_path_train = data_path_train\n",
    "        self.data_path_val = data_path_val\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.tokenizer = self._load_tokenizer(tokenizer_path)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def _load_tokenizer(self, tokenizer_path):\n",
    "        from src.tokenize.tokenizer import Tokenizer\n",
    "\n",
    "        return Tokenizer(tokenizer_path)\n",
    "\n",
    "    def _collate_fn(self, batch: int, padding_id: int):\n",
    "        batch = pad_sequence(\n",
    "            (torch.LongTensor(_[\"idx\"]) for _ in batch),\n",
    "            batch_first=True,\n",
    "            padding_value=padding_id,\n",
    "        )  # TODO : ShortTensor suffice our need but nn.Embedding don't support it. Using LOngTensor is a unnecessary waste of GPU memory\n",
    "        x_batch = torch.stack(\n",
    "            [en[:-1] for en in batch]\n",
    "        )  # Extract x (remove last token)\n",
    "        y_batch = torch.stack(\n",
    "            [en[1:] for en in batch]\n",
    "        )  # Extract y (remove first token)\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def setup(self, stage):\n",
    "\n",
    "        self.train_data = load_from_disk(self.data_path_train)\n",
    "        self.val_data = load_from_disk(self.data_path_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=functools.partial(\n",
    "                self._collate_fn, padding_id=self.tokenizer.eos_id()\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=functools.partial(\n",
    "                self._collate_fn, padding_id=self.tokenizer.eos_id()\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b25a704-64fe-4f9e-89e7-95e7e10c5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"/home/pranav-pc/projects/OpenTransformer/multiformer\"\n",
    "data_path_train = BASE_URL + \"/data/interim/TinyStories_train_65>tk>512.hf\"\n",
    "data_path_val = BASE_URL + \"/data/interim/TinyStories_val_65>tk>512.hf\"\n",
    "tokenizer_path = BASE_URL + \"/tokenizer_checkpoints\"\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 26\n",
    "ds = TinyStoriesDataloader(\n",
    "    data_path_train, data_path_val, tokenizer_path, batch_size, num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "233681cc-8e08-485f-bb57-f4944419e72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_from_disk(BASE_URL + \"/data/interim/TinyStories_val_65>tk>512.hf\")\n",
    "ds.tokenizer.decode_ids(list(set(i[-1] for i in data[\"idx\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "37a2d929-e13b-4b61-a0f9-6081aab56c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,  4335,  5148,  ...,  1009, 17487, 29889],\n",
       "         [    1,  2259,   471,  ...,  1250,  4720, 29889],\n",
       "         [    1,  3118,  2462,  ...,   310,  3974, 29889],\n",
       "         ...,\n",
       "         [    1,  4976,   322,  ...,  3698,  4459, 29889],\n",
       "         [    1,  9038,  2501,  ...,  4056, 17724, 29889],\n",
       "         [    1,   365,  2354,  ...,  5121, 22296,  1213]]),\n",
       " tensor([[ 4335,  5148,   714,  ..., 17487, 29889,     2],\n",
       "         [ 2259,   471,  6365,  ...,  4720, 29889,     2],\n",
       "         [ 3118,  2462,   297,  ...,  3974, 29889,     2],\n",
       "         ...,\n",
       "         [ 4976,   322,   670,  ...,  4459, 29889,     2],\n",
       "         [ 9038,  2501,   263,  ..., 17724, 29889,     2],\n",
       "         [  365,  2354,   471,  ..., 22296,  1213,     2]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.setup(\"val\")\n",
    "val_dataloader = ds.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10915265-5d2c-477d-ba4d-b619ec76b36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1,  4335,  5148,  ...,  1009, 17487, 29889],\n",
       "         [    1,  2259,   471,  ...,  1250,  4720, 29889],\n",
       "         [    1,  3118,  2462,  ...,   310,  3974, 29889],\n",
       "         ...,\n",
       "         [    1,  4976,   322,  ...,  3698,  4459, 29889],\n",
       "         [    1,  9038,  2501,  ...,  4056, 17724, 29889],\n",
       "         [    1,   365,  2354,  ...,  5121, 22296,  1213]]),\n",
       " tensor([[ 4335,  5148,   714,  ..., 17487, 29889,     2],\n",
       "         [ 2259,   471,  6365,  ...,  4720, 29889,     2],\n",
       "         [ 3118,  2462,   297,  ...,  3974, 29889,     2],\n",
       "         ...,\n",
       "         [ 4976,   322,   670,  ...,  4459, 29889,     2],\n",
       "         [ 9038,  2501,   263,  ..., 17724, 29889,     2],\n",
       "         [  365,  2354,   471,  ..., 22296,  1213,     2]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,label = next(iter(val_dataloader))\n",
    "data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff840f0-9223-45dd-8b7d-5992b657804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "conf = {\n",
    "    \"vocab_size\": 32000,\n",
    "    \"emebdding_dim\": 768,\n",
    "    \"max_seq_len\": block_size,\n",
    "    \"embedding_dropout\": 0.0,\n",
    "    \"rms_norm_eps\": 1e-05,\n",
    "    \"rope_scaling\": 1.0,\n",
    "    \"rope_theta\": 10000.0,\n",
    "    \"attention_bias\": False,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"num_attention_heads\": 12,\n",
    "    \"num_key_value_heads\": 12,\n",
    "    \"use_cache\": True,\n",
    "    \"use_sliding_window\": True,\n",
    "    \"residual_dropout\": 0.1,\n",
    "    \"mlp_dropout\": 0.0,\n",
    "    \"mlp_hidden_size\": int(1.3 * 768),\n",
    "    \"num_layers\": 4,\n",
    "    \"device\": device,\n",
    "    \"padding_idx\": tokenizer.eos_id(),\n",
    "}\n",
    "\n",
    "\n",
    "from src.models.blm.config import ModelArgs\n",
    "from src.models.blm.model import Transformer\n",
    "\n",
    "\n",
    "config = ModelArgs(**conf)\n",
    "model = Transformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8f5d4-fbe5-4a4e-9973-51f02ecd28cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
